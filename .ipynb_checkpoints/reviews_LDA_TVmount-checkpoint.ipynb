{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\nmf.py:972: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\nmf.py:1186: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\t_sne.py:420: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)  # to view entire text in any column\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import gzip\n",
    "from pprint import pprint\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "#nltk.download('stopwords') # run this line only once\n",
    "from nltk.corpus import stopwords\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer  # alternative lemmatizer\n",
    "# lemma = WordNetLemmatizer()\n",
    "\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim   # for visualizing found topics\n",
    "\n",
    "import os\n",
    "os.environ['MALLET_HOME'] = \"C:/Users/yanqi/Library/mallet-2.0.8\"\n",
    "mallet_path = \"C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet\"\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)  # suppressing deprecation warnings when running gensim LDA\n",
    "\n",
    "from specialmaps import HTML_MAP # for manual cleaning of HTML entities, not used\n",
    "from specialmaps import CONTRACTION_MAP\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for reading raw data (meta data for product info, and review data)\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDFn(path,n):\n",
    "  # read the first n lines from the json.gz file\n",
    "  i = 0\n",
    "  df = {}\n",
    "  parsed = parse(path)\n",
    "  for d in parsed:\n",
    "    print(d.keys())\n",
    "    if i >= n:\n",
    "        break\n",
    "    else:\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "def get_meta_DF_cat(path, select_cat):\n",
    "  # read in a subset of the json.gz file filtered by the categories column \n",
    "  # select_cat is a list that represents a hierarchy of categories\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    if select_cat in d['categories']:\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "def get_review_DF_asin(path, asins):\n",
    "  # get review data for the products with specified asins\n",
    "  # asins: list of asins for products of interest\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    if d['asin'] in asins:\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "def write_full_DF(select_cat):\n",
    "    # retrieved subset of meta and review data from raw data for select_category, save to csv file for faster access later\n",
    "    product_type = select_cat[0]\n",
    "    \n",
    "    # get meta data for the category of interest (indicated by select_cat)\n",
    "    meta = get_meta_DF_cat(\"meta_\" + product_type + \".json.gz\", select_cat)\n",
    "    meta.to_csv(select_cat[-1] + '_meta.csv')\n",
    "\n",
    "    # read in review data for products in the category of interest\n",
    "    reviews = get_review_DF_asin('reviews_' + product_type + '_5.json.gz', list(meta.asin))\n",
    "    reviews.to_csv(select_cat[-1] + '_reviews.csv')\n",
    "    \n",
    "def read_full_DF(file_prefix):\n",
    "    df_rev = pd.read_csv(file_prefix + '_reviews.csv',index_col = 0)\n",
    "    df_meta = pd.read_csv(file_prefix + '_meta.csv',index_col = 0)\n",
    "    return df_rev, df_meta\n",
    "\n",
    "def chk_mv(df):\n",
    "    # check for missing values in each column of the dataframe df\n",
    "    mv_bycol = pd.DataFrame( df.isnull().sum(axis=0), columns = ['num_mv'])\n",
    "    mv_bycol['pct_mv'] = mv_bycol['num_mv']/df.shape[0]\n",
    "    mv_bycol = mv_bycol.sort_values('num_mv', ascending=False)\n",
    "    mv_by_col = mv_bycol[mv_bycol['num_mv'] > 0]\n",
    "    print(mv_by_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cat = 'Electronics->Accessories & Supplies->Audio & Video Accessories->TV Accessories & Parts->TV Ceiling & Wall Mounts'.split('->')\n",
    "# write_full_DF(select_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['reviewerID', 'asin', 'helpful', 'reviewText', 'overall', 'summary',\n",
      "       'unixReviewTime', 'reviewTime', 'reviewerName'],\n",
      "      dtype='object') /n\n",
      "reviewerID        object \n",
      "asin              object \n",
      "helpful           object \n",
      "reviewText        object \n",
      "overall           float64\n",
      "summary           object \n",
      "unixReviewTime    int64  \n",
      "reviewTime        object \n",
      "reviewerName      object \n",
      "dtype: object /n\n",
      "(13123, 9) /n\n",
      "Index(['asin', 'related', 'title', 'price', 'salesRank', 'imUrl', 'brand',\n",
      "       'categories', 'description'],\n",
      "      dtype='object') /n\n",
      "asin           object \n",
      "related        object \n",
      "title          object \n",
      "price          float64\n",
      "salesRank      object \n",
      "imUrl          object \n",
      "brand          object \n",
      "categories     object \n",
      "description    object \n",
      "dtype: object /n\n",
      "(3540, 9) /n\n",
      "(13123, 17) \n",
      "\n",
      "Index(['reviewerID', 'asin', 'helpful', 'reviewText', 'overall', 'summary',\n",
      "       'unixReviewTime', 'reviewTime', 'reviewerName', 'related', 'title',\n",
      "       'price', 'salesRank', 'imUrl', 'brand', 'categories', 'description'],\n",
      "      dtype='object') \n",
      "\n",
      "              num_mv    pct_mv\n",
      "salesRank     7642    0.582336\n",
      "brand         2945    0.224415\n",
      "description   1215    0.092586\n",
      "reviewerName  353     0.026899\n",
      "price         101     0.007696\n",
      "related       83      0.006325\n",
      "title         9       0.000686\n",
      "reviewText    4       0.000305\n"
     ]
    }
   ],
   "source": [
    "df_rev, df_meta = read_full_DF(select_cat[-1])\n",
    "print(df_rev.columns,'/n')\n",
    "print(df_rev.dtypes,'/n')\n",
    "print(df_rev.shape,'/n')\n",
    "print(df_meta.columns,'/n')\n",
    "print(df_meta.dtypes,'/n')\n",
    "print(df_meta.shape,'/n')\n",
    "\n",
    "dfall = df_rev.merge(df_meta, on = 'asin')\n",
    "print(dfall.shape,'\\n')\n",
    "print(dfall.columns,'\\n')\n",
    "chk_mv(dfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8062</th>\n",
       "      <td>B001VIMEN6</td>\n",
       "      <td>Expensive as hell, but it works.  Wish I knew how to string together some metal wire cables and screw em' on.None-the-less, its an amazing product that really keeps your slim samsung snugged against the wall, simulating a true picture frame being hanged.  And it has hanged tight for over a year!</td>\n",
       "      <td>4.0</td>\n",
       "      <td>it works</td>\n",
       "      <td>Samsung WMN1000B Ultra Slim Wall Mount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10851</th>\n",
       "      <td>B0042P46OA</td>\n",
       "      <td>Bought this mounting solution to mount two LG 23\" monitors over my desk for a twin-monitor work-at-home station.  This mounting rack was perfect for these monitors and obviously could easily handle larger ones.  I'd buy again.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mounted two 23 inch monitors with room/strength to spare</td>\n",
       "      <td>Dual LCD Wall Mount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9301</th>\n",
       "      <td>B002TZ4CRG</td>\n",
       "      <td>We got 3 of these to mount some TVs in our shop, and they're working extremely well for that purpose.The install was extremely easy - it only took a few minutes.  On top of that, even though I'm typically an 'instruction-reader', there really wasn't anything complicated about this install at all.Having said that, the level that is built into the wall portion isn't reliable at all.  I would highly recommend ignoring it altogether since it was off by quite a bit in all 3 of the ones we got.Once installed, the TV's are mounted close to the wall and look great.For the price, these are an absolutely excellent value - and it's hard to imagine a better product at any price if you're just looking to mount a flat screen flush with the wall.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Easy to install, excellent value</td>\n",
       "      <td>VideoSecu Low Profile Ultra Slim 1&amp;quot; profile TV Wall Mount for most 27&amp;quot;-47&amp;quot; LCD LED Plasma TV, Some up to 55&amp;quot; Flat Panel Screen Display with VESA 100x100 to 400x400 1RX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>B0012S4APK</td>\n",
       "      <td>Instructions were a little vague, but I managed to get it put together and mounted on the wall in about 30 minutes. It is holding up an older 100lb plasma TV without any problems.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Works as advertised, but instructions are vague</td>\n",
       "      <td>Cheetah Mounts APTMM2B Flush Tilt (1.3&amp;quot; Profile) TV Wall Mount Bracket for 32-65 inch LED, LCD and Plasma Flat Screen TVs Up To VESA 684x400 and 165lbs, Including a Twisted Veins 10' Braided High Speed with Ethernet HDMI Cable and a 6&amp;quot; 3-Axis Magnetic Bubble Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>B000ID7QNI</td>\n",
       "      <td>This TV bracket mounted easily and articulates nicely. It holds my 26&amp;#34; HD TV sturdily and was much cheaper than buying at big box store.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect for small TVs</td>\n",
       "      <td>VideoSecu LCD Monitor TV Wall Mount Articulating Arm Bracket for most 12&amp;quot;-24&amp;quot;, some up to 27&amp;quot; with VESA 100/75mm LED Flat Panel Screen TV ML10B 1E9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  \\\n",
       "8062   B001VIMEN6   \n",
       "10851  B0042P46OA   \n",
       "9301   B002TZ4CRG   \n",
       "4312   B0012S4APK   \n",
       "1565   B000ID7QNI   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  reviewText  \\\n",
       "8062   Expensive as hell, but it works.  Wish I knew how to string together some metal wire cables and screw em' on.None-the-less, its an amazing product that really keeps your slim samsung snugged against the wall, simulating a true picture frame being hanged.  And it has hanged tight for over a year!                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "10851  Bought this mounting solution to mount two LG 23\" monitors over my desk for a twin-monitor work-at-home station.  This mounting rack was perfect for these monitors and obviously could easily handle larger ones.  I'd buy again.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "9301   We got 3 of these to mount some TVs in our shop, and they're working extremely well for that purpose.The install was extremely easy - it only took a few minutes.  On top of that, even though I'm typically an 'instruction-reader', there really wasn't anything complicated about this install at all.Having said that, the level that is built into the wall portion isn't reliable at all.  I would highly recommend ignoring it altogether since it was off by quite a bit in all 3 of the ones we got.Once installed, the TV's are mounted close to the wall and look great.For the price, these are an absolutely excellent value - and it's hard to imagine a better product at any price if you're just looking to mount a flat screen flush with the wall.   \n",
       "4312   Instructions were a little vague, but I managed to get it put together and mounted on the wall in about 30 minutes. It is holding up an older 100lb plasma TV without any problems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "1565   This TV bracket mounted easily and articulates nicely. It holds my 26&#34; HD TV sturdily and was much cheaper than buying at big box store.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "\n",
       "       overall                                                   summary  \\\n",
       "8062   4.0      it works                                                   \n",
       "10851  5.0      Mounted two 23 inch monitors with room/strength to spare   \n",
       "9301   5.0      Easy to install, excellent value                           \n",
       "4312   4.0      Works as advertised, but instructions are vague            \n",
       "1565   5.0      Perfect for small TVs                                      \n",
       "\n",
       "                                                                                                                                                                                                                                                                                    title  \n",
       "8062   Samsung WMN1000B Ultra Slim Wall Mount                                                                                                                                                                                                                                              \n",
       "10851  Dual LCD Wall Mount                                                                                                                                                                                                                                                                 \n",
       "9301   VideoSecu Low Profile Ultra Slim 1&quot; profile TV Wall Mount for most 27&quot;-47&quot; LCD LED Plasma TV, Some up to 55&quot; Flat Panel Screen Display with VESA 100x100 to 400x400 1RX                                                                                         \n",
       "4312   Cheetah Mounts APTMM2B Flush Tilt (1.3&quot; Profile) TV Wall Mount Bracket for 32-65 inch LED, LCD and Plasma Flat Screen TVs Up To VESA 684x400 and 165lbs, Including a Twisted Veins 10' Braided High Speed with Ethernet HDMI Cable and a 6&quot; 3-Axis Magnetic Bubble Level  \n",
       "1565   VideoSecu LCD Monitor TV Wall Mount Articulating Arm Bracket for most 12&quot;-24&quot;, some up to 27&quot; with VESA 100/75mm LED Flat Panel Screen TV ML10B 1E9                                                                                                                  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# core review data for topic modeling\n",
    "df = dfall[['asin','reviewText','overall','summary','title']]\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for data cleaning and text pre-processing \n",
    "\n",
    "    \n",
    "# function to plot most frequent terms\n",
    "def freq_words(x, terms = 30):\n",
    "  all_words = ' '.join([text for text in x])\n",
    "  all_words = all_words.split()\n",
    "\n",
    "  fdist = FreqDist(all_words)\n",
    "  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n",
    "\n",
    "  # selecting top n most frequent words\n",
    "  d = words_df.nlargest(columns=\"count\", n = terms) \n",
    "  plt.figure(figsize=(20,5))\n",
    "  ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n",
    "  ax.set(ylabel = 'Count')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            num_mv    pct_mv\n",
      "title       9       0.000686\n",
      "reviewText  4       0.000305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13119"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove record with missing reviewText\n",
    "chk_mv(df)\n",
    "df = df.dropna(subset = ['reviewText'])\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most reviewed:\n",
      "          asin  reviewCnt\n",
      "0  B0012S4APK  1295     \n",
      "1  B000WYVBR0  764      \n",
      "2  B001GTT0VO  598      \n",
      "3  B000ID7QNI  566      \n",
      "4  B000WL6YY8  525      \n",
      "5  B003O1UYHG  419      \n",
      "6  B000NMFCIA  416      \n",
      "7  B001TIG36C  391      \n",
      "8  B002MYQTEI  268      \n",
      "9  B001LL5JDA  232       \n",
      "\n",
      "count    379.000000 \n",
      "mean     34.614776  \n",
      "std      100.590265 \n",
      "min      5.000000   \n",
      "25%      6.000000   \n",
      "50%      11.000000  \n",
      "75%      23.000000  \n",
      "max      1295.000000\n",
      "Name: reviewCnt, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 12:18:14,971 : DEBUG : findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf') with score of 0.050000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic EDA \n",
    "# number of asins, number of associated reviews for each asin\n",
    "review_cnts = df.groupby('asin').agg({'reviewText':'count'}).sort_values(by = 'reviewText', ascending = False)\n",
    "review_cnts = review_cnts.reset_index()\n",
    "review_cnts = review_cnts.rename({'reviewText':'reviewCnt'}, axis = 'columns')\n",
    "print('Top 10 most reviewed:\\n', review_cnts.head(10),'\\n')\n",
    "print(review_cnts.reviewCnt.describe())\n",
    "plt.figure(figsize=(8,10))\n",
    "\n",
    "# a few products are much more highly reviewed than the rest, zoom in to x < 200\n",
    "review_cnts.plot.hist(by='reviewCnt', bins = 100, rwidth = 0.8)  \n",
    "plt.xlim([-1,100])   # enmt: log y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKIAAAFACAYAAACP0NSkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XvYbWVdL/zvT/BAngBdEAHtZcWbkRXKCjGtjdLLKduogYfcsWRba2eUWllbO7y4PVzZW1cYbaMIEVCTECRIUeJFUStQFogcPMRKUVYQrARNIzXwfv8Y95Lpw3zWetZhjvms5edzXfOaY9zjHuP+zTHHM+YYv+ceY1RrLQAAAAAwaw+adwAAAAAAfHuQiAIAAABgFBJRAAAAAIxCIgoAAACAUUhEAQAAADAKiSgAAAAARiERBQAAAMAoJKIAAAAAGIVEFAAAAACj2HXeAYztsY99bFu5cuW8wwAAAADYaVxzzTX/2lpbsbl633aJqJUrV2bt2rXzDgMAAABgp1FVn1tKPZfmAQAAADAKiSgAAAAARiERBQAAAMAoJKIAAAAAGIVEFAAAAACjkIgCAAAAYBQSUQAAAACMQiIKAAAAgFHMLBFVVd9fVddNvP6tql5eVXtW1WVVdXN/36PXr6o6tarWVdX1VfWkiWWt7vVvrqrVE+UHV9UNfZ5Tq6pm9XkAAAAA2DYzS0S11j7dWjuotXZQkoOT3JPkwiSvTHJ5a+2AJJf38SQ5OskB/bUmyWlJUlV7Jjk5yZOTHJLk5I3Jq15nzcR8R83q8wAAAACwbca6NO/wJP/UWvtckmOTnN3Lz07yrD58bJJz2uCqJLtX1T5JjkxyWWvtrtba3UkuS3JUn/ao1tqVrbWW5JyJZQEAAACwzOw6UjvPT/KOPrx3a+32JGmt3V5Ve/XyfZPcOjHP+l62qfL1U8ofoKrWZOg5le/+7u/+ZvmG0962dZ9mG614yX+fS7sAAAAA8zTzHlFV9ZAk/y3JOzdXdUpZ24ryBxa2dnprbVVrbdWKFSs2EwYAAAAAszDGpXlHJ7m2tXZHH7+jX1aX/n5nL1+fZP+J+fZLcttmyvebUg4AAADAMjRGIuoFuf+yvCS5OMnGJ9+tTnLRRPkJ/el5hyb5Ur+E79IkR1TVHv0m5UckubRP+3JVHdqflnfCxLIAAAAAWGZmeo+oqvqOJP93kv85UfyGJOdV1YuTfD7J8b38kiTHJFmX4Ql7JyZJa+2uqnptkqt7vde01u7qwy9JclaS3ZK8t78AAAAAWIZmmohqrd2T5DELyr6Q4Sl6C+u2JCctspwzk5w5pXxtkidsl2ABAAAAmKkxLs0DAAAAAIkoAAAAAMYhEQUAAADAKCSiAAAAABiFRBQAAAAAo5CIAgAAAGAUElEAAAAAjEIiCgAAAIBRSEQBAAAAMAqJKAAAAABGIREFAAAAwCgkogAAAAAYhUQUAAAAAKOQiAIAAABgFBJRAAAAAIxCIgoAAACAUUhEAQAAADAKiSgAAAAARiERBQAAAMAoJKIAAAAAGIVEFAAAAACjkIgCAAAAYBQSUQAAAACMQiIKAAAAgFFIRAEAAAAwCokoAAAAAEYhEQUAAADAKCSiAAAAABjFTBNRVbV7VZ1fVZ+qqk9W1VOqas+quqyqbu7ve/S6VVWnVtW6qrq+qp40sZzVvf7NVbV6ovzgqrqhz3NqVdUsPw8AAAAAW2/WPaL+OMn7WmuPT/IjST6Z5JVJLm+tHZDk8j6eJEcnOaC/1iQ5LUmqas8kJyd5cpJDkpy8MXnV66yZmO+oGX8eAAAAALbSzBJRVfWoJD+R5M1J0lr7emvti0mOTXJ2r3Z2kmf14WOTnNMGVyXZvar2SXJkkstaa3e11u5OclmSo/q0R7XWrmyttSTnTCwLAAAAgGVmlj2ivifJhiRvqaqPVdUZVfXwJHu31m5Pkv6+V6+/b5JbJ+Zf38s2Vb5+SvkDVNWaqlpbVWs3bNiw7Z8MAAAAgC02y0TUrkmelOS01toTk/x77r8Mb5pp93dqW1H+wMLWTm+trWqtrVqxYsWmowYAAABgJmaZiFqfZH1r7SN9/PwMiak7+mV16e93TtTff2L+/ZLctpny/aaUAwAAALAMzSwR1Vr7lyS3VtX396LDk3wiycVJNj75bnWSi/rwxUlO6E/POzTJl/qle5cmOaKq9ug3KT8iyaV92per6tD+tLwTJpYFAAAAwDKz64yX/ytJ3l5VD0nymSQnZkh+nVdVL07y+STH97qXJDkmybok9/S6aa3dVVWvTXJ1r/ea1tpdffglSc5KsluS9/YXAAAAAMvQTBNRrbXrkqyaMunwKXVbkpMWWc6ZSc6cUr42yRO2MUwAAAAARjDLe0QBAAAAwDdJRAEAAAAwCokoAAAAAEYhEQUAAADAKCSiAAAAABiFRBQAAAAAo5CIAgAAAGAUElEAAAAAjEIiCgAAAIBRSEQBAAAAMAqJKAAAAABGIREFAAAAwCgkogAAAAAYhUQUAAAAAKOQiAIAAABgFBJRAAAAAIxCIgoAAACAUUhEAQAAADAKiSgAAAAARiERBQAAAMAoJKIAAAAAGIVEFAAAAACjkIgCAAAAYBQSUQAAAACMQiIKAAAAgFFIRAEAAAAwCokoAAAAAEYhEQUAAADAKGaaiKqqW6rqhqq6rqrW9rI9q+qyqrq5v+/Ry6uqTq2qdVV1fVU9aWI5q3v9m6tq9UT5wX356/q8NcvPAwAAAMDWG6NH1NNbawe11lb18Vcmuby1dkCSy/t4khyd5ID+WpPktGRIXCU5OcmTkxyS5OSNyateZ83EfEfN/uMAAAAAsDXmcWnesUnO7sNnJ3nWRPk5bXBVkt2rap8kRya5rLV2V2vt7iSXJTmqT3tUa+3K1lpLcs7EsgAAAABYZmadiGpJ/raqrqmqNb1s79ba7UnS3/fq5fsmuXVi3vW9bFPl66eUP0BVramqtVW1dsOGDdv4kQAAAADYGrvOePlPba3dVlV7Jbmsqj61ibrT7u/UtqL8gYWtnZ7k9CRZtWrV1DoAAAAAzNZMe0S11m7r73cmuTDDPZ7u6JfVpb/f2auvT7L/xOz7JbltM+X7TSkHAAAAYBmaWSKqqh5eVY/cOJzkiCQ3Jrk4ycYn361OclEfvjjJCf3peYcm+VK/dO/SJEdU1R79JuVHJLm0T/tyVR3an5Z3wsSyAAAAAFhmZnlp3t5JLhxyRNk1yV+21t5XVVcnOa+qXpzk80mO7/UvSXJMknVJ7klyYpK01u6qqtcmubrXe01r7a4+/JIkZyXZLcl7+wsAAACAZWhmiajW2meS/MiU8i8kOXxKeUty0iLLOjPJmVPK1yZ5wjYHCwAAAMDMzfqpeQAAAACQRCIKAAAAgJFIRAEAAAAwCokoAAAAAEYhEQUAAADAKCSiAAAAABiFRBQAAAAAo5CIAgAAAGAUElEAAAAAjEIiCgAAAIBRSEQBAAAAMAqJKAAAAABGIREFAAAAwCgkogAAAAAYhUQUAAAAAKOQiAIAAABgFBJRAAAAAIxCIgoAAACAUUhEAQAAADAKiSgAAAAARiERBQAAAMAoJKIAAAAAGIVEFAAAAACjkIgCAAAAYBQSUQAAAACMQiIKAAAAgFFIRAEAAAAwCokoAAAAAEax66wbqKpdkqxN8s+ttWdW1eOSnJtkzyTXJvm51trXq+qhSc5JcnCSLyR5Xmvtlr6MVyV5cZL7kry0tXZpLz8qyR8n2SXJGa21N8z688zanX926lza3esXXzqXdgEAAIBvH2P0iHpZkk9OjP9+klNaawckuTtDgin9/e7W2vclOaXXS1UdmOT5SX4wyVFJ/rSqdukJrjclOTrJgUle0OsCAAAAsAwtKRFVVU9dStmUOvsl+akkZ/TxSvKMJOf3KmcneVYfPraPp08/vNc/Nsm5rbWvtdY+m2RdkkP6a11r7TOtta9n6GV17FI+DwAAAADjW2qPqD9ZYtlCb0zym0m+0ccfk+SLrbV7+/j6JPv24X2T3JokffqXev1vli+YZ7HyB6iqNVW1tqrWbtiwYQlhAwAAALC9bfIeUVX1lCQ/lmRFVf3axKRHZbgv06bmfWaSO1tr11TVYRuLp1Rtm5m2WPm0JFqbUpbW2ulJTk+SVatWTa0DAAAAwGxt7mblD0nyiF7vkRPl/5bkuM3M+9Qk/62qjknysAzJqzcm2b2qdu29nvZLcluvvz7J/knWV9WuSR6d5K6J8o0m51msHAAAAIBlZpOJqNbaB5N8sKrOaq19bksW3Fp7VZJXJUnvEfWK1toLq+qdGZJY5yZZneSiPsvFffzKPv39rbVWVRcn+cuq+qMk35XkgCQfzdBT6oD+FL5/znBD85/dkhgBAAAAGM/mekRt9NCqOj3Jysl5WmvP2Io2/1eSc6vqdUk+luTNvfzNSd5aVesy9IR6fm/jpqo6L8knktyb5KTW2n1JUlW/nOTSDJcJntlau2kr4gEAAABgBEtNRL0zyZ9lePrdfVvaSGvtiiRX9OHPZHji3cI6X01y/CLzvz7J66eUX5Lkki2NBwAAAIDxLTURdW9r7bSZRgIAAADATm3ak+em+Zuq+qWq2qeq9tz4mmlkAAAAAOxUltojanV//42Jspbke7ZvOAAAAADsrJaUiGqtPW7WgQAAAACwc1tSIqqqTphW3lo7Z/uGAwAAAMDOaqmX5v3oxPDDkhye5NokElEAAAAALMlSL837lcnxqnp0krfOJCIAAAAAdkpLfWreQvckOWB7BgIAAADAzm2p94j6mwxPyUuSXZL8QJLzZhUUAAAAADufpd4j6g8nhu9N8rnW2voZxAMAAADATmpJl+a11j6Y5FNJHplkjyRfn2VQAAAAAOx8lpSIqqrnJvlokuOTPDfJR6rquFkGBgAAAMDOZamX5v12kh9trd2ZJFW1Isn/l+T8WQUGAAAAwM5lqU/Ne9DGJFT3hS2YFwAAAACW3CPqfVV1aZJ39PHnJblkNiEBAAAAsDPaZCKqqr4vyd6ttd+oquckeVqSSnJlkrePEB8AAAAAO4nNXV73xiRfTpLW2rtaa7/WWvvVDL2h3jjr4AAAAADYeWwuEbWytXb9wsLW2tokK2cSEQAAAAA7pc0loh62iWm7bc9AAAAAANi5bS4RdXVV/cLCwqp6cZJrZhMSAAAAADujzT017+VJLqyqF+b+xNOqJA9J8uxZBgYAAADAzmWTiajW2h1Jfqyqnp7kCb34Pa219888MgAAAAB2KpvrEZUkaa19IMkHZhwLy9htb/q10dv8rpP+aPQ2AQAAgNnZ3D2iAAAAAGC7kIgCAAAAYBRLujQPlqNPvenYubT7+JMumku7AAAAsKPTIwoAAACAUUhEAQAAADCKmSWiquphVfXRqvp4Vd1UVf+7lz+uqj5SVTdX1V9V1UN6+UP7+Lo+feXEsl7Vyz9dVUdOlB/Vy9ZV1Stn9VkAAAAA2Haz7BH1tSTPaK39SJKDkhxVVYcm+f0kp7TWDkhyd5IX9/ovTnJ3a+37kpzS66WqDkzy/CQ/mOSoJH9aVbtU1S5J3pTk6CQHJnlBrwsAAADAMjSzRFQbfKWPPri/WpJnJDm/l5+d5Fl9+Ng+nj798KqqXn5ua+1rrbXPJlmX5JD+Wtda+0xr7etJzu11AQAAAFiGZnqPqN5z6bokdya5LMk/Jflia+3eXmV9kn378L5Jbk2SPv1LSR4zWb5gnsXKp8WxpqrWVtXaDRs2bI+PBgAAAMAW2nWWC2+t3ZfkoKraPcmFSX5gWrX+XotMW6x8WhKtTSlLa+30JKcnyapVq6bWge3hytOfOZd2n7Lm3XNpFwAAALbEKE/Na619MckVSQ5NsntVbUyA7Zfktj68Psn+SdKnPzrJXZPlC+ZZrBwAAACAZWiWT81b0XtCpap2S/KTST6Z5ANJjuvVVie5qA9f3MfTp7+/tdZ6+fP7U/Uel+SAJB9NcnWSA/pT+B6S4YbmF8/q8wAAAACwbWZ5ad4+Sc7uT7d7UJLzWmvvrqpPJDm3ql6X5GNJ3tzrvznJW6tqXYaeUM9PktbaTVV1XpJPJLk3yUn9kr9U1S8nuTTJLknObK3dNMPPAwAAAMA2mFkiqrV2fZInTin/TIYn3i0s/2qS4xdZ1uuTvH5K+SVJLtnmYAEAAACYuVHuEQUAAAAAElEAAAAAjEIiCgAAAIBRSEQBAAAAMAqJKAAAAABGIREFAAAAwCgkogAAAAAYhUQUAAAAAKOQiAIAAABgFBJRAAAAAIxCIgoAAACAUUhEAQAAADAKiSgAAAAARiERBQAAAMAoJKIAAAAAGIVEFAAAAACjkIgCAAAAYBQSUQAAAACMQiIKAAAAgFFIRAEAAAAwCokoAAAAAEYhEQUAAADAKCSiAAAAABiFRBQAAAAAo9h13gEAs3Xpm4+ZS7tHvviSubQLAADA8qVHFAAAAACjkIgCAAAAYBQSUQAAAACMYmaJqKrav6o+UFWfrKqbquplvXzPqrqsqm7u73v08qqqU6tqXVVdX1VPmljW6l7/5qpaPVF+cFXd0Oc5tapqVp8HAAAAgG0zyx5R9yb59dbaDyQ5NMlJVXVgklcmuby1dkCSy/t4khyd5ID+WpPktGRIXCU5OcmTkxyS5OSNyateZ83EfEfN8PMAAAAAsA1mlohqrd3eWru2D385ySeT7Jvk2CRn92pnJ3lWHz42yTltcFWS3atqnyRHJrmstXZXa+3uJJclOapPe1Rr7crWWktyzsSyAAAAAFhmRrlHVFWtTPLEJB9Jsndr7fZkSFYl2atX2zfJrROzre9lmypfP6V8WvtrqmptVa3dsGHDtn4cAAAAALbCzBNRVfWIJBckeXlr7d82VXVKWduK8gcWtnZ6a21Va23VihUrNhcyAAAAADOw6ywXXlUPzpCEentr7V29+I6q2qe1dnu/vO7OXr4+yf4Ts++X5LZeftiC8it6+X5T6gPL3Plvmc/t3I478X1zaRcAAIDBLJ+aV0nenOSTrbU/mph0cZKNT75bneSiifIT+tPzDk3ypX7p3qVJjqiqPfpNyo9Icmmf9uWqOrS3dcLEsgAAAABYZmbZI+qpSX4uyQ1VdV0v+60kb0hyXlW9OMnnkxzfp12S5Jgk65Lck+TEJGmt3VVVr01yda/3mtbaXX34JUnOSrJbkvf2FwAAAADL0MwSUa21v8v0+zglyeFT6rckJy2yrDOTnDmlfG2SJ2xDmAAAAACMZJSn5gEAAACARBQAAAAAo5CIAgAAAGAUElEAAAAAjGKWT80D2KG85ewjRm/zxNV/O3qbAAAA86JHFAAAAACjkIgCAAAAYBQSUQAAAACMQiIKAAAAgFFIRAEAAAAwCokoAAAAAEYhEQUAAADAKCSiAAAAABjFrvMOAIDFnfr2I+fS7ktfeOlc2gUAAHZuekQBAAAAMAqJKAAAAABGIREFAAAAwCjcIwqALfLq8+Zz36pXP9d9qwAAYEcnEQXADu/EC4+aS7tvefb75tIuAADsqFyaBwAAAMAoJKIAAAAAGIVEFAAAAACjkIgCAAAAYBQSUQAAAACMwlPzAGAGjr7opLm0+95j37TJ6cdc+LqRIrnfJc/+ndHbBABgeZKIAgDm6qfedepc2n3Pc146l3YBAL6duTQPAAAAgFHoEQUAsMBPXXDGXNp9z8/8/KLTnnn+20eM5H7vPu6Fi0776fPfNWIk9/ub454zl3YBgG03s0RUVZ2Z5JlJ7mytPaGX7Znkr5KsTHJLkue21u6uqkryx0mOSXJPkhe11q7t86xOsvHmEq9rrZ3dyw9OclaS3ZJckuRlrbU2q88DAMCO4djz3zd6mxcdd9TobQLAjmiWl+adlWThL/Irk1zeWjsgyeV9PEmOTnJAf61JclryzcTVyUmenOSQJCdX1R59ntN63Y3z+fUHAAAAWMZm1iOqtfahqlq5oPjYJIf14bOTXJHkf/Xyc3qPpquqaveq2qfXvay1dleSVNVlSY6qqiuSPKq1dmUvPyfJs5K8d1afBwAAttazL/i7ubR74c88bS7tAsBixr5Z+d6ttduTpL/v1cv3TXLrRL31vWxT5eunlE9VVWuqam1Vrd2wYcM2fwgAAAAAttxyeWpeTSlrW1E+VWvt9NbaqtbaqhUrVmxliAAAAABsi7ETUXf0S+7S3+/s5euT7D9Rb78kt22mfL8p5QAAAAAsU2Mnoi5OsroPr05y0UT5CTU4NMmX+qV7lyY5oqr26DcpPyLJpX3al6vq0P7EvRMmlgUAAADAMjSzm5VX1Tsy3Gz8sVW1PsPT796Q5LyqenGSzyc5vle/JMkxSdYluSfJiUnSWrurql6b5Ope7zUbb1ye5CUZnsy3W4ablLtROQAAAMAyNsun5r1gkUmHT6nbkpy0yHLOTHLmlPK1SZ6wLTECAAAAMJ6ZJaIAAIDl6/gLrp9Lu+/8mR+eS7sALA/L5al5AAAAAOzk9IgCAACWhZdeeOtc2j312ftvvhIA24UeUQAAAACMQo8oAACARbzpwjvm0u5Jz957k9Pfdf6/jhTJ/Z5z3GNHbxPY+egRBQAAAMAo9IgCAABgm33g7Rvm0u7TX7hiLu0CW0ePKAAAAABGIREFAAAAwChcmgcAAMBO6WNn3DmXdp/483vNpV3YEUhEAQAAwEhueeO/zKXdlS//zkWn/csfrhsxkvt95yu+by7tMl8SUQAAAMCyc8cbrxm9zb1ffvDobX67kYgCAAAAWII7Tr1iLu3u/dLD5tLuLEhEAQAAAOyg7nzT38yl3b1O+umtms9T8wAAAAAYhUQUAAAAAKOQiAIAAABgFBJRAAAAAIxCIgoAAACAUUhEAQAAADAKiSgAAAAARiERBQAAAMAoJKIAAAAAGIVEFAAAAACjkIgCAAAAYBQSUQAAAACMQiIKAAAAgFHs8Imoqjqqqj5dVeuq6pXzjgcAAACA6XboRFRV7ZLkTUmOTnJgkhdU1YHzjQoAAACAaXboRFSSQ5Ksa619prX29STnJjl2zjEBAAAAMMWOnojaN8mtE+PrexkAAAAAy0y11uYdw1arquOTHNla+/k+/nNJDmmt/cqCemuSrOmj35/k09uh+ccm+dftsJztaTnGlCzPuMS0NGJauuUYl5iWRkxLtxzjEtPSiGnplmNcYloaMS3dcoxLTEsjpqVbjnHt7DH9l9bais1V2nU7NTYv65PsPzG+X5LbFlZqrZ2e5PTt2XBVrW2trdqey9xWyzGmZHnGJaalEdPSLce4xLQ0Ylq65RiXmJZGTEu3HOMS09KIaemWY1xiWhoxLd1yjEtMgx390ryrkxxQVY+rqockeX6Si+ccEwAAAABT7NA9olpr91bVLye5NMkuSc5srd0057AAAAAAmGKHTkQlSWvtkiSXzKHp7Xqp33ayHGNKlmdcYloaMS3dcoxLTEsjpqVbjnGJaWnEtHTLMS4xLY2Ylm45xiWmpRHT0i3HuMSUHfxm5QAAAADsOHb0e0QBAAAAsIOQiAIAAABgFBJRi6iq3avql/rwYVX17nnHtNBkjDuqqvrKvGNYLpbTuqiqf+jvK6vqZ5dLPMtdVb20qj5ZVW//dmh3ShxL2m9W1RlVdeC40W1fVfWiqvqurZhvm35btrbdbVFVl/S4v+U3Z16/jTvK/mBequoxVXVdf/1LVf3zxPiRC+q+vKr+dF6xsvz03/0b5x3H9lRVV1TVqj58S1U9dgZtbNF66/vPH9vecfRlL7YP+GJVfWIWbc7SmL97O+P2D5uy8fxzHud8ElGL2z3Jck/y7AgxsgNqrW08OFqZZO6JqIl4lrtfSnJMa+2Fy7XdqprlQyqWtE9qrf18a22HOxhe4EVJtubAeFv321vb7lZrrR3TWvtilslvzg60P5iL1toXWmsHtdYOSvJnSU7pw6clef6C6s9P8o6xYwRyWJKZ7Ms2sQ84KMk3ZtHmjL0oI//u7Siqapd5x7CYGsg17DhWZuRzPhvH4t6Q5Hur6rokf5DkEVV1flV9qqreXlWVJFV1cFV9sKquqapLq2qfecRYVX/QXzdW1Q1V9byxgqiqv+6f/6aqWtPLvlJVr6+qj1fVVVW1dy9/XFVdWVVXV9Vrx4pxU7HyQBO9s96Q5Mf7Nvar846nqvapqg/1eG6sqh+fY0y/1mO4sfcq+LMk35Pk4jHX1YJ2f71v49f3v7sf7nVeXVWnV9XfJjlnhuEsdb95RVWtqqpdquqsif3WVq+3/p+cT9XQ2+rG3t5PVtXfV9XNVXVIVe25ifXzioll3diXt7KGnmZ/0fcZf1tVu1XVcUlWJXl73xZ3m8E6+n/6fvLG/t3VNra7qXX3m1X10j58SlW9vw8fXlVvq/t7EHzLb06ffWr8szSxPzisb0ujtj8lnoX7gqnbzdhxTXF+kmdW1UOT4W8mw8nd382isSVsV6dV1dq+jv73xHxvqKpP9L/TP5xBXK+tqpdNjL++ql5WU46hakGvv6r6P1X1ou0d08Tyl7Ifu7mqVvT6D6qqdbX9e/jsMmW/9wt9n/Txqrqgqr6jqh7d9w8P6vF8R1XdWlUPrqrvrar31XDM9eGqevy2BrW129SIdq2qs/u2e35fH9/sgVXD794V/W/vF5P8at+fjnks84Dvtse23b+vxSy2j6yqg2r4bb6+qi6sqj1qRr97mzHte5zL+V4tfo71mqr6SJKnzDq2qvr9+tbe0K+u4XjzN/o+4fqNf28T3+2fJrk2ye9W1SkT8/5CVf3R9oxvSrzfss5qOx5rbmU8D6+q9/R9541V9by+z/pYj+fM6r/Lczb+OV9rzWvKK0NW8MY+fFiSLyXZL0Py7sokT0vy4CT/kGRFr/e8JGfOKcafSXJZkl2S7J3k80n2GSmOPfv7bkluTPKYJC3JT/fy/zfJ7/Thi5Oc0IdPSvKVkb/XB8Q6721tIrZR18VSYunb/ruXUTy/nuS3+/AuSR45p3gOTnJDkocneUSSm5I8McktSR47h3huSfLYJH+S5ORe9owk1/XhVye5JsluM45js/vNPu2KDAeWBye5bGL+3bex7XuT/FBv75okZyapJMcm+evNrJ9XTCzrxr68jcs8qJefl+S/T36GGa6jPSfmeesNV+hRAAAK3ElEQVTE/nSr2t1MTIcmeWcf/nCSj2b4fTs5yf+c2L6+Gfvm4p/xdvaVeba/IJbF9gVTt5uxX1O27fckObYPvzLJH8yw7c1tVxt/j3fp2/UPJ9kzyadz/1Odt3qfsIm4Via5tg8/KMk/ZZFjqCz4DUzyf5K8aIbrbOM+Z1P7sZOTvLzXPyLJBTOK4Vu230wcLyV5XZJf6cMXJXl6H35ekjP68OVJDujDT07y/nlsU338ivT9Zmb0O93XW0vy1D5+ZpJXTLaX4Xfvij78LX+bM9ymvtnOYt/trL6vrdjGrk/yX3vZa5K8ceH3N8L6mvY9/kbmdL6Xxc+xntvLZ34umuE37YMT459IckKS0zPsmx6U5N1JfqKvv28kObTXfXiGfeyD+/g/JPmhkdfZdjvW3Mp4fibJX0yMPzrJrUn+rz5+Tvo+fR6vzPGcT4+opftoa219a+0bSa7L8If2/UmekOSyGv67/TsZDojn4WlJ3tFau6+1dkeSDyb50ZHafmlVfTzJVUn2T3JAkq9n2Cklw4HUyj781Nx/GcBbR4pv0rRY2XFcneTEqnp1hh+yL88pjqclubC19u+tta8keVeSufXOmvC09L+r1tr7kzymqh7dp13cWvuPkeOZtt+c9Jkk31NVf1JVRyX5t21s77OttRt6ezclubwNv6439LY3tX42tczr+vDkvmx7WWwdPb2qPlJVN2RImv3gdm530jVJDq6qRyb5WoaEzqoM2/SHNzPv5r7jWZt3+4vtC2a93Wytd+T+y/NmfVne5rar51bVtUk+lmH7PjDDPuCrSc6oquckuWd7B9VauyXJF6rqiRkSOR/LfI+hFtrcfuzMDCeBSfI/krxlRjEs3H6f0HvK3JDkhbl/n/RXGU5+k2Gb+quqekSGy87e2Y+P/zxDYm9bbc02NaZbW2t/34fflmG7Wm4e8N3O8Pvakji+N0OC4IO97OwMiY15WPg9Hpn5ne9NO2+5L8kFffrMz0Vbax9LsldVfVdV/UiSuzP842Dj/vPaJI/P/edUn2utXdXn/fck78/QG/fxGRJSN2zP+KZYuM4eku17rLmlbkjyk71n2Y9n2J9+trX2j336PLf1uZrlvUJ2Nl+bGL4vw7qrJDe11p4yn5C+xeiXIyRDt/UkP5nkKa21e6rqiiQPS/Kf/cApuX99bdQyB5uIlR1Ea+1DVfUTSX4qyVur6g9aa7O81Gwxc/l7W4JpcW38e/v3MQPppu03v6m1dnc/qDkyQw/J52Y4sdoe7X1jYvwbve17p8zTevnkP2Ym9wsLP8P2vizgAeuoqh6W5E8z/Af41p54ndm+qrX2n1V1S5ITM/y38vokT89wYvDJzcy+ye94BPNuf7F9way3m63110n+qKqelKGH5LWzamgz29V/ZOgt8qN9P3BWkoe11u6tqkOSHJ4hqfHLGRKx29sZGe47850ZEjtHLFJvU/uGWdnkfqzvE+6oqmdk6Lkyi3sSTtt+z0ryrNbax2u4PPGwPv3iJL9XVXtm6Hnw/gy9IL7YhvsSbTdbs01tz/aXEuKU8cltaDkcc077bh+UGXxfWxjH7iO2vTkLv8cvZw7ne5s4b/lqa+2+jdVGiu38JMdl2GeemyGZ8nuttT9fEPPKPPB484wkv5XkU5lN4nyy/cPywHX20CTb81hzi7TW/rGqDk5yTJLfS/K3Y7W93OkRtbgvJ3nkZup8OsmKqnpKktRwTfws/2u90GSMH0ryvH4d7IoMmdWPjhDDo5Pc3f/YH5+h2/Sm/H3u/2/s2Dd03tJYWdrfwWiq6r8kubO19hdJ3pzkSXMK5UNJntXvG/DwJM/O5nuOjOFD6X9X/cf4X1trY/7nZ4u2lxrum/Gg1toFSX43s/8+F1s/t2xsu5+gP24Jy9rav42lzLfxZOVf+3+qj9sO7W7OhzKcxH0ow7b8ixkuXZw8IF9W+4NlYrnuC6bqvbauyJB8GeMm5VO3qySPynCy8qUa7iF5dJL07f3RrbVLkrw8w82VZ+HCJEdl6PV0aRY/hvpckgOr6qG99+ThM4pnS52RoafGeRMnpLP2yCS3V9WDM3H81repjyb54wyXddzX96ufrarjk2/etPhHtlMcW7RNjey7N54TJHlBhvuv3ZIhQZcMl+hstGz2pzP+vpbqS0nurvvvl/VzGXomJuOvq4Xf41WZz/neUs5bxjoXPTfD+dtxGZJSlyb5H32fnarat6r2mjZja+0jGXom/Wxm/7szbZ2Nfaz5LWp44uM9rbW3JfnDDL0PV1bV9/Uqk9v6PI2+T9IjahGttS/UcHPIGzP8l+WOKXW+XsNN9E7tByi7Jnljhq7UY8f43gz/Gfp4hkz+b7bW/mWEMN6X5Ber6voMO8OrNlP/ZUn+soYbhV6wmbrb25bGyrBN3du7uJ7VWjtlczPM2GFJfqOq/jPJV3L/5Qmjaq1d2//bujHZe0Zr7WM1/n2SF3p1krf0bfyeJKvHbHwp+80F9s0Q78Z/irxqpgEuvn4uSHJC79Z+dZJ/nD77tzgryZ9V1X9k+M/bki57XOJvyxer6i8ydOe+pce0Te0uwYeT/HaSK1tr/15VX82ChMqU35z3bKe2d1jT9gUZLltYzt6R4RLChU/Qm4Wp21XvVfOxDMdLn8nwT6pkOAi+qPcKrCQzuWFqP377QIZeIPdV1YVJnpIpx1BVdV6G38KbM1yGshxcnKFnwUx7Fyzwu0k+kiE5d0O+9YTlr5K8M/f3kkqGZNVpVfU7Ge5jc26G9buttnSbGtMnk6yuqj/PsL2clmHf8Oaq+q0M62+jv0lyflUdm+F+W/NOYM/q+9oSqzP8vn1Hhu/wxF5+Vmbzu7eYhd/jn2RIvIx9vrfZ85axzkVbazfVcEnsP7fWbs+QlP6BJFf2Y9+vZLjP12KJ8fMy3BNs1r+P09bZvkmuGPFYc6EfSvIHVfWNJP+Z5CUZEmbvrOFJ1ldneLrlvI1+zrfxZpAAALDT6yck1yY5vrV287zj2VJVtSrJKa215XBvQoBNquHpo6e01i6fdywsHy7NAwDg20JVHZhkXYabgO+ISahXZujFOfZ/9QG2SFXtXlX/mOQ/JKFYSI8oAAAAAEahRxQAAAAAo5CIAgAAAGAUElEAAAAAjEIiCgBgB1ZVh/WnEgEALHsSUQAAO5Cq2mXeMQAAbC2JKACAkVTVb1bVS/vwKVX1/j58eFW9rapeUFU3VNWNVfX7E/N9papeU1UfSfKUqjqqqj5VVX+X5Dnz+TQAAFtOIgoAYDwfSvLjfXhVkkdU1YOTPC3JzUl+P8kzkhyU5Eer6lm97sOT3Nhae3KStUn+IslP92V953jhAwBsG4koAIDxXJPk4Kp6ZJKvJbkyQ0Lqx5N8MckVrbUNrbV7k7w9yU/0+e5LckEffnySz7bWbm6ttSRvG/MDAABsC4koAICRtNb+M8ktSU5M8g9JPpzk6Um+N8nnNzHrV1tr900ualYxAgDMkkQUAMC4PpTkFf39w0l+Mcl1Sa5K8l+r6rH9huQvSPLBKfN/Ksnjqup7+/gLZh8yAMD2IREFADCuDyfZJ8mVrbU7knw1yYdba7cneVWSDyT5eJJrW2sXLZy5tfbVJGuSvKffrPxzo0UOALCNari1AAAAAADMlh5RAAAAAIxCIgoAAACAUUhEAQAAADAKiSgAAAAARiERBQAAAMAoJKIAAAAAGIVEFAAAAACj+P8BC0du/a+8Dy4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq_words(list(df['reviewText']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text pre-processing\n",
    "\n",
    "#### Steps\n",
    "- treat each review as one document, clean up each document\n",
    "- remove/convert HTML tags (done)\n",
    "- expand the contractions (done)\n",
    "- handle misspelled words? (not implemented)\n",
    "- how about numbers, remove or keep?\n",
    "- convert to lowercase, i.e. normalize (done)\n",
    "- remove punctuation (done)\n",
    "- remove stopwords (done, notes: added 'tv', 'tvs', 'mount', 'wall') - need to automate \n",
    "- lemmatization (done, spacy lemmatizer)\n",
    "- remove stopwords again (done, notes: more stopwords generated after lemmatization)\n",
    "- remove numbers (done)\n",
    "\n",
    "#### Limitations and potential improvements\n",
    "- lemmatization is not perfect, \n",
    "  - e.g. 'tvs' is not converted to 'tv' -> stemming after lemmatization, map incorrect words back if any\n",
    "  - only keep postags: ['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "- add bigram phrases\n",
    "- spacing error e.g. \"this is great.Recommend to anyone\" -> insert empty space after \".\" in wordA.wordB pattern\n",
    "- special punctuation wordA...wordB...wordC, currently this becomes wordAwordBwordC -> replace \"..\" and \"...\" by \" \"\n",
    "- add part of speech tagging as a prep step (Q: necessary?)\n",
    "- Some steps may be simplified if using nltk tokenizers or other packages\n",
    "- Mis-spelled words -> correct them using fuzzy matching, or remove those words\n",
    "\n",
    "#### References\n",
    "- https://www.kdnuggets.com/2018/08/practitioners-guide-processing-understanding-text-2.html\n",
    "- https://machinelearningmastery.com/clean-text-machine-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for text cleaning and pre-processing\n",
    "\n",
    "def chk_has_html(rev_df,print_all=True):\n",
    "    # check for review text that has tags such as &#34;\n",
    "    # rev_df: e.g. df['reviewText']\n",
    "    html_num = defaultdict(int)\n",
    "    review_w_html = []\n",
    "    for idx, text in enumerate(rev_df):\n",
    "        strange_text = re.findall(r'&#\\d+;',text)\n",
    "        if len(strange_text) > 1:\n",
    "            for t in strange_text:\n",
    "                html_num[t] += 1\n",
    "            review_w_html.append(text)\n",
    "    \n",
    "    if print_all == True:\n",
    "        print(sorted(html_num.items(), key = lambda kv:(kv[1], kv[0]), reverse=True))     \n",
    "    return html_num\n",
    "\n",
    "def chk_html_num(rev_df,tag):\n",
    "    # prints reviews that contain the special HTML numbers specified by tag\n",
    "    # tag: HTML numbers with pattern r'&#\\d+;'\n",
    "    for idx, text in enumerate(rev_df):\n",
    "        if tag in text:\n",
    "            print(idx, text, '\\n')\n",
    "\n",
    "def convert_html(rev): \n",
    "    # replace the html tags by the corresponding symbol using HTML_MAP\n",
    "    html_entity = re.findall(r'&#\\d+;',rev)\n",
    "    rev_new = rev\n",
    "    if len(html_entity) > 0:\n",
    "        for t in html_entity:\n",
    "            rev_new = rev_new.replace(t,HTML_MAP[t])\n",
    "    return rev_new\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):    \n",
    "    # expand contractions. I'm -> I am. Aren't -> are not\n",
    "    # This is a simple version, see more elaborate version that considers word sense: https://pypi.org/project/pycontractions/\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    \n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "punc_char = set(string.punctuation)\n",
    "\n",
    "def remove_punctuation(rev):\n",
    "    # remove punctuation from the input string rev\n",
    "    return ''.join([ch for ch in rev if ch not in punc_char])\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['tv','tvs','wall','mount'])  \n",
    "\n",
    "def remove_stopwords(rev):\n",
    "    # rev is a review text, one string\n",
    "    rev_new = \" \".join([i for i in rev.split() if i not in stop_words])\n",
    "    return rev_new\n",
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(rev): \n",
    "    # lemmatize input string rev, i.e. reduce all forms of a word to the lemma\n",
    "    doc = nlp(\" \".join(rev.split()))\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "def lemmatization_tag(rev, tags = ['NOUN', 'ADJ']): # filter noun and adjective\n",
    "    doc = nlp(\" \".join(rev.split()))\n",
    "    return \" \".join([token.lemma_ for token in doc if token.pos_ in tags])\n",
    "\n",
    "def remove_num(s):\n",
    "    # s is a string, e.g. an entire review text\n",
    "    return ''.join([i for i in s if not i.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually remove HTML\n",
    "#chk_has_html(df['reviewText'])\n",
    "#chk_html_num(df['reviewText'], '&#8216;')\n",
    "# print(df['reviewText'][6436])\n",
    "# rev_new = convert_html(df['reviewText'][6436])\n",
    "\n",
    "# use beautiful soup to remove html entities\n",
    "# apply the function twice to completely strip off all the HTML entity numbers and tags\n",
    "# use .loc to avoid setting with copy warning: https://www.dataquest.io/blog/settingwithcopywarning/\n",
    "df.loc[:,'review_no_html'] = df['reviewText'].apply(remove_html_tags)\n",
    "df.loc[:,'review_no_html'] = df['review_no_html'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1293    Picked this up for our 26\" flat screen in the bedroom.  Super light, but feels very sturdy.  Nice array of positions.  Great price.What else is there to say?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "9886    THE GOOD: This is a mount with two huge shelves for DVD players, cable boxes etc. The title when I bought it made reference to 17-60 inch TV which is just plain wrong. This has nothing to do with mounting any TV, it is just two component shelves that looks just like the picture. This has to have the largest shelves I have ever seen and EXACTLY what I needed as my large Verizon cable box fit on it perfectly. I am sure if they corrected the title they would sell many more of these. Please see other reviews on this.THE BAD: The long metal wall plate shown in the instructions is replaced by a short metal plate maybe 1/3 the length with no explanation or note to that effect. So when you start looking at the instructions and parts you wonder where the bracket is and think it is missing. There is no new instruction for the small plate. The big plate had 7 holes,with 3 down the center. So if you wanted to mount this into a 2x4 stud you would use the center 3 holes. The short plate has 3 holes across the top and three across the bottom. So you can only use the center two to screw into the 2x4 as the outside ones would miss the ends of the stud. The screws are big so it should be OK and they are large and long. It appears two would be good enough, maybe. The outside ones would be likely right near the end of the stud so an anchor would hit the end and really not expand as expected. If you are not going into a stud you would use the outside 4 holes. But they are now closer together with all the weight on a smaller section of the wall.  When you are finished putting this whole thing together you will be surprised to learn the entire thing is held onto the bracket with two tiny connection screws facing down into a small top aluminum cover that rests on top of the tangs of the bracket that the screws go into. The bracket is strong so I do not feel it could bend or break. So considering the fact these two tiny screws and tangs hold this whole thing up, using two big screws to attach it to a stud now seems reasonable! The little screws are not to hold it up, but keep it against and on top of the bracket. The company who essentially is a wholesaler/drop-shipper has no number to call, though you can send a message to them, if you found them online as there is nothing in the instructions on contacting them. (google mount-it). Overall, I guess it is OK, but I would have been very happy with the original long bracket with three screws down the center. I took off 1 star for the smaller bracket and no mention it, some genus saved a little but weakened the installation somewhat. I found no other comparable product with as big shelves.Before you put it together (which is a juggling act) look at all the pieces very carefully and note how the four plastic gaskets fit into the back column sections and how these touch the pieces of glass and that there is a metal piece at on on top and on the bottom. Do some trial fittings. The instructions are not that great I REALLY suggest you do this with another person to help hold the numerous pieces together with you and do it on the floor not on a table as it possible for it to all fall apart as you are making it.Power cords may not fit in the column, but ones with thin ends do. My TV one won't, my set-top cable box does.Still it is a good product.  It is staying on my wall and seems solid with little chance the two little screws would get loose as the weight of everything presses against them and they are facing down.\n",
       "5862    I ordered Samsung's Touch Of Color T200HD 20-inch LCD HDTV Monitor for my son for Christmas.  He's a college student without a lot of room for bulky equipment; he's a techy guy, and a gamer.  But I knew he didn't have a lot of space, so also ordered this bracket, after another reviewer recommended it.  Not only does my son LOVE the HDTV/monitor, but the bracket was very easy for him to install, and simple to attach the Samsung to the wall.  He also said that the Samsung is watchable from a lot of angles, even being an LCD set and being attached to the wall.  This was a GREAT buy, and I'd highly recommend if you have one of these Samsungs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "8434    After a year of utilizing this product love it! Easy set up, sturdy, love the swivel and that you can pull it off the wall pretty far (makes for accessing inputs and outputs easily!).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "6639    This mount is great, simple, and straight forward. This is my second one. Installation is a breeze. I used my own anchors, but the kits does include some hardware and anchors for concrete. Would buy again and probably will have to eventually.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "Name: review_no_html, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_no_html'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10827    For the price I can't really complain. As other reviewers have mentioned it does bend down when you put weight on it, but once it settles it's solid. The rails seem a few millimeters too narrow, so some equipment had to be...coerced...into place. Overall it fit my need to set up a small rack in a computer closet for not a lot of money.                                                           \n",
      "10990    Works okay, wasn't quite what I expected, and won't line up with the studs (in the wall) on both left and right sides of the mount.  Appears to be made only to use with concrete anchors in brick walls.                                                                                                                                                                                                   \n",
      "635      Is a good looking and easy to install item. Strongly suggested. The price is great in comparisson with other similar items in the market.                                                                                                                                                                                                                                                                   \n",
      "8003     I love this mount. It was at least $35 cheaper than anything available in conventional stores but no less effective in mounting my 46\" TV. One problem this mount had, the level included on the mount is off slightly (ours was off about 1/4\"). But for the price I will deal with that minor inconvenience. Other than that the mount was extremely easy to install and looks fabulous in my living room.\n",
      "723      Although the box came all messed up, this product is still great! I used this for my new thin Samsung flat screen and it looks beautiful.I say you dont need the newest or most expensive mounts out there but Sanus does make really good mounts.                                                                                                                                                          \n",
      "Name: review_no_html, dtype: object\n",
      "\n",
      "\n",
      "10827    For the price I cannot really complain. As other reviewers have mentioned it does bend down when you put weight on it, but once it settles it is solid. The rails seem a few millimeters too narrow, so some equipment had to be...coerced...into place. Overall it fit my need to set up a small rack in a computer closet for not a lot of money.                                                         \n",
      "10990    Works okay, was not quite what I expected, and will not line up with the studs (in the wall) on both left and right sides of the mount.  Appears to be made only to use with concrete anchors in brick walls.                                                                                                                                                                                               \n",
      "635      Is a good looking and easy to install item. Strongly suggested. The price is great in comparisson with other similar items in the market.                                                                                                                                                                                                                                                                   \n",
      "8003     I love this mount. It was at least $35 cheaper than anything available in conventional stores but no less effective in mounting my 46\" TV. One problem this mount had, the level included on the mount is off slightly (ours was off about 1/4\"). But for the price I will deal with that minor inconvenience. Other than that the mount was extremely easy to install and looks fabulous in my living room.\n",
      "723      Although the box came all messed up, this product is still great! I used this for my new thin Samsung flat screen and it looks beautiful.I say you dont need the newest or most expensive mounts out there but Sanus does make really good mounts.                                                                                                                                                          \n",
      "Name: review_no_contraction, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# contraction expansion tests\n",
    "# expand_contractions(\"Y'all can't expand contractions I'd think\")\n",
    "# expand_contractions(\"I'd like to know how I'd done that! We're going to the zoo and I don't think I'll be home for dinner. \\\n",
    "#                     They're going to the zoo and she'll be home for dinner.\")\n",
    "df.loc[:,'review_no_contraction'] = df['review_no_html'].apply(expand_contractions)\n",
    "print(df['review_no_html'].sample(n=5, random_state = 0))\n",
    "print(\"\\n\")\n",
    "print(df['review_no_contraction'].sample(n=5, random_state = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'review_no_punc'] = [remove_punctuation(r) for r in df['review_no_contraction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'review_no_stopwords'] = [remove_stopwords(r.lower()) for r in df['review_no_punc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10827    For the price I can't really complain. As other reviewers have mentioned it does bend down when you put weight on it, but once it settles it's solid. The rails seem a few millimeters too narrow, so some equipment had to be...coerced...into place. Overall it fit my need to set up a small rack in a computer closet for not a lot of money.                                                           \n",
      "10990    Works okay, wasn't quite what I expected, and won't line up with the studs (in the wall) on both left and right sides of the mount.  Appears to be made only to use with concrete anchors in brick walls.                                                                                                                                                                                                   \n",
      "635      Is a good looking and easy to install item. Strongly suggested. The price is great in comparisson with other similar items in the market.                                                                                                                                                                                                                                                                   \n",
      "8003     I love this mount. It was at least $35 cheaper than anything available in conventional stores but no less effective in mounting my 46\" TV. One problem this mount had, the level included on the mount is off slightly (ours was off about 1/4\"). But for the price I will deal with that minor inconvenience. Other than that the mount was extremely easy to install and looks fabulous in my living room.\n",
      "723      Although the box came all messed up, this product is still great! I used this for my new thin Samsung flat screen and it looks beautiful.I say you dont need the newest or most expensive mounts out there but Sanus does make really good mounts.                                                                                                                                                          \n",
      "Name: reviewText, dtype: object \n",
      "\n",
      "10827    For the price I cannot really complain As other reviewers have mentioned it does bend down when you put weight on it but once it settles it is solid The rails seem a few millimeters too narrow so some equipment had to becoercedinto place Overall it fit my need to set up a small rack in a computer closet for not a lot of money                                                         \n",
      "10990    Works okay was not quite what I expected and will not line up with the studs in the wall on both left and right sides of the mount  Appears to be made only to use with concrete anchors in brick walls                                                                                                                                                                                         \n",
      "635      Is a good looking and easy to install item Strongly suggested The price is great in comparisson with other similar items in the market                                                                                                                                                                                                                                                          \n",
      "8003     I love this mount It was at least 35 cheaper than anything available in conventional stores but no less effective in mounting my 46 TV One problem this mount had the level included on the mount is off slightly ours was off about 14 But for the price I will deal with that minor inconvenience Other than that the mount was extremely easy to install and looks fabulous in my living room\n",
      "723      Although the box came all messed up this product is still great I used this for my new thin Samsung flat screen and it looks beautifulI say you dont need the newest or most expensive mounts out there but Sanus does make really good mounts                                                                                                                                                  \n",
      "Name: review_no_punc, dtype: object \n",
      "\n",
      "10827    price cannot really complain reviewers mentioned bend put weight settles solid rails seem millimeters narrow equipment becoercedinto place overall fit need set small rack computer closet lot money           \n",
      "10990    works okay quite expected line studs left right sides appears made use concrete anchors brick walls                                                                                                            \n",
      "635      good looking easy install item strongly suggested price great comparisson similar items market                                                                                                                 \n",
      "8003     love least 35 cheaper anything available conventional stores less effective mounting 46 one problem level included slightly 14 price deal minor inconvenience extremely easy install looks fabulous living room\n",
      "723      although box came messed product still great used new thin samsung flat screen looks beautifuli say dont need newest expensive mounts sanus make really good mounts                                            \n",
      "Name: review_no_stopwords, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df['reviewText'].sample(n=5, random_state = 0),'\\n')\n",
    "print(df['review_no_punc'].sample(n=5, random_state = 0),'\\n')\n",
    "print(df['review_no_stopwords'].sample(n=5, random_state = 0),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq_words(df['review_no_stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize, this is a relatively slow preprocessing step \n",
    "df.loc[:,'review_lemmatized'] = df['review_no_stopwords'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run remove stop words again because the lemmatization process generates more stop words\n",
    "df.loc[:,'review_lemmatized'] = df['review_lemmatized'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove numbers\n",
    "df.loc[:, 'review_lemmatized'] = df['review_lemmatized'].apply(remove_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10827    For the price I can't really complain. As other reviewers have mentioned it does bend down when you put weight on it, but once it settles it's solid. The rails seem a few millimeters too narrow, so some equipment had to be...coerced...into place. Overall it fit my need to set up a small rack in a computer closet for not a lot of money.\n",
      "10990    Works okay, wasn't quite what I expected, and won't line up with the studs (in the wall) on both left and right sides of the mount.  Appears to be made only to use with concrete anchors in brick walls.                                                                                                                                        \n",
      "635      Is a good looking and easy to install item. Strongly suggested. The price is great in comparisson with other similar items in the market.                                                                                                                                                                                                        \n",
      "Name: reviewText, dtype: object \n",
      "\n",
      "10827    price cannot really complain reviewers mentioned bend put weight settles solid rails seem millimeters narrow equipment becoercedinto place overall fit need set small rack computer closet lot money\n",
      "10990    works okay quite expected line studs left right sides appears made use concrete anchors brick walls                                                                                                 \n",
      "635      good looking easy install item strongly suggested price great comparisson similar items market                                                                                                      \n",
      "Name: review_no_stopwords, dtype: object \n",
      "\n",
      "10827    price really complain reviewer mention bend put weight settle solid rail seem millimeter narrow equipment becoercedinto place overall fit need set small rack computer closet lot money\n",
      "10990    work okay quite expect line stud leave right side appear make use concrete anchor brick                                                                                                \n",
      "635      good look easy install item strongly suggest price great comparisson similar item market                                                                                               \n",
      "Name: review_lemmatized, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df['reviewText'].sample(n=3, random_state = 0),'\\n')\n",
    "print(df['review_no_stopwords'].sample(n=3, random_state = 0),'\\n')\n",
    "print(df['review_lemmatized'].sample(n=3, random_state = 0),'\\n') \n",
    "# imperfect, e.g. changed needed to ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instal\n",
      "tv\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "print(porter.stem('installing'))\n",
    "print(porter.stem('tvs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq_words(df['review_lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['asin', 'reviewText', 'overall', 'summary', 'title', 'review_no_html',\n",
       "       'review_no_contraction', 'review_no_punc', 'review_no_stopwords',\n",
       "       'review_lemmatized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed review df for LDA modeling\n",
    "# remove html in 'title'\n",
    "# print(df.title[0:5])\n",
    "# df.loc[:,'title'] = df['title'].apply(remove_html_tags)\n",
    "# print(df.title[0:5])\n",
    "# df[['asin', 'title', 'overall', 'reviewText', 'review_no_html', 'review_lemmatized']].to_csv(select_cat[-1] + \"_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents 13119\n",
      "number of terms 5711\n",
      "2640 deduct\n",
      "4825 cancel\n",
      "3983 wake\n",
      "133 fluid\n",
      "4280 arrow\n",
      "1004 combination\n",
      "4259 active\n",
      "3344 redo\n",
      "2162 equipment\n",
      "3357 mancave\n"
     ]
    }
   ],
   "source": [
    "# useful attributes & methods: dictionary.token2id to get mapping, dictionary.num_docs \n",
    "df = pd.read_csv(select_cat[-1] + \"_processed.csv\", index_col= 0)\n",
    "reviews = df['review_lemmatized'].copy()\n",
    "reviews = reviews.apply(lambda x: x.split())\n",
    "\n",
    "# Dictionary expects a list of list (of tokens)\n",
    "dictionary = corpora.Dictionary(reviews)\n",
    "dictionary.filter_extremes(no_below=3)  # remove terms that appear in < 3 documents, memory use estimate: 8 bytes * num_terms * num_topics * 3\n",
    "\n",
    "# number of terms\n",
    "nd = dictionary.num_docs\n",
    "nt = len(dictionary.keys())\n",
    "print(\"number of documents\", nd)\n",
    "print(\"number of terms\", nt)\n",
    "\n",
    "# check some ids and tokens in the dictionary\n",
    "for i in random.sample(range(nt),10):\n",
    "    print(i, dictionary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13119\n",
      "['need', 'strong', 'sturdy', 'fold', 'almost', 'flat', 'enable', 'television', 'sit', 'square', 'flat', 'desire', 'extend', 'rotate', 'angle', 'turn', 'perfect', 'fit', 'long', 'match', 'correct', 'visa', 'pattern', 'television']\n",
      "[(5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1)]\n"
     ]
    }
   ],
   "source": [
    "# create document term matrix, it's a list of nd elements, nd = the number of documents\n",
    "# each element of DTM (AKA corpus) is a list of tuples (int, int) representing (word_index, frequency)\n",
    "DTM = [dictionary.doc2bow(doc) for doc in reviews]\n",
    "\n",
    "#spot check of DTM\n",
    "# use dictionary.token2id[token] to lookup the word_index for token, use dictionary[idx] to look up the token for idx\n",
    "print(len(DTM))\n",
    "print(reviews[1])\n",
    "print(DTM[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging  # add filename='lda_model.log' for external log file, set level = logging.ERROR or logging.INFO\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG) \n",
    "\n",
    "\n",
    "def train_lda_gensim(alpha0 = 'auto', eta0 = 'auto', n_topics = 10, passes0 = 10, iterations0 = 400, eval_every0 = 1):\n",
    "    LDA = gensim.models.ldamodel.LdaModel\n",
    "    lda_model = LDA(corpus=DTM, id2word=dictionary, num_topics=n_topics, alpha = alpha0, eta = eta0, passes = passes0, iterations = iterations0, eval_every = eval_every0)\n",
    "#     print(lda_model.alpha)\n",
    "#     print(max(lda_model.eta))\n",
    "#     print(min(lda_model.eta))\n",
    "#     print(np.mean(lda_model.eta))\n",
    "    pprint(lda_model.print_topics())\n",
    "    coherence_lda_model = CoherenceModel(model=lda_model, texts=reviews, dictionary=dictionary, coherence='c_v')\n",
    "    cs = coherence_lda_model.get_coherence()\n",
    "    print(\"model coherence score is:\", cs)\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis = pyLDAvis.gensim.prepare(lda_model, DTM, dictionary)\n",
    "    return lda_model, vis\n",
    "\n",
    "# Determine optimal number of topics k for LDA model (mallet implementation)\n",
    "def select_k_mallet(dictionary, corpus, texts, limit, start=3, step=2):\n",
    "    \"\"\"\n",
    "    Compute coherence for models with k number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for k in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=k, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "# Determine optimal number of topics k for LDA model (gensim implementation)\n",
    "def select_k(dictionary, corpus, texts, limit, start=3, step=2):\n",
    "    \"\"\"\n",
    "    Compute coherence for models with k number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for k in range(start, limit, step):\n",
    "        LDA = gensim.models.ldamodel.LdaModel\n",
    "        model = LDA(corpus=DTM, id2word=dictionary, num_topics=k, alpha = 'auto', eta = 'auto', passes = 10)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 12:51:58,234 : INFO : using autotuned alpha, starting with [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "2019-07-08 12:51:58,239 : INFO : using serial LDA version on this node\n",
      "2019-07-08 12:51:58,253 : INFO : running online (multi-pass) LDA training, 10 topics, 10 passes over the supplied corpus of 13119 documents, updating model once every 2000 documents, evaluating perplexity every 2000 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2019-07-08 12:51:58,268 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:52:08,468 : INFO : -9.407 per-word bound, 679.0 perplexity estimate based on a held-out corpus of 2000 documents with 76029 words\n",
      "2019-07-08 12:52:08,474 : INFO : PROGRESS: pass 0, at document #2000/13119\n",
      "2019-07-08 12:52:08,490 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:52:18,315 : DEBUG : 1887/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:52:18,349 : INFO : optimized alpha [0.06684677, 0.0721972, 0.094935335, 0.067766026, 0.07249256, 0.06487727, 0.068603694, 0.07251481, 0.06785738, 0.06719218]\n",
      "2019-07-08 12:52:18,352 : DEBUG : updating topics\n",
      "2019-07-08 12:52:18,360 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:52:18,376 : INFO : topic #5 (0.065): 0.016*\"use\" + 0.016*\"work\" + 0.014*\"great\" + 0.013*\"would\" + 0.012*\"buy\" + 0.012*\"one\" + 0.011*\"screw\" + 0.011*\"bracket\" + 0.011*\"monitor\" + 0.010*\"purchase\"\n",
      "2019-07-08 12:52:18,381 : INFO : topic #0 (0.067): 0.018*\"make\" + 0.017*\"screw\" + 0.012*\"use\" + 0.012*\"price\" + 0.012*\"one\" + 0.011*\"good\" + 0.011*\"stud\" + 0.010*\"would\" + 0.008*\"work\" + 0.008*\"level\"\n",
      "2019-07-08 12:52:18,387 : INFO : topic #7 (0.073): 0.016*\"use\" + 0.015*\"make\" + 0.015*\"monitor\" + 0.014*\"work\" + 0.014*\"good\" + 0.011*\"well\" + 0.010*\"one\" + 0.009*\"would\" + 0.009*\"buy\" + 0.008*\"hold\"\n",
      "2019-07-08 12:52:18,392 : INFO : topic #4 (0.072): 0.017*\"use\" + 0.015*\"one\" + 0.015*\"screw\" + 0.011*\"get\" + 0.010*\"need\" + 0.010*\"buy\" + 0.009*\"great\" + 0.008*\"easy\" + 0.008*\"hold\" + 0.008*\"install\"\n",
      "2019-07-08 12:52:18,395 : INFO : topic #2 (0.095): 0.015*\"one\" + 0.013*\"would\" + 0.013*\"screw\" + 0.011*\"buy\" + 0.010*\"get\" + 0.010*\"monitor\" + 0.009*\"bracket\" + 0.009*\"use\" + 0.009*\"arm\" + 0.008*\"work\"\n",
      "2019-07-08 12:52:18,399 : INFO : topic diff=8.819932, rho=1.000000\n",
      "2019-07-08 12:52:18,432 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:52:26,728 : INFO : -7.303 per-word bound, 157.9 perplexity estimate based on a held-out corpus of 2000 documents with 79013 words\n",
      "2019-07-08 12:52:26,730 : INFO : PROGRESS: pass 0, at document #4000/13119\n",
      "2019-07-08 12:52:26,734 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:52:32,605 : DEBUG : 1996/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:52:32,639 : INFO : optimized alpha [0.06408973, 0.0722291, 0.10156851, 0.06366121, 0.06909228, 0.06109568, 0.06657364, 0.068778075, 0.064128906, 0.06430166]\n",
      "2019-07-08 12:52:32,642 : DEBUG : updating topics\n",
      "2019-07-08 12:52:32,645 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:52:32,665 : INFO : topic #5 (0.061): 0.018*\"work\" + 0.016*\"great\" + 0.014*\"buy\" + 0.014*\"one\" + 0.014*\"use\" + 0.013*\"would\" + 0.011*\"purchase\" + 0.011*\"get\" + 0.009*\"easy\" + 0.009*\"install\"\n",
      "2019-07-08 12:52:32,670 : INFO : topic #3 (0.064): 0.027*\"easy\" + 0.020*\"install\" + 0.018*\"good\" + 0.018*\"product\" + 0.013*\"price\" + 0.012*\"look\" + 0.011*\"quality\" + 0.011*\"use\" + 0.011*\"screw\" + 0.010*\"sturdy\"\n",
      "2019-07-08 12:52:32,675 : INFO : topic #4 (0.069): 0.017*\"one\" + 0.015*\"use\" + 0.013*\"get\" + 0.013*\"level\" + 0.011*\"screw\" + 0.010*\"need\" + 0.009*\"buy\" + 0.009*\"great\" + 0.009*\"easy\" + 0.008*\"hold\"\n",
      "2019-07-08 12:52:32,680 : INFO : topic #1 (0.072): 0.029*\"easy\" + 0.021*\"install\" + 0.020*\"great\" + 0.015*\"use\" + 0.012*\"work\" + 0.012*\"would\" + 0.012*\"recommend\" + 0.011*\"price\" + 0.010*\"need\" + 0.009*\"sturdy\"\n",
      "2019-07-08 12:52:32,685 : INFO : topic #2 (0.102): 0.016*\"one\" + 0.014*\"would\" + 0.011*\"screw\" + 0.011*\"get\" + 0.009*\"arm\" + 0.009*\"bracket\" + 0.009*\"buy\" + 0.009*\"use\" + 0.008*\"go\" + 0.008*\"bolt\"\n",
      "2019-07-08 12:52:32,689 : INFO : topic diff=3.857842, rho=0.707107\n",
      "2019-07-08 12:52:32,718 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:52:39,781 : INFO : -7.103 per-word bound, 137.5 perplexity estimate based on a held-out corpus of 2000 documents with 75399 words\n",
      "2019-07-08 12:52:39,783 : INFO : PROGRESS: pass 0, at document #6000/13119\n",
      "2019-07-08 12:52:39,786 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:52:45,168 : DEBUG : 1999/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:52:45,204 : INFO : optimized alpha [0.06581954, 0.07458022, 0.10813237, 0.063077964, 0.066474274, 0.060237024, 0.064508915, 0.06544178, 0.061527066, 0.06279925]\n",
      "2019-07-08 12:52:45,207 : DEBUG : updating topics\n",
      "2019-07-08 12:52:45,209 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:52:45,222 : INFO : topic #5 (0.060): 0.020*\"work\" + 0.018*\"buy\" + 0.017*\"one\" + 0.016*\"great\" + 0.013*\"purchase\" + 0.013*\"use\" + 0.013*\"would\" + 0.011*\"get\" + 0.009*\"easy\" + 0.008*\"install\"\n",
      "2019-07-08 12:52:45,229 : INFO : topic #8 (0.062): 0.028*\"screw\" + 0.015*\"use\" + 0.013*\"one\" + 0.011*\"easy\" + 0.010*\"need\" + 0.010*\"stud\" + 0.010*\"would\" + 0.009*\"come\" + 0.008*\"great\" + 0.008*\"bracket\"\n",
      "2019-07-08 12:52:45,234 : INFO : topic #4 (0.066): 0.016*\"one\" + 0.016*\"level\" + 0.015*\"use\" + 0.014*\"get\" + 0.013*\"screw\" + 0.012*\"cable\" + 0.011*\"need\" + 0.009*\"buy\" + 0.009*\"hold\" + 0.008*\"easy\"\n",
      "2019-07-08 12:52:45,238 : INFO : topic #1 (0.075): 0.034*\"easy\" + 0.026*\"great\" + 0.024*\"install\" + 0.015*\"work\" + 0.015*\"price\" + 0.014*\"use\" + 0.013*\"would\" + 0.013*\"recommend\" + 0.010*\"need\" + 0.009*\"inch\"\n",
      "2019-07-08 12:52:45,242 : INFO : topic #2 (0.108): 0.016*\"one\" + 0.014*\"would\" + 0.013*\"screw\" + 0.011*\"get\" + 0.010*\"bracket\" + 0.009*\"use\" + 0.008*\"go\" + 0.008*\"buy\" + 0.008*\"bolt\" + 0.007*\"level\"\n",
      "2019-07-08 12:52:45,246 : INFO : topic diff=1.887977, rho=0.577350\n",
      "2019-07-08 12:52:45,280 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:52:51,463 : INFO : -7.002 per-word bound, 128.2 perplexity estimate based on a held-out corpus of 2000 documents with 73605 words\n",
      "2019-07-08 12:52:51,465 : INFO : PROGRESS: pass 0, at document #8000/13119\n",
      "2019-07-08 12:52:51,469 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:52:56,280 : DEBUG : 1999/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:52:56,320 : INFO : optimized alpha [0.06536028, 0.07799138, 0.1131512, 0.06354839, 0.065200925, 0.060782686, 0.06308862, 0.06433062, 0.060248274, 0.06214274]\n",
      "2019-07-08 12:52:56,322 : DEBUG : updating topics\n",
      "2019-07-08 12:52:56,325 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:52:56,338 : INFO : topic #8 (0.060): 0.030*\"screw\" + 0.017*\"use\" + 0.013*\"stud\" + 0.012*\"one\" + 0.011*\"need\" + 0.010*\"easy\" + 0.010*\"would\" + 0.008*\"bracket\" + 0.008*\"bolt\" + 0.008*\"inch\"\n",
      "2019-07-08 12:52:56,341 : INFO : topic #5 (0.061): 0.024*\"buy\" + 0.020*\"work\" + 0.019*\"one\" + 0.018*\"great\" + 0.014*\"purchase\" + 0.014*\"would\" + 0.012*\"use\" + 0.012*\"get\" + 0.008*\"cheetah\" + 0.008*\"good\"\n",
      "2019-07-08 12:52:56,347 : INFO : topic #0 (0.065): 0.019*\"cable\" + 0.017*\"price\" + 0.016*\"make\" + 0.016*\"hdmi\" + 0.014*\"good\" + 0.014*\"level\" + 0.012*\"one\" + 0.012*\"screw\" + 0.012*\"come\" + 0.012*\"work\"\n",
      "2019-07-08 12:52:56,363 : INFO : topic #1 (0.078): 0.036*\"easy\" + 0.030*\"great\" + 0.026*\"install\" + 0.017*\"work\" + 0.015*\"price\" + 0.015*\"recommend\" + 0.014*\"would\" + 0.013*\"use\" + 0.012*\"need\" + 0.011*\"inch\"\n",
      "2019-07-08 12:52:56,375 : INFO : topic #2 (0.113): 0.016*\"one\" + 0.014*\"would\" + 0.013*\"screw\" + 0.011*\"get\" + 0.011*\"bracket\" + 0.009*\"use\" + 0.008*\"bolt\" + 0.008*\"stud\" + 0.008*\"buy\" + 0.008*\"go\"\n",
      "2019-07-08 12:52:56,379 : INFO : topic diff=1.231881, rho=0.500000\n",
      "2019-07-08 12:52:56,416 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:53:03,057 : INFO : -7.158 per-word bound, 142.8 perplexity estimate based on a held-out corpus of 2000 documents with 85614 words\n",
      "2019-07-08 12:53:03,060 : INFO : PROGRESS: pass 0, at document #10000/13119\n",
      "2019-07-08 12:53:03,063 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:53:07,808 : DEBUG : 1998/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:53:07,837 : INFO : optimized alpha [0.06548626, 0.080662966, 0.12074627, 0.0646124, 0.065512255, 0.061380092, 0.06505654, 0.06612373, 0.060279883, 0.06247356]\n",
      "2019-07-08 12:53:07,839 : DEBUG : updating topics\n",
      "2019-07-08 12:53:07,847 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:53:07,858 : INFO : topic #8 (0.060): 0.031*\"screw\" + 0.016*\"use\" + 0.014*\"stud\" + 0.011*\"one\" + 0.011*\"need\" + 0.010*\"would\" + 0.009*\"easy\" + 0.009*\"bracket\" + 0.009*\"inch\" + 0.008*\"bolt\"\n",
      "2019-07-08 12:53:07,863 : INFO : topic #5 (0.061): 0.023*\"buy\" + 0.020*\"work\" + 0.019*\"one\" + 0.017*\"great\" + 0.014*\"purchase\" + 0.014*\"would\" + 0.012*\"get\" + 0.011*\"use\" + 0.009*\"good\" + 0.009*\"new\"\n",
      "2019-07-08 12:53:07,866 : INFO : topic #7 (0.066): 0.019*\"monitor\" + 0.016*\"work\" + 0.015*\"use\" + 0.013*\"well\" + 0.013*\"hold\" + 0.012*\"make\" + 0.011*\"good\" + 0.010*\"would\" + 0.009*\"one\" + 0.009*\"get\"\n",
      "2019-07-08 12:53:07,870 : INFO : topic #1 (0.081): 0.036*\"easy\" + 0.030*\"great\" + 0.026*\"install\" + 0.018*\"work\" + 0.015*\"recommend\" + 0.013*\"price\" + 0.013*\"would\" + 0.012*\"use\" + 0.011*\"need\" + 0.011*\"inch\"\n",
      "2019-07-08 12:53:07,874 : INFO : topic #2 (0.121): 0.015*\"one\" + 0.014*\"would\" + 0.011*\"screw\" + 0.011*\"bracket\" + 0.011*\"get\" + 0.008*\"stud\" + 0.008*\"go\" + 0.008*\"use\" + 0.008*\"back\" + 0.007*\"make\"\n",
      "2019-07-08 12:53:07,878 : INFO : topic diff=1.050205, rho=0.447214\n",
      "2019-07-08 12:53:07,917 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:53:13,309 : INFO : -7.104 per-word bound, 137.5 perplexity estimate based on a held-out corpus of 2000 documents with 69590 words\n",
      "2019-07-08 12:53:13,311 : INFO : PROGRESS: pass 0, at document #12000/13119\n",
      "2019-07-08 12:53:13,314 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:53:17,302 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:53:17,335 : INFO : optimized alpha [0.064792976, 0.083697185, 0.12540056, 0.06593306, 0.0652015, 0.061906375, 0.06563, 0.07049886, 0.060473915, 0.06176506]\n",
      "2019-07-08 12:53:17,337 : DEBUG : updating topics\n",
      "2019-07-08 12:53:17,339 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:53:17,358 : INFO : topic #8 (0.060): 0.035*\"screw\" + 0.019*\"use\" + 0.014*\"stud\" + 0.011*\"one\" + 0.011*\"need\" + 0.009*\"would\" + 0.009*\"inch\" + 0.009*\"bracket\" + 0.009*\"easy\" + 0.008*\"two\"\n",
      "2019-07-08 12:53:17,363 : INFO : topic #9 (0.062): 0.027*\"level\" + 0.022*\"use\" + 0.018*\"include\" + 0.017*\"stud\" + 0.014*\"need\" + 0.013*\"screw\" + 0.013*\"make\" + 0.010*\"drill\" + 0.010*\"bolt\" + 0.010*\"come\"\n",
      "2019-07-08 12:53:17,367 : INFO : topic #7 (0.070): 0.037*\"monitor\" + 0.018*\"work\" + 0.016*\"use\" + 0.013*\"well\" + 0.013*\"hold\" + 0.011*\"good\" + 0.011*\"make\" + 0.010*\"would\" + 0.010*\"desk\" + 0.009*\"one\"\n",
      "2019-07-08 12:53:17,372 : INFO : topic #1 (0.084): 0.038*\"easy\" + 0.032*\"great\" + 0.027*\"install\" + 0.021*\"work\" + 0.015*\"recommend\" + 0.014*\"price\" + 0.013*\"would\" + 0.013*\"use\" + 0.012*\"need\" + 0.011*\"inch\"\n",
      "2019-07-08 12:53:17,377 : INFO : topic #2 (0.125): 0.015*\"one\" + 0.015*\"would\" + 0.011*\"get\" + 0.011*\"screw\" + 0.010*\"bracket\" + 0.009*\"use\" + 0.008*\"go\" + 0.008*\"stud\" + 0.007*\"back\" + 0.007*\"make\"\n",
      "2019-07-08 12:53:17,381 : INFO : topic diff=0.680748, rho=0.408248\n",
      "2019-07-08 12:53:17,410 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:53:21,412 : INFO : -7.404 per-word bound, 169.3 perplexity estimate based on a held-out corpus of 1119 documents with 49461 words\n",
      "2019-07-08 12:53:21,415 : INFO : PROGRESS: pass 0, at document #13119/13119\n",
      "2019-07-08 12:53:21,418 : DEBUG : performing inference on a chunk of 1119 documents\n",
      "2019-07-08 12:53:24,302 : DEBUG : 1119/1119 documents converged within 400 iterations\n",
      "2019-07-08 12:53:24,320 : INFO : optimized alpha [0.06567674, 0.087316476, 0.13263956, 0.06731054, 0.06665239, 0.06396133, 0.06778705, 0.07363358, 0.06123787, 0.061884508]\n",
      "2019-07-08 12:53:24,326 : DEBUG : updating topics\n",
      "2019-07-08 12:53:24,339 : INFO : merging changes from 1119 documents into a model of 13119 documents\n",
      "2019-07-08 12:53:24,359 : INFO : topic #8 (0.061): 0.033*\"screw\" + 0.018*\"use\" + 0.013*\"stud\" + 0.010*\"need\" + 0.010*\"one\" + 0.009*\"would\" + 0.008*\"bracket\" + 0.008*\"easy\" + 0.008*\"inch\" + 0.008*\"two\"\n",
      "2019-07-08 12:53:24,366 : INFO : topic #9 (0.062): 0.026*\"level\" + 0.022*\"use\" + 0.017*\"stud\" + 0.017*\"include\" + 0.014*\"need\" + 0.013*\"make\" + 0.012*\"screw\" + 0.012*\"drill\" + 0.010*\"hole\" + 0.010*\"come\"\n",
      "2019-07-08 12:53:24,371 : INFO : topic #7 (0.074): 0.031*\"monitor\" + 0.016*\"work\" + 0.016*\"use\" + 0.013*\"hold\" + 0.013*\"well\" + 0.011*\"good\" + 0.011*\"stand\" + 0.010*\"would\" + 0.009*\"make\" + 0.009*\"get\"\n",
      "2019-07-08 12:53:24,374 : INFO : topic #1 (0.087): 0.038*\"easy\" + 0.031*\"great\" + 0.025*\"install\" + 0.021*\"work\" + 0.015*\"recommend\" + 0.014*\"use\" + 0.013*\"would\" + 0.012*\"inch\" + 0.012*\"price\" + 0.011*\"look\"\n",
      "2019-07-08 12:53:24,400 : INFO : topic #2 (0.133): 0.015*\"one\" + 0.015*\"would\" + 0.011*\"get\" + 0.010*\"bracket\" + 0.010*\"screw\" + 0.008*\"use\" + 0.008*\"go\" + 0.007*\"make\" + 0.007*\"back\" + 0.007*\"two\"\n",
      "2019-07-08 12:53:24,405 : INFO : topic diff=0.681162, rho=0.377964\n",
      "2019-07-08 12:53:24,462 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:53:30,524 : INFO : -6.840 per-word bound, 114.6 perplexity estimate based on a held-out corpus of 2000 documents with 76029 words\n",
      "2019-07-08 12:53:30,526 : INFO : PROGRESS: pass 1, at document #2000/13119\n",
      "2019-07-08 12:53:30,529 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:53:34,909 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:53:34,964 : INFO : optimized alpha [0.06300715, 0.08917466, 0.13161318, 0.067748025, 0.06518305, 0.06152808, 0.06520605, 0.07390944, 0.059545945, 0.06078403]\n",
      "2019-07-08 12:53:34,973 : DEBUG : updating topics\n",
      "2019-07-08 12:53:34,991 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:53:35,001 : INFO : topic #8 (0.060): 0.042*\"screw\" + 0.019*\"use\" + 0.014*\"stud\" + 0.011*\"need\" + 0.010*\"one\" + 0.009*\"would\" + 0.008*\"bracket\" + 0.008*\"inch\" + 0.008*\"two\" + 0.008*\"easy\"\n",
      "2019-07-08 12:53:35,008 : INFO : topic #9 (0.061): 0.027*\"level\" + 0.023*\"use\" + 0.018*\"stud\" + 0.017*\"include\" + 0.014*\"need\" + 0.014*\"screw\" + 0.014*\"make\" + 0.013*\"drill\" + 0.011*\"hole\" + 0.010*\"bolt\"\n",
      "2019-07-08 12:53:35,011 : INFO : topic #7 (0.074): 0.042*\"monitor\" + 0.017*\"use\" + 0.016*\"work\" + 0.013*\"hold\" + 0.013*\"well\" + 0.012*\"arm\" + 0.010*\"desk\" + 0.010*\"good\" + 0.010*\"make\" + 0.010*\"would\"\n",
      "2019-07-08 12:53:35,020 : INFO : topic #1 (0.089): 0.037*\"easy\" + 0.032*\"great\" + 0.026*\"install\" + 0.022*\"work\" + 0.015*\"recommend\" + 0.015*\"use\" + 0.013*\"would\" + 0.013*\"inch\" + 0.013*\"price\" + 0.011*\"need\"\n",
      "2019-07-08 12:53:35,031 : INFO : topic #2 (0.132): 0.015*\"one\" + 0.014*\"would\" + 0.011*\"bracket\" + 0.011*\"screw\" + 0.011*\"get\" + 0.008*\"go\" + 0.008*\"use\" + 0.007*\"make\" + 0.007*\"stud\" + 0.007*\"arm\"\n",
      "2019-07-08 12:53:35,044 : INFO : topic diff=0.410141, rho=0.341803\n",
      "2019-07-08 12:53:35,083 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:53:40,628 : INFO : -6.865 per-word bound, 116.6 perplexity estimate based on a held-out corpus of 2000 documents with 79013 words\n",
      "2019-07-08 12:53:40,630 : INFO : PROGRESS: pass 1, at document #4000/13119\n",
      "2019-07-08 12:53:40,633 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:53:44,758 : DEBUG : 1999/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:53:44,806 : INFO : optimized alpha [0.06226215, 0.093323156, 0.1349309, 0.06904946, 0.0648163, 0.060380753, 0.06482765, 0.07350275, 0.058640543, 0.06120796]\n",
      "2019-07-08 12:53:44,813 : DEBUG : updating topics\n",
      "2019-07-08 12:53:44,819 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:53:44,842 : INFO : topic #8 (0.059): 0.042*\"screw\" + 0.019*\"use\" + 0.014*\"stud\" + 0.011*\"need\" + 0.010*\"one\" + 0.008*\"would\" + 0.008*\"bracket\" + 0.008*\"inch\" + 0.007*\"easy\" + 0.007*\"two\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 12:53:44,851 : INFO : topic #5 (0.060): 0.024*\"antenna\" + 0.022*\"buy\" + 0.020*\"one\" + 0.019*\"work\" + 0.015*\"get\" + 0.015*\"great\" + 0.012*\"purchase\" + 0.011*\"would\" + 0.010*\"use\" + 0.009*\"good\"\n",
      "2019-07-08 12:53:44,854 : INFO : topic #7 (0.074): 0.040*\"monitor\" + 0.017*\"use\" + 0.015*\"work\" + 0.014*\"hold\" + 0.013*\"well\" + 0.013*\"arm\" + 0.011*\"move\" + 0.010*\"make\" + 0.010*\"good\" + 0.010*\"would\"\n",
      "2019-07-08 12:53:44,857 : INFO : topic #1 (0.093): 0.037*\"easy\" + 0.032*\"great\" + 0.026*\"install\" + 0.021*\"work\" + 0.015*\"recommend\" + 0.014*\"use\" + 0.013*\"would\" + 0.013*\"price\" + 0.013*\"inch\" + 0.012*\"need\"\n",
      "2019-07-08 12:53:44,859 : INFO : topic #2 (0.135): 0.016*\"one\" + 0.015*\"would\" + 0.011*\"get\" + 0.011*\"screw\" + 0.011*\"bracket\" + 0.008*\"go\" + 0.008*\"arm\" + 0.008*\"use\" + 0.007*\"stud\" + 0.007*\"make\"\n",
      "2019-07-08 12:53:44,867 : INFO : topic diff=0.356404, rho=0.341803\n",
      "2019-07-08 12:53:44,892 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:53:50,896 : INFO : -6.847 per-word bound, 115.1 perplexity estimate based on a held-out corpus of 2000 documents with 75399 words\n",
      "2019-07-08 12:53:50,898 : INFO : PROGRESS: pass 1, at document #6000/13119\n",
      "2019-07-08 12:53:50,918 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:53:54,709 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:53:54,765 : INFO : optimized alpha [0.06399858, 0.09631559, 0.13892046, 0.070692115, 0.06412725, 0.060301498, 0.06415651, 0.0713955, 0.058154095, 0.062437408]\n",
      "2019-07-08 12:53:54,767 : DEBUG : updating topics\n",
      "2019-07-08 12:53:54,776 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:53:54,797 : INFO : topic #8 (0.058): 0.046*\"screw\" + 0.019*\"use\" + 0.014*\"stud\" + 0.011*\"need\" + 0.010*\"one\" + 0.009*\"bracket\" + 0.008*\"inch\" + 0.008*\"would\" + 0.008*\"come\" + 0.008*\"bolt\"\n",
      "2019-07-08 12:53:54,801 : INFO : topic #5 (0.060): 0.023*\"buy\" + 0.022*\"one\" + 0.019*\"work\" + 0.016*\"antenna\" + 0.016*\"get\" + 0.014*\"great\" + 0.013*\"purchase\" + 0.011*\"would\" + 0.010*\"good\" + 0.010*\"new\"\n",
      "2019-07-08 12:53:54,804 : INFO : topic #7 (0.071): 0.038*\"monitor\" + 0.017*\"use\" + 0.016*\"work\" + 0.014*\"hold\" + 0.013*\"arm\" + 0.013*\"well\" + 0.011*\"good\" + 0.010*\"make\" + 0.010*\"move\" + 0.010*\"would\"\n",
      "2019-07-08 12:53:54,807 : INFO : topic #1 (0.096): 0.039*\"easy\" + 0.032*\"great\" + 0.027*\"install\" + 0.022*\"work\" + 0.015*\"recommend\" + 0.014*\"price\" + 0.014*\"would\" + 0.013*\"use\" + 0.013*\"inch\" + 0.012*\"need\"\n",
      "2019-07-08 12:53:54,816 : INFO : topic #2 (0.139): 0.016*\"one\" + 0.015*\"would\" + 0.012*\"screw\" + 0.012*\"get\" + 0.011*\"bracket\" + 0.008*\"go\" + 0.008*\"use\" + 0.007*\"make\" + 0.007*\"arm\" + 0.007*\"back\"\n",
      "2019-07-08 12:53:54,821 : INFO : topic diff=0.333612, rho=0.341803\n",
      "2019-07-08 12:53:54,860 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:53:59,967 : INFO : -6.830 per-word bound, 113.7 perplexity estimate based on a held-out corpus of 2000 documents with 73605 words\n",
      "2019-07-08 12:53:59,970 : INFO : PROGRESS: pass 1, at document #8000/13119\n",
      "2019-07-08 12:53:59,973 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:54:04,007 : DEBUG : 1998/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:54:04,073 : INFO : optimized alpha [0.06468081, 0.10133507, 0.14190164, 0.07257489, 0.06323326, 0.060687978, 0.063620046, 0.07072558, 0.057960283, 0.06358324]\n",
      "2019-07-08 12:54:04,075 : DEBUG : updating topics\n",
      "2019-07-08 12:54:04,085 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:54:04,107 : INFO : topic #8 (0.058): 0.048*\"screw\" + 0.019*\"use\" + 0.016*\"stud\" + 0.011*\"need\" + 0.010*\"one\" + 0.010*\"bracket\" + 0.009*\"inch\" + 0.008*\"would\" + 0.008*\"bolt\" + 0.007*\"come\"\n",
      "2019-07-08 12:54:04,110 : INFO : topic #5 (0.061): 0.027*\"buy\" + 0.024*\"one\" + 0.019*\"work\" + 0.016*\"get\" + 0.014*\"great\" + 0.013*\"purchase\" + 0.012*\"would\" + 0.011*\"antenna\" + 0.010*\"good\" + 0.010*\"new\"\n",
      "2019-07-08 12:54:04,131 : INFO : topic #3 (0.073): 0.035*\"good\" + 0.035*\"easy\" + 0.033*\"product\" + 0.031*\"price\" + 0.025*\"install\" + 0.021*\"great\" + 0.020*\"quality\" + 0.018*\"well\" + 0.015*\"look\" + 0.014*\"buy\"\n",
      "2019-07-08 12:54:04,135 : INFO : topic #1 (0.101): 0.038*\"easy\" + 0.033*\"great\" + 0.026*\"install\" + 0.022*\"work\" + 0.015*\"recommend\" + 0.014*\"would\" + 0.014*\"price\" + 0.014*\"inch\" + 0.013*\"use\" + 0.013*\"need\"\n",
      "2019-07-08 12:54:04,138 : INFO : topic #2 (0.142): 0.016*\"one\" + 0.014*\"would\" + 0.012*\"bracket\" + 0.012*\"get\" + 0.011*\"screw\" + 0.008*\"go\" + 0.008*\"use\" + 0.008*\"make\" + 0.007*\"stud\" + 0.007*\"bolt\"\n",
      "2019-07-08 12:54:04,140 : INFO : topic diff=0.313709, rho=0.341803\n",
      "2019-07-08 12:54:04,199 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:54:10,153 : INFO : -6.952 per-word bound, 123.8 perplexity estimate based on a held-out corpus of 2000 documents with 85614 words\n",
      "2019-07-08 12:54:10,155 : INFO : PROGRESS: pass 1, at document #10000/13119\n",
      "2019-07-08 12:54:10,161 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:54:14,511 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:54:14,570 : INFO : optimized alpha [0.06489738, 0.10489472, 0.14915162, 0.07466529, 0.063962534, 0.061289623, 0.06577015, 0.072293185, 0.058436114, 0.064640805]\n",
      "2019-07-08 12:54:14,585 : DEBUG : updating topics\n",
      "2019-07-08 12:54:14,593 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:54:14,603 : INFO : topic #8 (0.058): 0.047*\"screw\" + 0.019*\"use\" + 0.017*\"stud\" + 0.011*\"need\" + 0.010*\"bracket\" + 0.010*\"inch\" + 0.010*\"one\" + 0.008*\"would\" + 0.008*\"bolt\" + 0.007*\"hole\"\n",
      "2019-07-08 12:54:14,606 : INFO : topic #5 (0.061): 0.026*\"buy\" + 0.023*\"one\" + 0.018*\"work\" + 0.016*\"get\" + 0.014*\"purchase\" + 0.014*\"great\" + 0.012*\"new\" + 0.012*\"would\" + 0.010*\"good\" + 0.010*\"cheetah\"\n",
      "2019-07-08 12:54:14,610 : INFO : topic #3 (0.075): 0.036*\"good\" + 0.034*\"product\" + 0.033*\"easy\" + 0.031*\"price\" + 0.023*\"install\" + 0.022*\"great\" + 0.021*\"quality\" + 0.019*\"well\" + 0.016*\"look\" + 0.014*\"buy\"\n",
      "2019-07-08 12:54:14,617 : INFO : topic #1 (0.105): 0.038*\"easy\" + 0.033*\"great\" + 0.027*\"install\" + 0.022*\"work\" + 0.015*\"recommend\" + 0.015*\"inch\" + 0.014*\"would\" + 0.013*\"price\" + 0.012*\"need\" + 0.012*\"use\"\n",
      "2019-07-08 12:54:14,624 : INFO : topic #2 (0.149): 0.015*\"one\" + 0.015*\"would\" + 0.012*\"bracket\" + 0.011*\"get\" + 0.010*\"screw\" + 0.008*\"go\" + 0.008*\"make\" + 0.008*\"stud\" + 0.008*\"use\" + 0.008*\"back\"\n",
      "2019-07-08 12:54:14,629 : INFO : topic diff=0.330529, rho=0.341803\n",
      "2019-07-08 12:54:14,669 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:54:20,294 : INFO : -6.972 per-word bound, 125.5 perplexity estimate based on a held-out corpus of 2000 documents with 69590 words\n",
      "2019-07-08 12:54:20,296 : INFO : PROGRESS: pass 1, at document #12000/13119\n",
      "2019-07-08 12:54:20,299 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:54:23,859 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:54:23,914 : INFO : optimized alpha [0.06465681, 0.10790544, 0.15262027, 0.076719716, 0.06434035, 0.06142239, 0.06669728, 0.07662794, 0.059146643, 0.06454615]\n",
      "2019-07-08 12:54:23,937 : DEBUG : updating topics\n",
      "2019-07-08 12:54:23,940 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:54:23,960 : INFO : topic #8 (0.059): 0.050*\"screw\" + 0.021*\"use\" + 0.017*\"stud\" + 0.011*\"need\" + 0.010*\"inch\" + 0.009*\"one\" + 0.009*\"bracket\" + 0.008*\"would\" + 0.008*\"two\" + 0.007*\"bolt\"\n",
      "2019-07-08 12:54:23,967 : INFO : topic #5 (0.061): 0.027*\"buy\" + 0.023*\"one\" + 0.019*\"work\" + 0.015*\"get\" + 0.014*\"purchase\" + 0.013*\"new\" + 0.013*\"great\" + 0.012*\"would\" + 0.010*\"good\" + 0.009*\"use\"\n",
      "2019-07-08 12:54:23,970 : INFO : topic #3 (0.077): 0.037*\"good\" + 0.034*\"product\" + 0.033*\"easy\" + 0.033*\"price\" + 0.024*\"install\" + 0.023*\"great\" + 0.021*\"quality\" + 0.020*\"well\" + 0.015*\"look\" + 0.014*\"buy\"\n",
      "2019-07-08 12:54:23,972 : INFO : topic #1 (0.108): 0.038*\"easy\" + 0.033*\"great\" + 0.027*\"install\" + 0.024*\"work\" + 0.015*\"recommend\" + 0.014*\"inch\" + 0.014*\"would\" + 0.013*\"need\" + 0.013*\"use\" + 0.012*\"price\"\n",
      "2019-07-08 12:54:23,975 : INFO : topic #2 (0.153): 0.015*\"one\" + 0.015*\"would\" + 0.011*\"get\" + 0.011*\"bracket\" + 0.010*\"screw\" + 0.009*\"go\" + 0.008*\"use\" + 0.008*\"make\" + 0.007*\"back\" + 0.007*\"stud\"\n",
      "2019-07-08 12:54:23,978 : INFO : topic diff=0.298882, rho=0.341803\n",
      "2019-07-08 12:54:24,025 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:54:27,532 : INFO : -7.096 per-word bound, 136.8 perplexity estimate based on a held-out corpus of 1119 documents with 49461 words\n",
      "2019-07-08 12:54:27,551 : INFO : PROGRESS: pass 1, at document #13119/13119\n",
      "2019-07-08 12:54:27,559 : DEBUG : performing inference on a chunk of 1119 documents\n",
      "2019-07-08 12:54:29,546 : DEBUG : 1119/1119 documents converged within 400 iterations\n",
      "2019-07-08 12:54:29,567 : INFO : optimized alpha [0.06586029, 0.11161772, 0.15862727, 0.07890513, 0.066365466, 0.06343466, 0.06911266, 0.0792893, 0.05999794, 0.06506794]\n",
      "2019-07-08 12:54:29,583 : DEBUG : updating topics\n",
      "2019-07-08 12:54:29,593 : INFO : merging changes from 1119 documents into a model of 13119 documents\n",
      "2019-07-08 12:54:29,612 : INFO : topic #8 (0.060): 0.047*\"screw\" + 0.021*\"use\" + 0.016*\"stud\" + 0.011*\"need\" + 0.009*\"bracket\" + 0.009*\"one\" + 0.009*\"inch\" + 0.008*\"would\" + 0.007*\"bolt\" + 0.007*\"two\"\n",
      "2019-07-08 12:54:29,615 : INFO : topic #5 (0.063): 0.043*\"antenna\" + 0.021*\"channel\" + 0.020*\"one\" + 0.019*\"get\" + 0.018*\"buy\" + 0.017*\"work\" + 0.011*\"great\" + 0.011*\"mohu\" + 0.011*\"good\" + 0.010*\"purchase\"\n",
      "2019-07-08 12:54:29,618 : INFO : topic #7 (0.079): 0.038*\"monitor\" + 0.018*\"use\" + 0.016*\"work\" + 0.015*\"hold\" + 0.014*\"stand\" + 0.013*\"arm\" + 0.013*\"well\" + 0.011*\"move\" + 0.010*\"would\" + 0.009*\"good\"\n",
      "2019-07-08 12:54:29,628 : INFO : topic #1 (0.112): 0.038*\"easy\" + 0.031*\"great\" + 0.025*\"install\" + 0.024*\"work\" + 0.015*\"inch\" + 0.014*\"recommend\" + 0.014*\"use\" + 0.014*\"would\" + 0.012*\"need\" + 0.012*\"look\"\n",
      "2019-07-08 12:54:29,634 : INFO : topic #2 (0.159): 0.015*\"one\" + 0.015*\"would\" + 0.011*\"get\" + 0.010*\"bracket\" + 0.009*\"screw\" + 0.008*\"go\" + 0.008*\"make\" + 0.008*\"use\" + 0.007*\"two\" + 0.007*\"back\"\n",
      "2019-07-08 12:54:29,638 : INFO : topic diff=0.370978, rho=0.341803\n",
      "2019-07-08 12:54:29,680 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:54:35,936 : INFO : -6.817 per-word bound, 112.7 perplexity estimate based on a held-out corpus of 2000 documents with 76029 words\n",
      "2019-07-08 12:54:35,938 : INFO : PROGRESS: pass 2, at document #2000/13119\n",
      "2019-07-08 12:54:35,941 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:54:39,575 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:54:39,641 : INFO : optimized alpha [0.063874215, 0.1140025, 0.15777567, 0.0806717, 0.06591613, 0.06155422, 0.067367494, 0.08025976, 0.059340093, 0.06518986]\n",
      "2019-07-08 12:54:39,643 : DEBUG : updating topics\n",
      "2019-07-08 12:54:39,651 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:54:39,660 : INFO : topic #8 (0.059): 0.056*\"screw\" + 0.022*\"use\" + 0.016*\"stud\" + 0.011*\"need\" + 0.009*\"bracket\" + 0.009*\"inch\" + 0.009*\"one\" + 0.008*\"would\" + 0.008*\"head\" + 0.008*\"two\"\n",
      "2019-07-08 12:54:39,663 : INFO : topic #5 (0.062): 0.037*\"antenna\" + 0.020*\"one\" + 0.020*\"buy\" + 0.019*\"get\" + 0.018*\"channel\" + 0.017*\"work\" + 0.011*\"great\" + 0.011*\"good\" + 0.011*\"purchase\" + 0.010*\"new\"\n",
      "2019-07-08 12:54:39,666 : INFO : topic #3 (0.081): 0.037*\"good\" + 0.033*\"easy\" + 0.032*\"price\" + 0.031*\"product\" + 0.025*\"great\" + 0.023*\"install\" + 0.023*\"quality\" + 0.020*\"well\" + 0.017*\"look\" + 0.015*\"buy\"\n",
      "2019-07-08 12:54:39,669 : INFO : topic #1 (0.114): 0.037*\"easy\" + 0.032*\"great\" + 0.026*\"install\" + 0.024*\"work\" + 0.015*\"inch\" + 0.014*\"use\" + 0.014*\"recommend\" + 0.014*\"would\" + 0.012*\"need\" + 0.011*\"price\"\n",
      "2019-07-08 12:54:39,673 : INFO : topic #2 (0.158): 0.016*\"one\" + 0.015*\"would\" + 0.011*\"bracket\" + 0.011*\"get\" + 0.010*\"screw\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"use\" + 0.007*\"two\" + 0.007*\"back\"\n",
      "2019-07-08 12:54:39,682 : INFO : topic diff=0.315135, rho=0.323432\n",
      "2019-07-08 12:54:39,722 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:54:45,254 : INFO : -6.836 per-word bound, 114.3 perplexity estimate based on a held-out corpus of 2000 documents with 79013 words\n",
      "2019-07-08 12:54:45,258 : INFO : PROGRESS: pass 2, at document #4000/13119\n",
      "2019-07-08 12:54:45,261 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:54:48,663 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:54:48,727 : INFO : optimized alpha [0.06387753, 0.11924272, 0.16219051, 0.082985446, 0.06579977, 0.06055859, 0.0673327, 0.0807223, 0.058852285, 0.066536225]\n",
      "2019-07-08 12:54:48,735 : DEBUG : updating topics\n",
      "2019-07-08 12:54:48,744 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:54:48,753 : INFO : topic #8 (0.059): 0.056*\"screw\" + 0.022*\"use\" + 0.017*\"stud\" + 0.011*\"need\" + 0.009*\"bracket\" + 0.009*\"one\" + 0.009*\"inch\" + 0.008*\"would\" + 0.008*\"bolt\" + 0.008*\"head\"\n",
      "2019-07-08 12:54:48,756 : INFO : topic #5 (0.061): 0.029*\"antenna\" + 0.021*\"one\" + 0.020*\"buy\" + 0.019*\"get\" + 0.016*\"work\" + 0.014*\"channel\" + 0.011*\"great\" + 0.011*\"purchase\" + 0.011*\"new\" + 0.010*\"good\"\n",
      "2019-07-08 12:54:48,759 : INFO : topic #3 (0.083): 0.037*\"good\" + 0.033*\"easy\" + 0.033*\"price\" + 0.032*\"product\" + 0.025*\"great\" + 0.024*\"install\" + 0.023*\"quality\" + 0.020*\"well\" + 0.016*\"look\" + 0.015*\"buy\"\n",
      "2019-07-08 12:54:48,763 : INFO : topic #1 (0.119): 0.037*\"easy\" + 0.031*\"great\" + 0.026*\"install\" + 0.024*\"work\" + 0.015*\"inch\" + 0.014*\"use\" + 0.014*\"recommend\" + 0.013*\"would\" + 0.013*\"need\" + 0.011*\"sturdy\"\n",
      "2019-07-08 12:54:48,766 : INFO : topic #2 (0.162): 0.017*\"one\" + 0.015*\"would\" + 0.011*\"get\" + 0.011*\"bracket\" + 0.009*\"screw\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"arm\" + 0.007*\"back\" + 0.007*\"tilt\"\n",
      "2019-07-08 12:54:48,776 : INFO : topic diff=0.296524, rho=0.323432\n",
      "2019-07-08 12:54:48,810 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:54:54,049 : INFO : -6.822 per-word bound, 113.1 perplexity estimate based on a held-out corpus of 2000 documents with 75399 words\n",
      "2019-07-08 12:54:54,053 : INFO : PROGRESS: pass 2, at document #6000/13119\n",
      "2019-07-08 12:54:54,056 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:54:57,666 : DEBUG : 1999/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:54:57,723 : INFO : optimized alpha [0.06626963, 0.12248403, 0.16708101, 0.08553751, 0.06538104, 0.06042875, 0.06689607, 0.07849072, 0.05873338, 0.06835168]\n",
      "2019-07-08 12:54:57,728 : DEBUG : updating topics\n",
      "2019-07-08 12:54:57,737 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:54:57,757 : INFO : topic #8 (0.059): 0.061*\"screw\" + 0.021*\"use\" + 0.016*\"stud\" + 0.011*\"need\" + 0.010*\"bracket\" + 0.009*\"one\" + 0.009*\"inch\" + 0.008*\"long\" + 0.008*\"bolt\" + 0.008*\"would\"\n",
      "2019-07-08 12:54:57,760 : INFO : topic #5 (0.060): 0.023*\"one\" + 0.022*\"buy\" + 0.021*\"antenna\" + 0.019*\"get\" + 0.016*\"work\" + 0.012*\"purchase\" + 0.011*\"new\" + 0.011*\"good\" + 0.011*\"great\" + 0.010*\"channel\"\n",
      "2019-07-08 12:54:57,763 : INFO : topic #3 (0.086): 0.036*\"good\" + 0.035*\"easy\" + 0.034*\"price\" + 0.032*\"product\" + 0.027*\"great\" + 0.024*\"install\" + 0.022*\"quality\" + 0.019*\"well\" + 0.016*\"look\" + 0.016*\"buy\"\n",
      "2019-07-08 12:54:57,766 : INFO : topic #1 (0.122): 0.038*\"easy\" + 0.031*\"great\" + 0.026*\"install\" + 0.024*\"work\" + 0.015*\"inch\" + 0.014*\"would\" + 0.014*\"use\" + 0.013*\"recommend\" + 0.013*\"need\" + 0.012*\"price\"\n",
      "2019-07-08 12:54:57,769 : INFO : topic #2 (0.167): 0.017*\"one\" + 0.015*\"would\" + 0.012*\"get\" + 0.011*\"bracket\" + 0.010*\"screw\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"use\" + 0.007*\"back\"\n",
      "2019-07-08 12:54:57,773 : INFO : topic diff=0.293770, rho=0.323432\n",
      "2019-07-08 12:54:57,820 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:55:03,369 : INFO : -6.808 per-word bound, 112.0 perplexity estimate based on a held-out corpus of 2000 documents with 73605 words\n",
      "2019-07-08 12:55:03,371 : INFO : PROGRESS: pass 2, at document #8000/13119\n",
      "2019-07-08 12:55:03,378 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:55:06,886 : DEBUG : 1999/2000 documents converged within 400 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 12:55:06,937 : INFO : optimized alpha [0.06752664, 0.12820962, 0.17017755, 0.08861257, 0.064751066, 0.060622912, 0.066668734, 0.0780524, 0.058811266, 0.07005293]\n",
      "2019-07-08 12:55:06,951 : DEBUG : updating topics\n",
      "2019-07-08 12:55:06,961 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:55:06,974 : INFO : topic #8 (0.059): 0.061*\"screw\" + 0.022*\"use\" + 0.018*\"stud\" + 0.012*\"need\" + 0.010*\"bracket\" + 0.009*\"inch\" + 0.009*\"bolt\" + 0.009*\"one\" + 0.009*\"long\" + 0.008*\"would\"\n",
      "2019-07-08 12:55:06,989 : INFO : topic #5 (0.061): 0.024*\"buy\" + 0.024*\"one\" + 0.019*\"get\" + 0.016*\"work\" + 0.015*\"antenna\" + 0.012*\"purchase\" + 0.011*\"new\" + 0.011*\"cheetah\" + 0.011*\"good\" + 0.010*\"great\"\n",
      "2019-07-08 12:55:06,992 : INFO : topic #3 (0.089): 0.036*\"good\" + 0.036*\"price\" + 0.034*\"easy\" + 0.034*\"product\" + 0.028*\"great\" + 0.025*\"install\" + 0.022*\"quality\" + 0.019*\"well\" + 0.017*\"buy\" + 0.015*\"look\"\n",
      "2019-07-08 12:55:06,995 : INFO : topic #1 (0.128): 0.037*\"easy\" + 0.032*\"great\" + 0.025*\"install\" + 0.024*\"work\" + 0.016*\"inch\" + 0.014*\"would\" + 0.014*\"recommend\" + 0.013*\"need\" + 0.013*\"use\" + 0.012*\"price\"\n",
      "2019-07-08 12:55:06,999 : INFO : topic #2 (0.170): 0.016*\"one\" + 0.015*\"would\" + 0.012*\"get\" + 0.011*\"bracket\" + 0.010*\"screw\" + 0.008*\"go\" + 0.008*\"make\" + 0.007*\"tilt\" + 0.007*\"back\" + 0.007*\"use\"\n",
      "2019-07-08 12:55:07,002 : INFO : topic diff=0.288710, rho=0.323432\n",
      "2019-07-08 12:55:07,047 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:55:12,848 : INFO : -6.925 per-word bound, 121.6 perplexity estimate based on a held-out corpus of 2000 documents with 85614 words\n",
      "2019-07-08 12:55:12,857 : INFO : PROGRESS: pass 2, at document #10000/13119\n",
      "2019-07-08 12:55:12,867 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:55:16,964 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:55:17,010 : INFO : optimized alpha [0.06807242, 0.13119394, 0.1777224, 0.09122381, 0.06584541, 0.06106568, 0.06930441, 0.079788186, 0.059590723, 0.071600944]\n",
      "2019-07-08 12:55:17,012 : DEBUG : updating topics\n",
      "2019-07-08 12:55:17,033 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:55:17,045 : INFO : topic #8 (0.060): 0.059*\"screw\" + 0.021*\"use\" + 0.019*\"stud\" + 0.011*\"need\" + 0.011*\"bracket\" + 0.010*\"inch\" + 0.009*\"long\" + 0.008*\"one\" + 0.008*\"bolt\" + 0.008*\"would\"\n",
      "2019-07-08 12:55:17,053 : INFO : topic #5 (0.061): 0.024*\"buy\" + 0.023*\"one\" + 0.019*\"get\" + 0.016*\"work\" + 0.013*\"new\" + 0.013*\"purchase\" + 0.012*\"antenna\" + 0.011*\"cheetah\" + 0.011*\"customer\" + 0.011*\"good\"\n",
      "2019-07-08 12:55:17,058 : INFO : topic #3 (0.091): 0.037*\"good\" + 0.036*\"product\" + 0.035*\"price\" + 0.033*\"easy\" + 0.028*\"great\" + 0.023*\"quality\" + 0.023*\"install\" + 0.020*\"well\" + 0.016*\"buy\" + 0.016*\"look\"\n",
      "2019-07-08 12:55:17,061 : INFO : topic #1 (0.131): 0.036*\"easy\" + 0.031*\"great\" + 0.026*\"install\" + 0.024*\"work\" + 0.016*\"inch\" + 0.014*\"would\" + 0.014*\"recommend\" + 0.013*\"need\" + 0.013*\"use\" + 0.011*\"sturdy\"\n",
      "2019-07-08 12:55:17,073 : INFO : topic #2 (0.178): 0.016*\"one\" + 0.015*\"would\" + 0.012*\"get\" + 0.011*\"bracket\" + 0.009*\"screw\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"use\"\n",
      "2019-07-08 12:55:17,085 : INFO : topic diff=0.324096, rho=0.323432\n",
      "2019-07-08 12:55:17,125 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:55:21,929 : INFO : -6.948 per-word bound, 123.5 perplexity estimate based on a held-out corpus of 2000 documents with 69590 words\n",
      "2019-07-08 12:55:21,931 : INFO : PROGRESS: pass 2, at document #12000/13119\n",
      "2019-07-08 12:55:21,934 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:55:25,195 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:55:25,244 : INFO : optimized alpha [0.06803084, 0.1341612, 0.18068467, 0.09390824, 0.0666499, 0.061108746, 0.07061667, 0.0841882, 0.060629923, 0.0716886]\n",
      "2019-07-08 12:55:25,249 : DEBUG : updating topics\n",
      "2019-07-08 12:55:25,262 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:55:25,284 : INFO : topic #8 (0.061): 0.061*\"screw\" + 0.023*\"use\" + 0.019*\"stud\" + 0.011*\"need\" + 0.010*\"inch\" + 0.010*\"bracket\" + 0.010*\"long\" + 0.008*\"anchor\" + 0.008*\"one\" + 0.008*\"bolt\"\n",
      "2019-07-08 12:55:25,287 : INFO : topic #5 (0.061): 0.024*\"buy\" + 0.023*\"one\" + 0.018*\"get\" + 0.017*\"work\" + 0.015*\"new\" + 0.012*\"purchase\" + 0.011*\"antenna\" + 0.010*\"good\" + 0.010*\"would\" + 0.009*\"great\"\n",
      "2019-07-08 12:55:25,290 : INFO : topic #3 (0.094): 0.037*\"good\" + 0.036*\"price\" + 0.035*\"product\" + 0.033*\"easy\" + 0.029*\"great\" + 0.023*\"install\" + 0.022*\"quality\" + 0.021*\"well\" + 0.017*\"buy\" + 0.015*\"look\"\n",
      "2019-07-08 12:55:25,298 : INFO : topic #1 (0.134): 0.037*\"easy\" + 0.031*\"great\" + 0.026*\"install\" + 0.025*\"work\" + 0.016*\"inch\" + 0.014*\"would\" + 0.014*\"need\" + 0.013*\"use\" + 0.013*\"recommend\" + 0.011*\"tilt\"\n",
      "2019-07-08 12:55:25,304 : INFO : topic #2 (0.181): 0.016*\"one\" + 0.015*\"would\" + 0.012*\"get\" + 0.010*\"bracket\" + 0.009*\"go\" + 0.008*\"screw\" + 0.008*\"make\" + 0.007*\"back\" + 0.007*\"tilt\" + 0.007*\"use\"\n",
      "2019-07-08 12:55:25,310 : INFO : topic diff=0.288548, rho=0.323432\n",
      "2019-07-08 12:55:25,353 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:55:28,671 : INFO : -7.050 per-word bound, 132.5 perplexity estimate based on a held-out corpus of 1119 documents with 49461 words\n",
      "2019-07-08 12:55:28,673 : INFO : PROGRESS: pass 2, at document #13119/13119\n",
      "2019-07-08 12:55:28,696 : DEBUG : performing inference on a chunk of 1119 documents\n",
      "2019-07-08 12:55:30,761 : DEBUG : 1119/1119 documents converged within 400 iterations\n",
      "2019-07-08 12:55:30,780 : INFO : optimized alpha [0.06915284, 0.1372366, 0.18624769, 0.09622338, 0.0692015, 0.06305724, 0.073224425, 0.08670824, 0.061631262, 0.072217345]\n",
      "2019-07-08 12:55:30,784 : DEBUG : updating topics\n",
      "2019-07-08 12:55:30,787 : INFO : merging changes from 1119 documents into a model of 13119 documents\n",
      "2019-07-08 12:55:30,798 : INFO : topic #8 (0.062): 0.058*\"screw\" + 0.023*\"use\" + 0.017*\"stud\" + 0.011*\"need\" + 0.009*\"bracket\" + 0.009*\"long\" + 0.009*\"anchor\" + 0.009*\"inch\" + 0.008*\"bolt\" + 0.008*\"one\"\n",
      "2019-07-08 12:55:30,805 : INFO : topic #5 (0.063): 0.044*\"antenna\" + 0.023*\"channel\" + 0.022*\"get\" + 0.019*\"one\" + 0.016*\"buy\" + 0.014*\"work\" + 0.013*\"mohu\" + 0.011*\"good\" + 0.011*\"signal\" + 0.010*\"new\"\n",
      "2019-07-08 12:55:30,809 : INFO : topic #3 (0.096): 0.037*\"good\" + 0.035*\"price\" + 0.034*\"product\" + 0.034*\"easy\" + 0.029*\"great\" + 0.023*\"quality\" + 0.023*\"install\" + 0.021*\"well\" + 0.016*\"look\" + 0.016*\"buy\"\n",
      "2019-07-08 12:55:30,816 : INFO : topic #1 (0.137): 0.037*\"easy\" + 0.030*\"great\" + 0.025*\"work\" + 0.024*\"install\" + 0.017*\"inch\" + 0.014*\"use\" + 0.014*\"would\" + 0.013*\"recommend\" + 0.013*\"need\" + 0.011*\"hold\"\n",
      "2019-07-08 12:55:30,825 : INFO : topic #2 (0.186): 0.016*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.010*\"bracket\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"screw\" + 0.007*\"two\" + 0.007*\"use\" + 0.007*\"back\"\n",
      "2019-07-08 12:55:30,832 : INFO : topic diff=0.374281, rho=0.323432\n",
      "2019-07-08 12:55:30,875 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:55:36,377 : INFO : -6.809 per-word bound, 112.1 perplexity estimate based on a held-out corpus of 2000 documents with 76029 words\n",
      "2019-07-08 12:55:36,379 : INFO : PROGRESS: pass 3, at document #2000/13119\n",
      "2019-07-08 12:55:36,382 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:55:39,803 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:55:39,872 : INFO : optimized alpha [0.06768396, 0.13955912, 0.18641677, 0.09920098, 0.069334745, 0.06138468, 0.07176345, 0.08813097, 0.061381347, 0.07273878]\n",
      "2019-07-08 12:55:39,879 : DEBUG : updating topics\n",
      "2019-07-08 12:55:39,882 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:55:39,909 : INFO : topic #8 (0.061): 0.066*\"screw\" + 0.023*\"use\" + 0.017*\"stud\" + 0.011*\"need\" + 0.009*\"bracket\" + 0.009*\"head\" + 0.009*\"long\" + 0.008*\"inch\" + 0.008*\"strip\" + 0.008*\"bolt\"\n",
      "2019-07-08 12:55:39,912 : INFO : topic #5 (0.061): 0.040*\"antenna\" + 0.022*\"get\" + 0.020*\"channel\" + 0.020*\"one\" + 0.017*\"buy\" + 0.015*\"work\" + 0.011*\"mohu\" + 0.011*\"new\" + 0.011*\"good\" + 0.011*\"signal\"\n",
      "2019-07-08 12:55:39,914 : INFO : topic #3 (0.099): 0.037*\"good\" + 0.035*\"price\" + 0.033*\"product\" + 0.033*\"easy\" + 0.030*\"great\" + 0.025*\"quality\" + 0.023*\"install\" + 0.021*\"well\" + 0.018*\"buy\" + 0.016*\"look\"\n",
      "2019-07-08 12:55:39,917 : INFO : topic #1 (0.140): 0.036*\"easy\" + 0.030*\"great\" + 0.025*\"work\" + 0.025*\"install\" + 0.017*\"inch\" + 0.015*\"use\" + 0.013*\"would\" + 0.013*\"recommend\" + 0.013*\"need\" + 0.012*\"hold\"\n",
      "2019-07-08 12:55:39,923 : INFO : topic #2 (0.186): 0.016*\"one\" + 0.015*\"would\" + 0.011*\"get\" + 0.011*\"bracket\" + 0.009*\"go\" + 0.008*\"screw\" + 0.008*\"make\" + 0.007*\"two\" + 0.007*\"tilt\" + 0.007*\"back\"\n",
      "2019-07-08 12:55:39,929 : INFO : topic diff=0.314884, rho=0.307736\n",
      "2019-07-08 12:55:39,956 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:55:45,573 : INFO : -6.822 per-word bound, 113.2 perplexity estimate based on a held-out corpus of 2000 documents with 79013 words\n",
      "2019-07-08 12:55:45,575 : INFO : PROGRESS: pass 3, at document #4000/13119\n",
      "2019-07-08 12:55:45,578 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:55:50,390 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:55:50,460 : INFO : optimized alpha [0.06800595, 0.14532547, 0.19120914, 0.101994924, 0.06933878, 0.060590714, 0.07185346, 0.08880664, 0.06103017, 0.07450659]\n",
      "2019-07-08 12:55:50,469 : DEBUG : updating topics\n",
      "2019-07-08 12:55:50,479 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:55:50,495 : INFO : topic #5 (0.061): 0.031*\"antenna\" + 0.021*\"get\" + 0.020*\"one\" + 0.017*\"buy\" + 0.017*\"channel\" + 0.014*\"work\" + 0.011*\"new\" + 0.010*\"good\" + 0.010*\"purchase\" + 0.009*\"customer\"\n",
      "2019-07-08 12:55:50,506 : INFO : topic #8 (0.061): 0.066*\"screw\" + 0.023*\"use\" + 0.018*\"stud\" + 0.011*\"need\" + 0.009*\"bracket\" + 0.009*\"bolt\" + 0.009*\"head\" + 0.008*\"long\" + 0.008*\"inch\" + 0.008*\"one\"\n",
      "2019-07-08 12:55:50,509 : INFO : topic #3 (0.102): 0.037*\"good\" + 0.035*\"price\" + 0.033*\"product\" + 0.033*\"easy\" + 0.030*\"great\" + 0.025*\"quality\" + 0.023*\"install\" + 0.021*\"well\" + 0.018*\"buy\" + 0.016*\"look\"\n",
      "2019-07-08 12:55:50,515 : INFO : topic #1 (0.145): 0.036*\"easy\" + 0.030*\"great\" + 0.025*\"install\" + 0.025*\"work\" + 0.016*\"inch\" + 0.014*\"use\" + 0.014*\"need\" + 0.013*\"would\" + 0.013*\"recommend\" + 0.011*\"sturdy\"\n",
      "2019-07-08 12:55:50,525 : INFO : topic #2 (0.191): 0.017*\"one\" + 0.015*\"would\" + 0.012*\"get\" + 0.010*\"bracket\" + 0.009*\"go\" + 0.008*\"screw\" + 0.008*\"make\" + 0.007*\"tilt\" + 0.007*\"back\" + 0.007*\"two\"\n",
      "2019-07-08 12:55:50,550 : INFO : topic diff=0.293417, rho=0.307736\n",
      "2019-07-08 12:55:50,650 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:55:56,518 : INFO : -6.810 per-word bound, 112.2 perplexity estimate based on a held-out corpus of 2000 documents with 75399 words\n",
      "2019-07-08 12:55:56,531 : INFO : PROGRESS: pass 3, at document #6000/13119\n",
      "2019-07-08 12:55:56,534 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:55:59,907 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:55:59,936 : INFO : optimized alpha [0.07079756, 0.14804018, 0.19658874, 0.10526951, 0.0690566, 0.06041921, 0.07157599, 0.08646859, 0.06136991, 0.07668161]\n",
      "2019-07-08 12:55:59,938 : DEBUG : updating topics\n",
      "2019-07-08 12:55:59,940 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:55:59,951 : INFO : topic #5 (0.060): 0.024*\"antenna\" + 0.022*\"one\" + 0.022*\"get\" + 0.018*\"buy\" + 0.014*\"work\" + 0.013*\"channel\" + 0.012*\"new\" + 0.011*\"customer\" + 0.010*\"purchase\" + 0.010*\"good\"\n",
      "2019-07-08 12:55:59,955 : INFO : topic #8 (0.061): 0.071*\"screw\" + 0.023*\"use\" + 0.017*\"stud\" + 0.011*\"need\" + 0.011*\"long\" + 0.010*\"bracket\" + 0.009*\"bolt\" + 0.008*\"head\" + 0.008*\"inch\" + 0.008*\"one\"\n",
      "2019-07-08 12:55:59,958 : INFO : topic #3 (0.105): 0.037*\"price\" + 0.037*\"good\" + 0.034*\"easy\" + 0.033*\"product\" + 0.031*\"great\" + 0.024*\"install\" + 0.024*\"quality\" + 0.020*\"well\" + 0.018*\"buy\" + 0.016*\"look\"\n",
      "2019-07-08 12:55:59,961 : INFO : topic #1 (0.148): 0.037*\"easy\" + 0.030*\"great\" + 0.025*\"install\" + 0.025*\"work\" + 0.017*\"inch\" + 0.014*\"use\" + 0.014*\"would\" + 0.013*\"need\" + 0.012*\"recommend\" + 0.012*\"hold\"\n",
      "2019-07-08 12:55:59,964 : INFO : topic #2 (0.197): 0.017*\"one\" + 0.015*\"would\" + 0.012*\"get\" + 0.010*\"bracket\" + 0.009*\"go\" + 0.009*\"screw\" + 0.008*\"tilt\" + 0.008*\"make\" + 0.007*\"back\" + 0.007*\"two\"\n",
      "2019-07-08 12:55:59,967 : INFO : topic diff=0.288445, rho=0.307736\n",
      "2019-07-08 12:55:59,990 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:56:04,814 : INFO : -6.795 per-word bound, 111.0 perplexity estimate based on a held-out corpus of 2000 documents with 73605 words\n",
      "2019-07-08 12:56:04,816 : INFO : PROGRESS: pass 3, at document #8000/13119\n",
      "2019-07-08 12:56:04,819 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:56:07,883 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:56:07,912 : INFO : optimized alpha [0.0724376, 0.15386333, 0.19914198, 0.108757116, 0.06840422, 0.060427956, 0.0715138, 0.086009465, 0.061704185, 0.07874937]\n",
      "2019-07-08 12:56:07,915 : DEBUG : updating topics\n",
      "2019-07-08 12:56:07,917 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:56:07,927 : INFO : topic #5 (0.060): 0.023*\"one\" + 0.021*\"get\" + 0.020*\"buy\" + 0.018*\"antenna\" + 0.014*\"work\" + 0.012*\"cheetah\" + 0.012*\"customer\" + 0.012*\"new\" + 0.011*\"purchase\" + 0.010*\"good\"\n",
      "2019-07-08 12:56:07,930 : INFO : topic #8 (0.062): 0.071*\"screw\" + 0.023*\"use\" + 0.019*\"stud\" + 0.012*\"need\" + 0.011*\"long\" + 0.010*\"bracket\" + 0.010*\"bolt\" + 0.009*\"inch\" + 0.008*\"head\" + 0.008*\"anchor\"\n",
      "2019-07-08 12:56:07,936 : INFO : topic #3 (0.109): 0.038*\"price\" + 0.036*\"good\" + 0.035*\"product\" + 0.033*\"easy\" + 0.032*\"great\" + 0.024*\"install\" + 0.023*\"quality\" + 0.020*\"well\" + 0.020*\"buy\" + 0.015*\"look\"\n",
      "2019-07-08 12:56:07,938 : INFO : topic #1 (0.154): 0.036*\"easy\" + 0.030*\"great\" + 0.025*\"work\" + 0.024*\"install\" + 0.017*\"inch\" + 0.014*\"use\" + 0.014*\"would\" + 0.014*\"need\" + 0.013*\"hold\" + 0.013*\"recommend\"\n",
      "2019-07-08 12:56:07,941 : INFO : topic #2 (0.199): 0.017*\"one\" + 0.015*\"would\" + 0.012*\"get\" + 0.011*\"bracket\" + 0.009*\"go\" + 0.008*\"screw\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\"\n",
      "2019-07-08 12:56:07,944 : INFO : topic diff=0.281061, rho=0.307736\n",
      "2019-07-08 12:56:07,971 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:56:12,867 : INFO : -6.911 per-word bound, 120.3 perplexity estimate based on a held-out corpus of 2000 documents with 85614 words\n",
      "2019-07-08 12:56:12,870 : INFO : PROGRESS: pass 3, at document #10000/13119\n",
      "2019-07-08 12:56:12,872 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:56:16,153 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:56:16,181 : INFO : optimized alpha [0.07292597, 0.15678221, 0.20727861, 0.11157287, 0.06962088, 0.06095645, 0.07432162, 0.08772587, 0.06266114, 0.08060905]\n",
      "2019-07-08 12:56:16,183 : DEBUG : updating topics\n",
      "2019-07-08 12:56:16,186 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:56:16,196 : INFO : topic #5 (0.061): 0.021*\"one\" + 0.020*\"get\" + 0.020*\"buy\" + 0.014*\"antenna\" + 0.014*\"work\" + 0.014*\"new\" + 0.013*\"customer\" + 0.013*\"cheetah\" + 0.011*\"purchase\" + 0.010*\"service\"\n",
      "2019-07-08 12:56:16,199 : INFO : topic #8 (0.063): 0.068*\"screw\" + 0.023*\"use\" + 0.020*\"stud\" + 0.011*\"long\" + 0.011*\"need\" + 0.010*\"bracket\" + 0.010*\"inch\" + 0.009*\"bolt\" + 0.009*\"anchor\" + 0.008*\"head\"\n",
      "2019-07-08 12:56:16,201 : INFO : topic #3 (0.112): 0.037*\"price\" + 0.036*\"good\" + 0.036*\"product\" + 0.032*\"easy\" + 0.031*\"great\" + 0.024*\"quality\" + 0.022*\"install\" + 0.021*\"well\" + 0.019*\"buy\" + 0.015*\"look\"\n",
      "2019-07-08 12:56:16,204 : INFO : topic #1 (0.157): 0.035*\"easy\" + 0.029*\"great\" + 0.025*\"install\" + 0.024*\"work\" + 0.018*\"inch\" + 0.014*\"would\" + 0.013*\"need\" + 0.013*\"use\" + 0.013*\"recommend\" + 0.012*\"hold\"\n",
      "2019-07-08 12:56:16,207 : INFO : topic #2 (0.207): 0.016*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.010*\"bracket\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.008*\"screw\" + 0.007*\"back\" + 0.007*\"two\"\n",
      "2019-07-08 12:56:16,210 : INFO : topic diff=0.314920, rho=0.307736\n",
      "2019-07-08 12:56:16,234 : DEBUG : bound: at document #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 12:56:20,545 : INFO : -6.935 per-word bound, 122.4 perplexity estimate based on a held-out corpus of 2000 documents with 69590 words\n",
      "2019-07-08 12:56:20,549 : INFO : PROGRESS: pass 3, at document #12000/13119\n",
      "2019-07-08 12:56:20,551 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:56:23,282 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:56:23,307 : INFO : optimized alpha [0.07302357, 0.15964262, 0.21008012, 0.11455618, 0.07063325, 0.06108242, 0.07580638, 0.0922738, 0.06387668, 0.08068936]\n",
      "2019-07-08 12:56:23,311 : DEBUG : updating topics\n",
      "2019-07-08 12:56:23,314 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:56:23,325 : INFO : topic #5 (0.061): 0.021*\"one\" + 0.020*\"get\" + 0.020*\"buy\" + 0.015*\"new\" + 0.014*\"work\" + 0.013*\"antenna\" + 0.011*\"purchase\" + 0.011*\"customer\" + 0.010*\"service\" + 0.010*\"good\"\n",
      "2019-07-08 12:56:23,328 : INFO : topic #8 (0.064): 0.069*\"screw\" + 0.024*\"use\" + 0.020*\"stud\" + 0.012*\"long\" + 0.011*\"need\" + 0.010*\"anchor\" + 0.009*\"inch\" + 0.009*\"bracket\" + 0.009*\"bolt\" + 0.009*\"drywall\"\n",
      "2019-07-08 12:56:23,331 : INFO : topic #3 (0.115): 0.038*\"price\" + 0.037*\"good\" + 0.036*\"product\" + 0.032*\"easy\" + 0.032*\"great\" + 0.023*\"quality\" + 0.023*\"install\" + 0.021*\"well\" + 0.019*\"buy\" + 0.016*\"work\"\n",
      "2019-07-08 12:56:23,334 : INFO : topic #1 (0.160): 0.036*\"easy\" + 0.030*\"great\" + 0.026*\"work\" + 0.025*\"install\" + 0.017*\"inch\" + 0.014*\"need\" + 0.014*\"use\" + 0.014*\"would\" + 0.012*\"recommend\" + 0.012*\"hold\"\n",
      "2019-07-08 12:56:23,337 : INFO : topic #2 (0.210): 0.016*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.010*\"bracket\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"screw\"\n",
      "2019-07-08 12:56:23,340 : INFO : topic diff=0.275201, rho=0.307736\n",
      "2019-07-08 12:56:23,363 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:56:26,000 : INFO : -7.023 per-word bound, 130.1 perplexity estimate based on a held-out corpus of 1119 documents with 49461 words\n",
      "2019-07-08 12:56:26,003 : INFO : PROGRESS: pass 3, at document #13119/13119\n",
      "2019-07-08 12:56:26,006 : DEBUG : performing inference on a chunk of 1119 documents\n",
      "2019-07-08 12:56:27,529 : DEBUG : 1119/1119 documents converged within 400 iterations\n",
      "2019-07-08 12:56:27,544 : INFO : optimized alpha [0.07394768, 0.16260622, 0.21523172, 0.116329275, 0.07354365, 0.0628133, 0.078611165, 0.094633445, 0.06499098, 0.081302226]\n",
      "2019-07-08 12:56:27,547 : DEBUG : updating topics\n",
      "2019-07-08 12:56:27,550 : INFO : merging changes from 1119 documents into a model of 13119 documents\n",
      "2019-07-08 12:56:27,561 : INFO : topic #5 (0.063): 0.046*\"antenna\" + 0.025*\"channel\" + 0.023*\"get\" + 0.018*\"one\" + 0.014*\"mohu\" + 0.013*\"work\" + 0.013*\"buy\" + 0.012*\"signal\" + 0.011*\"good\" + 0.010*\"new\"\n",
      "2019-07-08 12:56:27,564 : INFO : topic #8 (0.065): 0.065*\"screw\" + 0.024*\"use\" + 0.018*\"stud\" + 0.011*\"long\" + 0.011*\"anchor\" + 0.011*\"need\" + 0.009*\"bolt\" + 0.009*\"bracket\" + 0.009*\"drywall\" + 0.008*\"inch\"\n",
      "2019-07-08 12:56:27,567 : INFO : topic #3 (0.116): 0.037*\"good\" + 0.037*\"price\" + 0.035*\"product\" + 0.033*\"easy\" + 0.032*\"great\" + 0.024*\"quality\" + 0.022*\"install\" + 0.022*\"well\" + 0.018*\"buy\" + 0.016*\"look\"\n",
      "2019-07-08 12:56:27,572 : INFO : topic #1 (0.163): 0.036*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.024*\"install\" + 0.018*\"inch\" + 0.015*\"use\" + 0.013*\"would\" + 0.013*\"need\" + 0.013*\"hold\" + 0.012*\"recommend\"\n",
      "2019-07-08 12:56:27,575 : INFO : topic #2 (0.215): 0.016*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.009*\"bracket\" + 0.009*\"go\" + 0.008*\"make\" + 0.007*\"two\" + 0.007*\"back\" + 0.007*\"tilt\" + 0.007*\"screw\"\n",
      "2019-07-08 12:56:27,578 : INFO : topic diff=0.359894, rho=0.307736\n",
      "2019-07-08 12:56:27,606 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:56:32,090 : INFO : -6.804 per-word bound, 111.7 perplexity estimate based on a held-out corpus of 2000 documents with 76029 words\n",
      "2019-07-08 12:56:32,092 : INFO : PROGRESS: pass 4, at document #2000/13119\n",
      "2019-07-08 12:56:32,095 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:56:34,927 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:56:34,955 : INFO : optimized alpha [0.07250609, 0.16469763, 0.21521086, 0.119591475, 0.07398071, 0.061365213, 0.07733189, 0.096275374, 0.0650214, 0.08212074]\n",
      "2019-07-08 12:56:34,959 : DEBUG : updating topics\n",
      "2019-07-08 12:56:34,962 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:56:34,971 : INFO : topic #5 (0.061): 0.042*\"antenna\" + 0.023*\"get\" + 0.022*\"channel\" + 0.018*\"one\" + 0.014*\"buy\" + 0.013*\"work\" + 0.012*\"mohu\" + 0.011*\"signal\" + 0.011*\"new\" + 0.010*\"good\"\n",
      "2019-07-08 12:56:34,975 : INFO : topic #8 (0.065): 0.073*\"screw\" + 0.025*\"use\" + 0.018*\"stud\" + 0.011*\"need\" + 0.010*\"long\" + 0.010*\"head\" + 0.010*\"anchor\" + 0.009*\"bolt\" + 0.009*\"bracket\" + 0.009*\"strip\"\n",
      "2019-07-08 12:56:34,978 : INFO : topic #3 (0.120): 0.037*\"price\" + 0.037*\"good\" + 0.033*\"product\" + 0.033*\"great\" + 0.032*\"easy\" + 0.025*\"quality\" + 0.022*\"install\" + 0.021*\"well\" + 0.020*\"buy\" + 0.016*\"look\"\n",
      "2019-07-08 12:56:34,981 : INFO : topic #1 (0.165): 0.036*\"easy\" + 0.029*\"great\" + 0.025*\"work\" + 0.024*\"install\" + 0.018*\"inch\" + 0.015*\"use\" + 0.013*\"would\" + 0.013*\"need\" + 0.013*\"hold\" + 0.013*\"screen\"\n",
      "2019-07-08 12:56:34,984 : INFO : topic #2 (0.215): 0.017*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.010*\"bracket\" + 0.009*\"go\" + 0.008*\"make\" + 0.007*\"tilt\" + 0.007*\"two\" + 0.007*\"screw\" + 0.007*\"back\"\n",
      "2019-07-08 12:56:34,987 : INFO : topic diff=0.295785, rho=0.294124\n",
      "2019-07-08 12:56:35,012 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:56:39,570 : INFO : -6.814 per-word bound, 112.5 perplexity estimate based on a held-out corpus of 2000 documents with 79013 words\n",
      "2019-07-08 12:56:39,572 : INFO : PROGRESS: pass 4, at document #4000/13119\n",
      "2019-07-08 12:56:39,574 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:56:42,462 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:56:42,490 : INFO : optimized alpha [0.07301159, 0.17129155, 0.22045542, 0.122585244, 0.07394063, 0.060732633, 0.07724301, 0.09724898, 0.06484159, 0.0840294]\n",
      "2019-07-08 12:56:42,492 : DEBUG : updating topics\n",
      "2019-07-08 12:56:42,495 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:56:42,506 : INFO : topic #5 (0.061): 0.034*\"antenna\" + 0.023*\"get\" + 0.019*\"one\" + 0.018*\"channel\" + 0.014*\"buy\" + 0.013*\"work\" + 0.011*\"new\" + 0.010*\"customer\" + 0.010*\"good\" + 0.010*\"mohu\"\n",
      "2019-07-08 12:56:42,509 : INFO : topic #8 (0.065): 0.073*\"screw\" + 0.024*\"use\" + 0.019*\"stud\" + 0.010*\"need\" + 0.010*\"long\" + 0.010*\"anchor\" + 0.010*\"bolt\" + 0.010*\"head\" + 0.009*\"bracket\" + 0.008*\"wood\"\n",
      "2019-07-08 12:56:42,512 : INFO : topic #3 (0.123): 0.037*\"price\" + 0.037*\"good\" + 0.034*\"product\" + 0.033*\"great\" + 0.032*\"easy\" + 0.025*\"quality\" + 0.023*\"install\" + 0.021*\"well\" + 0.020*\"buy\" + 0.016*\"look\"\n",
      "2019-07-08 12:56:42,515 : INFO : topic #1 (0.171): 0.035*\"easy\" + 0.028*\"great\" + 0.024*\"work\" + 0.024*\"install\" + 0.017*\"inch\" + 0.015*\"use\" + 0.014*\"need\" + 0.013*\"would\" + 0.012*\"hold\" + 0.012*\"screen\"\n",
      "2019-07-08 12:56:42,520 : INFO : topic #2 (0.220): 0.017*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.009*\"bracket\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"screw\"\n",
      "2019-07-08 12:56:42,523 : INFO : topic diff=0.275321, rho=0.294124\n",
      "2019-07-08 12:56:42,545 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:56:47,224 : INFO : -6.801 per-word bound, 111.5 perplexity estimate based on a held-out corpus of 2000 documents with 75399 words\n",
      "2019-07-08 12:56:47,226 : INFO : PROGRESS: pass 4, at document #6000/13119\n",
      "2019-07-08 12:56:47,228 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:56:50,432 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:56:50,465 : INFO : optimized alpha [0.07599986, 0.17341763, 0.22628051, 0.12631637, 0.07372621, 0.060598068, 0.07703603, 0.0946393, 0.06543359, 0.086302005]\n",
      "2019-07-08 12:56:50,467 : DEBUG : updating topics\n",
      "2019-07-08 12:56:50,470 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:56:50,480 : INFO : topic #5 (0.061): 0.026*\"antenna\" + 0.023*\"get\" + 0.020*\"one\" + 0.014*\"channel\" + 0.014*\"buy\" + 0.013*\"work\" + 0.012*\"customer\" + 0.012*\"new\" + 0.010*\"cheetah\" + 0.010*\"service\"\n",
      "2019-07-08 12:56:50,483 : INFO : topic #8 (0.065): 0.078*\"screw\" + 0.024*\"use\" + 0.018*\"stud\" + 0.012*\"long\" + 0.011*\"need\" + 0.010*\"bolt\" + 0.009*\"anchor\" + 0.009*\"bracket\" + 0.009*\"head\" + 0.008*\"inch\"\n",
      "2019-07-08 12:56:50,489 : INFO : topic #3 (0.126): 0.039*\"price\" + 0.036*\"good\" + 0.034*\"product\" + 0.033*\"great\" + 0.033*\"easy\" + 0.024*\"quality\" + 0.023*\"install\" + 0.020*\"buy\" + 0.020*\"well\" + 0.016*\"look\"\n",
      "2019-07-08 12:56:50,492 : INFO : topic #1 (0.173): 0.036*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.024*\"install\" + 0.017*\"inch\" + 0.015*\"use\" + 0.013*\"need\" + 0.013*\"would\" + 0.013*\"hold\" + 0.012*\"screen\"\n",
      "2019-07-08 12:56:50,495 : INFO : topic #2 (0.226): 0.017*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.010*\"bracket\" + 0.009*\"go\" + 0.008*\"tilt\" + 0.008*\"make\" + 0.007*\"screw\" + 0.007*\"back\" + 0.007*\"two\"\n",
      "2019-07-08 12:56:50,498 : INFO : topic diff=0.268998, rho=0.294124\n",
      "2019-07-08 12:56:50,520 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:56:55,553 : INFO : -6.786 per-word bound, 110.4 perplexity estimate based on a held-out corpus of 2000 documents with 73605 words\n",
      "2019-07-08 12:56:55,555 : INFO : PROGRESS: pass 4, at document #8000/13119\n",
      "2019-07-08 12:56:55,558 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:56:59,187 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:56:59,214 : INFO : optimized alpha [0.077747375, 0.18005389, 0.22941601, 0.13039827, 0.073108144, 0.060587168, 0.07699079, 0.093919955, 0.065897785, 0.08847201]\n",
      "2019-07-08 12:56:59,216 : DEBUG : updating topics\n",
      "2019-07-08 12:56:59,218 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:56:59,229 : INFO : topic #5 (0.061): 0.023*\"get\" + 0.020*\"one\" + 0.020*\"antenna\" + 0.016*\"buy\" + 0.014*\"customer\" + 0.013*\"cheetah\" + 0.012*\"work\" + 0.012*\"new\" + 0.011*\"channel\" + 0.010*\"service\"\n",
      "2019-07-08 12:56:59,234 : INFO : topic #8 (0.066): 0.078*\"screw\" + 0.024*\"use\" + 0.020*\"stud\" + 0.013*\"long\" + 0.011*\"need\" + 0.011*\"bolt\" + 0.010*\"anchor\" + 0.010*\"bracket\" + 0.009*\"head\" + 0.008*\"inch\"\n",
      "2019-07-08 12:56:59,237 : INFO : topic #3 (0.130): 0.040*\"price\" + 0.036*\"good\" + 0.035*\"product\" + 0.034*\"great\" + 0.033*\"easy\" + 0.024*\"install\" + 0.023*\"quality\" + 0.021*\"buy\" + 0.020*\"well\" + 0.015*\"work\"\n",
      "2019-07-08 12:56:59,239 : INFO : topic #1 (0.180): 0.035*\"easy\" + 0.029*\"great\" + 0.024*\"work\" + 0.024*\"install\" + 0.018*\"inch\" + 0.014*\"use\" + 0.014*\"hold\" + 0.014*\"need\" + 0.013*\"would\" + 0.012*\"screen\"\n",
      "2019-07-08 12:56:59,243 : INFO : topic #2 (0.229): 0.017*\"one\" + 0.015*\"would\" + 0.012*\"get\" + 0.010*\"bracket\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"screw\" + 0.007*\"back\" + 0.007*\"two\"\n",
      "2019-07-08 12:56:59,246 : INFO : topic diff=0.259866, rho=0.294124\n",
      "2019-07-08 12:56:59,269 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:57:05,629 : INFO : -6.901 per-word bound, 119.5 perplexity estimate based on a held-out corpus of 2000 documents with 85614 words\n",
      "2019-07-08 12:57:05,631 : INFO : PROGRESS: pass 4, at document #10000/13119\n",
      "2019-07-08 12:57:05,634 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:57:09,005 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:57:09,060 : INFO : optimized alpha [0.07810533, 0.18252525, 0.23814361, 0.1333743, 0.07436337, 0.06116251, 0.079910524, 0.09562032, 0.067049086, 0.09034367]\n",
      "2019-07-08 12:57:09,062 : DEBUG : updating topics\n",
      "2019-07-08 12:57:09,065 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:57:09,091 : INFO : topic #5 (0.061): 0.022*\"get\" + 0.019*\"one\" + 0.016*\"buy\" + 0.016*\"antenna\" + 0.014*\"customer\" + 0.014*\"new\" + 0.013*\"cheetah\" + 0.012*\"work\" + 0.011*\"service\" + 0.010*\"purchase\"\n",
      "2019-07-08 12:57:09,096 : INFO : topic #8 (0.067): 0.075*\"screw\" + 0.024*\"use\" + 0.021*\"stud\" + 0.013*\"long\" + 0.011*\"need\" + 0.010*\"anchor\" + 0.010*\"bolt\" + 0.010*\"bracket\" + 0.009*\"inch\" + 0.009*\"head\"\n",
      "2019-07-08 12:57:09,099 : INFO : topic #3 (0.133): 0.039*\"price\" + 0.036*\"product\" + 0.036*\"good\" + 0.033*\"great\" + 0.031*\"easy\" + 0.024*\"quality\" + 0.022*\"install\" + 0.021*\"well\" + 0.021*\"buy\" + 0.016*\"work\"\n",
      "2019-07-08 12:57:09,102 : INFO : topic #1 (0.183): 0.035*\"easy\" + 0.028*\"great\" + 0.024*\"work\" + 0.024*\"install\" + 0.018*\"inch\" + 0.014*\"use\" + 0.013*\"need\" + 0.013*\"hold\" + 0.013*\"would\" + 0.012*\"flat\"\n",
      "2019-07-08 12:57:09,105 : INFO : topic #2 (0.238): 0.017*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.010*\"bracket\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"screw\"\n",
      "2019-07-08 12:57:09,108 : INFO : topic diff=0.292773, rho=0.294124\n",
      "2019-07-08 12:57:09,150 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:57:13,711 : INFO : -6.926 per-word bound, 121.6 perplexity estimate based on a held-out corpus of 2000 documents with 69590 words\n",
      "2019-07-08 12:57:13,713 : INFO : PROGRESS: pass 4, at document #12000/13119\n",
      "2019-07-08 12:57:13,715 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:57:17,015 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:57:17,070 : INFO : optimized alpha [0.07822898, 0.18503171, 0.24094306, 0.13639756, 0.07539275, 0.06121218, 0.08144904, 0.10005412, 0.0684597, 0.09033135]\n",
      "2019-07-08 12:57:17,075 : DEBUG : updating topics\n",
      "2019-07-08 12:57:17,085 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:57:17,107 : INFO : topic #5 (0.061): 0.021*\"get\" + 0.019*\"one\" + 0.016*\"buy\" + 0.015*\"antenna\" + 0.015*\"new\" + 0.013*\"work\" + 0.012*\"customer\" + 0.011*\"service\" + 0.010*\"return\" + 0.010*\"cheetah\"\n",
      "2019-07-08 12:57:17,112 : INFO : topic #8 (0.068): 0.075*\"screw\" + 0.026*\"use\" + 0.021*\"stud\" + 0.013*\"long\" + 0.012*\"anchor\" + 0.011*\"need\" + 0.010*\"bolt\" + 0.010*\"drywall\" + 0.009*\"head\" + 0.009*\"inch\"\n",
      "2019-07-08 12:57:17,116 : INFO : topic #3 (0.136): 0.040*\"price\" + 0.037*\"good\" + 0.036*\"product\" + 0.034*\"great\" + 0.032*\"easy\" + 0.023*\"quality\" + 0.022*\"install\" + 0.022*\"well\" + 0.021*\"buy\" + 0.017*\"work\"\n",
      "2019-07-08 12:57:17,119 : INFO : topic #1 (0.185): 0.035*\"easy\" + 0.029*\"great\" + 0.026*\"work\" + 0.024*\"install\" + 0.018*\"inch\" + 0.014*\"use\" + 0.014*\"need\" + 0.013*\"would\" + 0.013*\"flat\" + 0.013*\"hold\"\n",
      "2019-07-08 12:57:17,122 : INFO : topic #2 (0.241): 0.017*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.009*\"go\" + 0.009*\"bracket\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"like\"\n",
      "2019-07-08 12:57:17,133 : INFO : topic diff=0.252660, rho=0.294124\n",
      "2019-07-08 12:57:17,169 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:57:20,646 : INFO : -7.005 per-word bound, 128.5 perplexity estimate based on a held-out corpus of 1119 documents with 49461 words\n",
      "2019-07-08 12:57:20,648 : INFO : PROGRESS: pass 4, at document #13119/13119\n",
      "2019-07-08 12:57:20,654 : DEBUG : performing inference on a chunk of 1119 documents\n",
      "2019-07-08 12:57:22,732 : DEBUG : 1119/1119 documents converged within 400 iterations\n",
      "2019-07-08 12:57:22,766 : INFO : optimized alpha [0.078774795, 0.18808225, 0.24570735, 0.13799402, 0.078339055, 0.06294136, 0.08462127, 0.10227625, 0.06947569, 0.090797365]\n",
      "2019-07-08 12:57:22,773 : DEBUG : updating topics\n",
      "2019-07-08 12:57:22,779 : INFO : merging changes from 1119 documents into a model of 13119 documents\n",
      "2019-07-08 12:57:22,804 : INFO : topic #5 (0.063): 0.047*\"antenna\" + 0.026*\"channel\" + 0.024*\"get\" + 0.016*\"one\" + 0.015*\"mohu\" + 0.012*\"work\" + 0.012*\"signal\" + 0.011*\"buy\" + 0.010*\"good\" + 0.010*\"new\"\n",
      "2019-07-08 12:57:22,810 : INFO : topic #8 (0.069): 0.070*\"screw\" + 0.025*\"use\" + 0.019*\"stud\" + 0.013*\"anchor\" + 0.012*\"long\" + 0.011*\"need\" + 0.010*\"drywall\" + 0.010*\"bolt\" + 0.009*\"head\" + 0.008*\"bracket\"\n",
      "2019-07-08 12:57:22,813 : INFO : topic #3 (0.138): 0.038*\"price\" + 0.037*\"good\" + 0.035*\"product\" + 0.033*\"great\" + 0.032*\"easy\" + 0.024*\"quality\" + 0.022*\"well\" + 0.022*\"install\" + 0.019*\"buy\" + 0.017*\"work\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 12:57:22,829 : INFO : topic #1 (0.188): 0.035*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.019*\"inch\" + 0.015*\"use\" + 0.013*\"hold\" + 0.013*\"need\" + 0.013*\"would\" + 0.013*\"screen\"\n",
      "2019-07-08 12:57:22,838 : INFO : topic #2 (0.246): 0.017*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.009*\"go\" + 0.008*\"bracket\" + 0.008*\"make\" + 0.007*\"two\" + 0.007*\"back\" + 0.007*\"tilt\" + 0.007*\"like\"\n",
      "2019-07-08 12:57:22,841 : INFO : topic diff=0.336069, rho=0.294124\n",
      "2019-07-08 12:57:22,896 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:57:28,666 : INFO : -6.800 per-word bound, 111.5 perplexity estimate based on a held-out corpus of 2000 documents with 76029 words\n",
      "2019-07-08 12:57:28,668 : INFO : PROGRESS: pass 5, at document #2000/13119\n",
      "2019-07-08 12:57:28,671 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:57:31,860 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:57:31,918 : INFO : optimized alpha [0.07740698, 0.19035234, 0.24527834, 0.1415411, 0.07883776, 0.06151965, 0.08348742, 0.10388375, 0.06963988, 0.091644794]\n",
      "2019-07-08 12:57:31,934 : DEBUG : updating topics\n",
      "2019-07-08 12:57:31,944 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:57:31,955 : INFO : topic #5 (0.062): 0.044*\"antenna\" + 0.024*\"get\" + 0.023*\"channel\" + 0.016*\"one\" + 0.012*\"mohu\" + 0.012*\"work\" + 0.012*\"signal\" + 0.011*\"buy\" + 0.011*\"new\" + 0.010*\"good\"\n",
      "2019-07-08 12:57:31,959 : INFO : topic #8 (0.070): 0.078*\"screw\" + 0.026*\"use\" + 0.019*\"stud\" + 0.012*\"long\" + 0.011*\"anchor\" + 0.010*\"need\" + 0.010*\"head\" + 0.010*\"bolt\" + 0.009*\"strip\" + 0.009*\"drywall\"\n",
      "2019-07-08 12:57:31,966 : INFO : topic #3 (0.142): 0.038*\"price\" + 0.037*\"good\" + 0.034*\"great\" + 0.033*\"product\" + 0.031*\"easy\" + 0.025*\"quality\" + 0.022*\"install\" + 0.021*\"buy\" + 0.021*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 12:57:31,969 : INFO : topic #1 (0.190): 0.035*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.019*\"inch\" + 0.016*\"use\" + 0.013*\"hold\" + 0.013*\"screen\" + 0.013*\"need\" + 0.013*\"flat\"\n",
      "2019-07-08 12:57:31,978 : INFO : topic #2 (0.245): 0.017*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.009*\"bracket\" + 0.009*\"go\" + 0.008*\"make\" + 0.007*\"tilt\" + 0.007*\"two\" + 0.007*\"back\" + 0.006*\"screw\"\n",
      "2019-07-08 12:57:31,983 : INFO : topic diff=0.269867, rho=0.282172\n",
      "2019-07-08 12:57:32,024 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:57:37,964 : INFO : -6.807 per-word bound, 112.0 perplexity estimate based on a held-out corpus of 2000 documents with 79013 words\n",
      "2019-07-08 12:57:37,968 : INFO : PROGRESS: pass 5, at document #4000/13119\n",
      "2019-07-08 12:57:37,970 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:57:41,349 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:57:41,392 : INFO : optimized alpha [0.07789426, 0.19759104, 0.25132442, 0.1444937, 0.0788228, 0.061007973, 0.083425544, 0.10497971, 0.069562145, 0.09358465]\n",
      "2019-07-08 12:57:41,404 : DEBUG : updating topics\n",
      "2019-07-08 12:57:41,411 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:57:41,440 : INFO : topic #5 (0.061): 0.036*\"antenna\" + 0.023*\"get\" + 0.019*\"channel\" + 0.017*\"one\" + 0.012*\"work\" + 0.011*\"buy\" + 0.011*\"customer\" + 0.011*\"new\" + 0.010*\"mohu\" + 0.010*\"signal\"\n",
      "2019-07-08 12:57:41,444 : INFO : topic #8 (0.070): 0.078*\"screw\" + 0.026*\"use\" + 0.020*\"stud\" + 0.012*\"anchor\" + 0.011*\"long\" + 0.011*\"bolt\" + 0.010*\"need\" + 0.010*\"head\" + 0.009*\"drywall\" + 0.009*\"wood\"\n",
      "2019-07-08 12:57:41,448 : INFO : topic #3 (0.144): 0.039*\"price\" + 0.037*\"good\" + 0.034*\"product\" + 0.034*\"great\" + 0.031*\"easy\" + 0.025*\"quality\" + 0.022*\"install\" + 0.021*\"buy\" + 0.021*\"well\" + 0.016*\"work\"\n",
      "2019-07-08 12:57:41,452 : INFO : topic #1 (0.198): 0.035*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.018*\"inch\" + 0.015*\"use\" + 0.014*\"need\" + 0.013*\"hold\" + 0.013*\"flat\" + 0.013*\"screen\"\n",
      "2019-07-08 12:57:41,456 : INFO : topic #2 (0.251): 0.018*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.009*\"go\" + 0.009*\"bracket\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.006*\"like\"\n",
      "2019-07-08 12:57:41,459 : INFO : topic diff=0.250990, rho=0.282172\n",
      "2019-07-08 12:57:41,499 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:57:46,478 : INFO : -6.794 per-word bound, 111.0 perplexity estimate based on a held-out corpus of 2000 documents with 75399 words\n",
      "2019-07-08 12:57:46,480 : INFO : PROGRESS: pass 5, at document #6000/13119\n",
      "2019-07-08 12:57:46,483 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:57:49,474 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:57:49,525 : INFO : optimized alpha [0.0811735, 0.19952612, 0.25878352, 0.14837371, 0.07845363, 0.0608652, 0.08315067, 0.102129474, 0.07036964, 0.09595386]\n",
      "2019-07-08 12:57:49,539 : DEBUG : updating topics\n",
      "2019-07-08 12:57:49,551 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:57:49,563 : INFO : topic #5 (0.061): 0.028*\"antenna\" + 0.024*\"get\" + 0.017*\"one\" + 0.016*\"channel\" + 0.014*\"customer\" + 0.012*\"buy\" + 0.012*\"new\" + 0.011*\"work\" + 0.011*\"service\" + 0.011*\"cheetah\"\n",
      "2019-07-08 12:57:49,574 : INFO : topic #8 (0.070): 0.083*\"screw\" + 0.025*\"use\" + 0.019*\"stud\" + 0.013*\"long\" + 0.011*\"bolt\" + 0.011*\"anchor\" + 0.011*\"need\" + 0.009*\"head\" + 0.009*\"bracket\" + 0.008*\"bottom\"\n",
      "2019-07-08 12:57:49,578 : INFO : topic #3 (0.148): 0.040*\"price\" + 0.036*\"good\" + 0.034*\"great\" + 0.034*\"product\" + 0.032*\"easy\" + 0.024*\"quality\" + 0.023*\"install\" + 0.022*\"buy\" + 0.020*\"well\" + 0.016*\"work\"\n",
      "2019-07-08 12:57:49,583 : INFO : topic #1 (0.200): 0.035*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.018*\"inch\" + 0.015*\"use\" + 0.014*\"hold\" + 0.013*\"screen\" + 0.013*\"need\" + 0.013*\"flat\"\n",
      "2019-07-08 12:57:49,586 : INFO : topic #2 (0.259): 0.018*\"one\" + 0.016*\"would\" + 0.013*\"get\" + 0.009*\"go\" + 0.009*\"bracket\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.006*\"could\"\n",
      "2019-07-08 12:57:49,591 : INFO : topic diff=0.245054, rho=0.282172\n",
      "2019-07-08 12:57:49,638 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:57:54,186 : INFO : -6.780 per-word bound, 109.9 perplexity estimate based on a held-out corpus of 2000 documents with 73605 words\n",
      "2019-07-08 12:57:54,189 : INFO : PROGRESS: pass 5, at document #8000/13119\n",
      "2019-07-08 12:57:54,192 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:57:57,610 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:57:57,671 : INFO : optimized alpha [0.083079435, 0.20622225, 0.26228157, 0.15319845, 0.077676, 0.06088828, 0.08310428, 0.10134513, 0.070953995, 0.09816675]\n",
      "2019-07-08 12:57:57,675 : DEBUG : updating topics\n",
      "2019-07-08 12:57:57,679 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:57:57,709 : INFO : topic #5 (0.061): 0.024*\"get\" + 0.022*\"antenna\" + 0.017*\"one\" + 0.015*\"customer\" + 0.014*\"cheetah\" + 0.013*\"buy\" + 0.012*\"channel\" + 0.012*\"new\" + 0.011*\"service\" + 0.011*\"work\"\n",
      "2019-07-08 12:57:57,711 : INFO : topic #8 (0.071): 0.083*\"screw\" + 0.025*\"use\" + 0.021*\"stud\" + 0.014*\"long\" + 0.012*\"bolt\" + 0.012*\"anchor\" + 0.011*\"need\" + 0.009*\"head\" + 0.009*\"bracket\" + 0.008*\"inch\"\n",
      "2019-07-08 12:57:57,714 : INFO : topic #3 (0.153): 0.041*\"price\" + 0.036*\"good\" + 0.035*\"product\" + 0.035*\"great\" + 0.032*\"easy\" + 0.024*\"quality\" + 0.023*\"install\" + 0.023*\"buy\" + 0.020*\"well\" + 0.016*\"work\"\n",
      "2019-07-08 12:57:57,721 : INFO : topic #1 (0.206): 0.035*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.019*\"inch\" + 0.015*\"use\" + 0.015*\"hold\" + 0.014*\"need\" + 0.013*\"screen\" + 0.013*\"would\"\n",
      "2019-07-08 12:57:57,724 : INFO : topic #2 (0.262): 0.017*\"one\" + 0.016*\"would\" + 0.013*\"get\" + 0.009*\"bracket\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.006*\"review\"\n",
      "2019-07-08 12:57:57,727 : INFO : topic diff=0.235480, rho=0.282172\n",
      "2019-07-08 12:57:57,767 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:58:03,166 : INFO : -6.894 per-word bound, 118.9 perplexity estimate based on a held-out corpus of 2000 documents with 85614 words\n",
      "2019-07-08 12:58:03,168 : INFO : PROGRESS: pass 5, at document #10000/13119\n",
      "2019-07-08 12:58:03,171 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:58:06,770 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:58:06,816 : INFO : optimized alpha [0.083378345, 0.20928243, 0.27228257, 0.156538, 0.07888369, 0.061466444, 0.086128876, 0.10300912, 0.072185785, 0.0998426]\n",
      "2019-07-08 12:58:06,819 : DEBUG : updating topics\n",
      "2019-07-08 12:58:06,822 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:58:06,850 : INFO : topic #5 (0.061): 0.023*\"get\" + 0.018*\"antenna\" + 0.017*\"one\" + 0.016*\"customer\" + 0.014*\"cheetah\" + 0.014*\"new\" + 0.013*\"buy\" + 0.012*\"service\" + 0.011*\"work\" + 0.010*\"channel\"\n",
      "2019-07-08 12:58:06,853 : INFO : topic #8 (0.072): 0.079*\"screw\" + 0.025*\"use\" + 0.021*\"stud\" + 0.014*\"long\" + 0.012*\"anchor\" + 0.012*\"bolt\" + 0.011*\"need\" + 0.009*\"inch\" + 0.009*\"drywall\" + 0.009*\"bracket\"\n",
      "2019-07-08 12:58:06,855 : INFO : topic #3 (0.157): 0.040*\"price\" + 0.036*\"product\" + 0.036*\"good\" + 0.034*\"great\" + 0.031*\"easy\" + 0.025*\"quality\" + 0.022*\"buy\" + 0.022*\"install\" + 0.021*\"well\" + 0.016*\"work\"\n",
      "2019-07-08 12:58:06,858 : INFO : topic #1 (0.209): 0.034*\"easy\" + 0.028*\"great\" + 0.024*\"work\" + 0.023*\"install\" + 0.019*\"inch\" + 0.014*\"use\" + 0.014*\"hold\" + 0.013*\"need\" + 0.013*\"flat\" + 0.013*\"would\"\n",
      "2019-07-08 12:58:06,865 : INFO : topic #2 (0.272): 0.017*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.009*\"go\" + 0.009*\"bracket\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"like\"\n",
      "2019-07-08 12:58:06,874 : INFO : topic diff=0.267215, rho=0.282172\n",
      "2019-07-08 12:58:06,915 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:58:12,127 : INFO : -6.919 per-word bound, 121.0 perplexity estimate based on a held-out corpus of 2000 documents with 69590 words\n",
      "2019-07-08 12:58:12,129 : INFO : PROGRESS: pass 5, at document #12000/13119\n",
      "2019-07-08 12:58:12,133 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:58:14,892 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:58:14,944 : INFO : optimized alpha [0.083360314, 0.21161464, 0.27512372, 0.15936796, 0.08000989, 0.061588965, 0.087600306, 0.10758057, 0.07366384, 0.09977541]\n",
      "2019-07-08 12:58:14,950 : DEBUG : updating topics\n",
      "2019-07-08 12:58:14,954 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:58:14,971 : INFO : topic #5 (0.062): 0.022*\"get\" + 0.017*\"one\" + 0.017*\"antenna\" + 0.015*\"new\" + 0.014*\"customer\" + 0.013*\"buy\" + 0.012*\"work\" + 0.012*\"service\" + 0.011*\"cheetah\" + 0.011*\"return\"\n",
      "2019-07-08 12:58:14,984 : INFO : topic #8 (0.074): 0.079*\"screw\" + 0.027*\"use\" + 0.022*\"stud\" + 0.014*\"long\" + 0.014*\"anchor\" + 0.012*\"bolt\" + 0.011*\"need\" + 0.011*\"drywall\" + 0.009*\"head\" + 0.009*\"inch\"\n",
      "2019-07-08 12:58:14,990 : INFO : topic #3 (0.159): 0.040*\"price\" + 0.037*\"good\" + 0.036*\"product\" + 0.035*\"great\" + 0.031*\"easy\" + 0.024*\"quality\" + 0.022*\"install\" + 0.022*\"buy\" + 0.022*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 12:58:14,993 : INFO : topic #1 (0.212): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.023*\"install\" + 0.019*\"inch\" + 0.015*\"use\" + 0.014*\"need\" + 0.014*\"flat\" + 0.014*\"hold\" + 0.013*\"screen\"\n",
      "2019-07-08 12:58:14,996 : INFO : topic #2 (0.275): 0.017*\"one\" + 0.016*\"would\" + 0.013*\"get\" + 0.009*\"go\" + 0.008*\"bracket\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.008*\"back\" + 0.007*\"two\" + 0.007*\"like\"\n",
      "2019-07-08 12:58:14,999 : INFO : topic diff=0.228268, rho=0.282172\n",
      "2019-07-08 12:58:15,040 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:58:17,906 : INFO : -6.992 per-word bound, 127.3 perplexity estimate based on a held-out corpus of 1119 documents with 49461 words\n",
      "2019-07-08 12:58:17,909 : INFO : PROGRESS: pass 5, at document #13119/13119\n",
      "2019-07-08 12:58:17,912 : DEBUG : performing inference on a chunk of 1119 documents\n",
      "2019-07-08 12:58:19,524 : DEBUG : 1119/1119 documents converged within 400 iterations\n",
      "2019-07-08 12:58:19,545 : INFO : optimized alpha [0.08354459, 0.21435635, 0.27946588, 0.16005084, 0.08312798, 0.0632973, 0.09109096, 0.109594226, 0.07462829, 0.09997117]\n",
      "2019-07-08 12:58:19,554 : DEBUG : updating topics\n",
      "2019-07-08 12:58:19,559 : INFO : merging changes from 1119 documents into a model of 13119 documents\n",
      "2019-07-08 12:58:19,585 : INFO : topic #5 (0.063): 0.049*\"antenna\" + 0.027*\"channel\" + 0.025*\"get\" + 0.015*\"mohu\" + 0.014*\"one\" + 0.013*\"signal\" + 0.012*\"work\" + 0.010*\"new\" + 0.009*\"good\" + 0.009*\"station\"\n",
      "2019-07-08 12:58:19,591 : INFO : topic #8 (0.075): 0.074*\"screw\" + 0.026*\"use\" + 0.020*\"stud\" + 0.014*\"anchor\" + 0.013*\"long\" + 0.012*\"bolt\" + 0.011*\"drywall\" + 0.011*\"need\" + 0.009*\"head\" + 0.008*\"wood\"\n",
      "2019-07-08 12:58:19,595 : INFO : topic #3 (0.160): 0.039*\"price\" + 0.037*\"good\" + 0.035*\"product\" + 0.034*\"great\" + 0.032*\"easy\" + 0.024*\"quality\" + 0.022*\"well\" + 0.022*\"install\" + 0.021*\"buy\" + 0.018*\"work\"\n",
      "2019-07-08 12:58:19,600 : INFO : topic #1 (0.214): 0.035*\"easy\" + 0.027*\"great\" + 0.026*\"work\" + 0.022*\"install\" + 0.019*\"inch\" + 0.016*\"use\" + 0.014*\"hold\" + 0.013*\"flat\" + 0.013*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 12:58:19,606 : INFO : topic #2 (0.279): 0.017*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.009*\"go\" + 0.008*\"make\" + 0.008*\"bracket\" + 0.007*\"two\" + 0.007*\"back\" + 0.007*\"like\" + 0.007*\"tilt\"\n",
      "2019-07-08 12:58:19,625 : INFO : topic diff=0.310364, rho=0.282172\n",
      "2019-07-08 12:58:19,670 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:58:24,605 : INFO : -6.797 per-word bound, 111.2 perplexity estimate based on a held-out corpus of 2000 documents with 76029 words\n",
      "2019-07-08 12:58:24,607 : INFO : PROGRESS: pass 6, at document #2000/13119\n",
      "2019-07-08 12:58:24,610 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:58:27,410 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:58:27,452 : INFO : optimized alpha [0.08211074, 0.21666598, 0.27970466, 0.16376309, 0.08364953, 0.061994202, 0.08981373, 0.11120856, 0.07484778, 0.100791775]\n",
      "2019-07-08 12:58:27,457 : DEBUG : updating topics\n",
      "2019-07-08 12:58:27,463 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:58:27,487 : INFO : topic #5 (0.062): 0.045*\"antenna\" + 0.025*\"get\" + 0.024*\"channel\" + 0.014*\"one\" + 0.013*\"mohu\" + 0.013*\"signal\" + 0.012*\"work\" + 0.011*\"new\" + 0.010*\"buy\" + 0.009*\"customer\"\n",
      "2019-07-08 12:58:27,491 : INFO : topic #8 (0.075): 0.082*\"screw\" + 0.027*\"use\" + 0.020*\"stud\" + 0.012*\"anchor\" + 0.012*\"long\" + 0.011*\"bolt\" + 0.011*\"head\" + 0.010*\"need\" + 0.010*\"drywall\" + 0.009*\"strip\"\n",
      "2019-07-08 12:58:27,501 : INFO : topic #3 (0.164): 0.039*\"price\" + 0.037*\"good\" + 0.035*\"great\" + 0.033*\"product\" + 0.031*\"easy\" + 0.026*\"quality\" + 0.023*\"buy\" + 0.022*\"install\" + 0.021*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 12:58:27,511 : INFO : topic #1 (0.217): 0.035*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.019*\"inch\" + 0.016*\"use\" + 0.014*\"hold\" + 0.014*\"screen\" + 0.014*\"flat\" + 0.013*\"need\"\n",
      "2019-07-08 12:58:27,518 : INFO : topic #2 (0.280): 0.017*\"one\" + 0.016*\"would\" + 0.012*\"get\" + 0.009*\"go\" + 0.009*\"bracket\" + 0.008*\"make\" + 0.007*\"tilt\" + 0.007*\"two\" + 0.007*\"back\" + 0.007*\"like\"\n",
      "2019-07-08 12:58:27,522 : INFO : topic diff=0.243343, rho=0.271568\n",
      "2019-07-08 12:58:27,565 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:58:33,303 : INFO : -6.802 per-word bound, 111.6 perplexity estimate based on a held-out corpus of 2000 documents with 79013 words\n",
      "2019-07-08 12:58:33,305 : INFO : PROGRESS: pass 6, at document #4000/13119\n",
      "2019-07-08 12:58:33,308 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:58:36,169 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:58:36,216 : INFO : optimized alpha [0.082715146, 0.22433501, 0.28639507, 0.1670078, 0.0835768, 0.061484344, 0.0897368, 0.11240362, 0.074685484, 0.102817304]\n",
      "2019-07-08 12:58:36,220 : DEBUG : updating topics\n",
      "2019-07-08 12:58:36,228 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:58:36,250 : INFO : topic #5 (0.061): 0.038*\"antenna\" + 0.024*\"get\" + 0.021*\"channel\" + 0.014*\"one\" + 0.012*\"customer\" + 0.011*\"work\" + 0.011*\"new\" + 0.011*\"mohu\" + 0.010*\"signal\" + 0.010*\"service\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 12:58:36,261 : INFO : topic #8 (0.075): 0.081*\"screw\" + 0.026*\"use\" + 0.021*\"stud\" + 0.013*\"anchor\" + 0.013*\"bolt\" + 0.012*\"long\" + 0.010*\"head\" + 0.010*\"need\" + 0.010*\"drywall\" + 0.009*\"wood\"\n",
      "2019-07-08 12:58:36,265 : INFO : topic #3 (0.167): 0.040*\"price\" + 0.037*\"good\" + 0.035*\"great\" + 0.034*\"product\" + 0.031*\"easy\" + 0.026*\"quality\" + 0.022*\"buy\" + 0.022*\"install\" + 0.021*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 12:58:36,276 : INFO : topic #1 (0.224): 0.035*\"easy\" + 0.027*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.019*\"inch\" + 0.016*\"use\" + 0.014*\"hold\" + 0.014*\"flat\" + 0.013*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 12:58:36,283 : INFO : topic #2 (0.286): 0.018*\"one\" + 0.016*\"would\" + 0.013*\"get\" + 0.009*\"go\" + 0.008*\"bracket\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"like\"\n",
      "2019-07-08 12:58:36,292 : INFO : topic diff=0.227031, rho=0.271568\n",
      "2019-07-08 12:58:36,316 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:58:41,767 : INFO : -6.789 per-word bound, 110.6 perplexity estimate based on a held-out corpus of 2000 documents with 75399 words\n",
      "2019-07-08 12:58:41,770 : INFO : PROGRESS: pass 6, at document #6000/13119\n",
      "2019-07-08 12:58:41,773 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:58:45,050 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:58:45,093 : INFO : optimized alpha [0.08619003, 0.22669771, 0.29498622, 0.17110202, 0.08321299, 0.06136215, 0.0895274, 0.10924786, 0.075613536, 0.105166964]\n",
      "2019-07-08 12:58:45,106 : DEBUG : updating topics\n",
      "2019-07-08 12:58:45,110 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:58:45,131 : INFO : topic #5 (0.061): 0.030*\"antenna\" + 0.024*\"get\" + 0.017*\"channel\" + 0.015*\"one\" + 0.015*\"customer\" + 0.012*\"new\" + 0.012*\"service\" + 0.011*\"cheetah\" + 0.011*\"work\" + 0.010*\"buy\"\n",
      "2019-07-08 12:58:45,140 : INFO : topic #8 (0.076): 0.087*\"screw\" + 0.026*\"use\" + 0.020*\"stud\" + 0.014*\"long\" + 0.013*\"bolt\" + 0.012*\"anchor\" + 0.011*\"need\" + 0.010*\"head\" + 0.009*\"drywall\" + 0.009*\"bottom\"\n",
      "2019-07-08 12:58:45,150 : INFO : topic #3 (0.171): 0.041*\"price\" + 0.036*\"good\" + 0.035*\"great\" + 0.034*\"product\" + 0.032*\"easy\" + 0.024*\"quality\" + 0.023*\"install\" + 0.023*\"buy\" + 0.020*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 12:58:45,154 : INFO : topic #1 (0.227): 0.035*\"easy\" + 0.027*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.019*\"inch\" + 0.015*\"use\" + 0.015*\"hold\" + 0.014*\"flat\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 12:58:45,157 : INFO : topic #2 (0.295): 0.018*\"one\" + 0.016*\"would\" + 0.013*\"get\" + 0.009*\"go\" + 0.009*\"bracket\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"could\"\n",
      "2019-07-08 12:58:45,160 : INFO : topic diff=0.221579, rho=0.271568\n",
      "2019-07-08 12:58:45,198 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:58:50,917 : INFO : -6.775 per-word bound, 109.5 perplexity estimate based on a held-out corpus of 2000 documents with 73605 words\n",
      "2019-07-08 12:58:50,920 : INFO : PROGRESS: pass 6, at document #8000/13119\n",
      "2019-07-08 12:58:50,925 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:58:53,775 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:58:53,827 : INFO : optimized alpha [0.08822444, 0.23412833, 0.2990486, 0.17613828, 0.08237834, 0.06140849, 0.08948971, 0.10828061, 0.07618241, 0.10742833]\n",
      "2019-07-08 12:58:53,829 : DEBUG : updating topics\n",
      "2019-07-08 12:58:53,832 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:58:53,859 : INFO : topic #5 (0.061): 0.024*\"get\" + 0.024*\"antenna\" + 0.016*\"customer\" + 0.015*\"one\" + 0.014*\"cheetah\" + 0.014*\"channel\" + 0.012*\"service\" + 0.012*\"new\" + 0.011*\"work\" + 0.011*\"buy\"\n",
      "2019-07-08 12:58:53,862 : INFO : topic #8 (0.076): 0.087*\"screw\" + 0.026*\"use\" + 0.022*\"stud\" + 0.014*\"long\" + 0.014*\"bolt\" + 0.013*\"anchor\" + 0.011*\"need\" + 0.010*\"head\" + 0.009*\"drywall\" + 0.009*\"tighten\"\n",
      "2019-07-08 12:58:53,864 : INFO : topic #3 (0.176): 0.041*\"price\" + 0.036*\"good\" + 0.035*\"great\" + 0.035*\"product\" + 0.032*\"easy\" + 0.024*\"quality\" + 0.024*\"buy\" + 0.023*\"install\" + 0.021*\"well\" + 0.016*\"work\"\n",
      "2019-07-08 12:58:53,866 : INFO : topic #1 (0.234): 0.035*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.022*\"install\" + 0.019*\"inch\" + 0.015*\"hold\" + 0.015*\"use\" + 0.014*\"screen\" + 0.013*\"need\" + 0.013*\"flat\"\n",
      "2019-07-08 12:58:53,869 : INFO : topic #2 (0.299): 0.018*\"one\" + 0.016*\"would\" + 0.013*\"get\" + 0.009*\"go\" + 0.009*\"bracket\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"like\"\n",
      "2019-07-08 12:58:53,876 : INFO : topic diff=0.211907, rho=0.271568\n",
      "2019-07-08 12:58:53,924 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:58:59,398 : INFO : -6.888 per-word bound, 118.5 perplexity estimate based on a held-out corpus of 2000 documents with 85614 words\n",
      "2019-07-08 12:58:59,400 : INFO : PROGRESS: pass 6, at document #10000/13119\n",
      "2019-07-08 12:58:59,404 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:59:02,600 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:59:02,645 : INFO : optimized alpha [0.088380374, 0.23803712, 0.31080934, 0.17988363, 0.08360197, 0.06197162, 0.092653535, 0.10989015, 0.07745184, 0.10903107]\n",
      "2019-07-08 12:59:02,651 : DEBUG : updating topics\n",
      "2019-07-08 12:59:02,654 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:59:02,668 : INFO : topic #5 (0.062): 0.023*\"get\" + 0.020*\"antenna\" + 0.017*\"customer\" + 0.015*\"cheetah\" + 0.014*\"one\" + 0.014*\"new\" + 0.013*\"service\" + 0.011*\"channel\" + 0.011*\"work\" + 0.011*\"buy\"\n",
      "2019-07-08 12:59:02,683 : INFO : topic #8 (0.077): 0.083*\"screw\" + 0.026*\"use\" + 0.022*\"stud\" + 0.014*\"long\" + 0.014*\"anchor\" + 0.013*\"bolt\" + 0.011*\"need\" + 0.010*\"drywall\" + 0.009*\"head\" + 0.009*\"inch\"\n",
      "2019-07-08 12:59:02,687 : INFO : topic #3 (0.180): 0.040*\"price\" + 0.036*\"good\" + 0.036*\"product\" + 0.034*\"great\" + 0.031*\"easy\" + 0.025*\"quality\" + 0.023*\"buy\" + 0.021*\"install\" + 0.021*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 12:59:02,692 : INFO : topic #1 (0.238): 0.034*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.020*\"inch\" + 0.015*\"use\" + 0.015*\"hold\" + 0.014*\"flat\" + 0.013*\"need\" + 0.013*\"screen\"\n",
      "2019-07-08 12:59:02,702 : INFO : topic #2 (0.311): 0.017*\"one\" + 0.016*\"would\" + 0.013*\"get\" + 0.009*\"go\" + 0.009*\"bracket\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.008*\"back\" + 0.007*\"like\" + 0.007*\"two\"\n",
      "2019-07-08 12:59:02,713 : INFO : topic diff=0.242615, rho=0.271568\n",
      "2019-07-08 12:59:02,762 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:59:08,108 : INFO : -6.914 per-word bound, 120.6 perplexity estimate based on a held-out corpus of 2000 documents with 69590 words\n",
      "2019-07-08 12:59:08,110 : INFO : PROGRESS: pass 6, at document #12000/13119\n",
      "2019-07-08 12:59:08,114 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:59:10,846 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:59:10,896 : INFO : optimized alpha [0.08827251, 0.24117428, 0.31459656, 0.18282558, 0.0847732, 0.062153477, 0.09412629, 0.11446876, 0.07902571, 0.10867183]\n",
      "2019-07-08 12:59:10,899 : DEBUG : updating topics\n",
      "2019-07-08 12:59:10,913 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:59:10,939 : INFO : topic #5 (0.062): 0.022*\"get\" + 0.018*\"antenna\" + 0.015*\"customer\" + 0.015*\"one\" + 0.015*\"new\" + 0.013*\"service\" + 0.012*\"cheetah\" + 0.011*\"work\" + 0.011*\"buy\" + 0.011*\"return\"\n",
      "2019-07-08 12:59:10,942 : INFO : topic #8 (0.079): 0.082*\"screw\" + 0.028*\"use\" + 0.023*\"stud\" + 0.015*\"anchor\" + 0.014*\"long\" + 0.013*\"bolt\" + 0.012*\"drywall\" + 0.011*\"need\" + 0.010*\"head\" + 0.008*\"inch\"\n",
      "2019-07-08 12:59:10,945 : INFO : topic #3 (0.183): 0.041*\"price\" + 0.037*\"good\" + 0.036*\"product\" + 0.035*\"great\" + 0.031*\"easy\" + 0.024*\"quality\" + 0.023*\"buy\" + 0.022*\"well\" + 0.022*\"install\" + 0.018*\"work\"\n",
      "2019-07-08 12:59:10,948 : INFO : topic #1 (0.241): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.023*\"install\" + 0.020*\"inch\" + 0.015*\"use\" + 0.014*\"flat\" + 0.014*\"hold\" + 0.014*\"screen\" + 0.014*\"need\"\n",
      "2019-07-08 12:59:10,951 : INFO : topic #2 (0.315): 0.017*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.008*\"make\" + 0.008*\"bracket\" + 0.008*\"tilt\" + 0.008*\"back\" + 0.007*\"two\" + 0.007*\"like\"\n",
      "2019-07-08 12:59:10,954 : INFO : topic diff=0.205510, rho=0.271568\n",
      "2019-07-08 12:59:10,991 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:59:13,538 : INFO : -6.981 per-word bound, 126.3 perplexity estimate based on a held-out corpus of 1119 documents with 49461 words\n",
      "2019-07-08 12:59:13,540 : INFO : PROGRESS: pass 6, at document #13119/13119\n",
      "2019-07-08 12:59:13,543 : DEBUG : performing inference on a chunk of 1119 documents\n",
      "2019-07-08 12:59:15,051 : DEBUG : 1119/1119 documents converged within 400 iterations\n",
      "2019-07-08 12:59:15,069 : INFO : optimized alpha [0.088409506, 0.24403799, 0.32003903, 0.18302773, 0.08797997, 0.06378352, 0.09767519, 0.116345525, 0.080033526, 0.108622745]\n",
      "2019-07-08 12:59:15,074 : DEBUG : updating topics\n",
      "2019-07-08 12:59:15,077 : INFO : merging changes from 1119 documents into a model of 13119 documents\n",
      "2019-07-08 12:59:15,097 : INFO : topic #5 (0.064): 0.050*\"antenna\" + 0.027*\"channel\" + 0.025*\"get\" + 0.015*\"mohu\" + 0.013*\"signal\" + 0.013*\"one\" + 0.011*\"work\" + 0.010*\"new\" + 0.009*\"station\" + 0.009*\"customer\"\n",
      "2019-07-08 12:59:15,112 : INFO : topic #8 (0.080): 0.077*\"screw\" + 0.027*\"use\" + 0.021*\"stud\" + 0.015*\"anchor\" + 0.014*\"long\" + 0.013*\"bolt\" + 0.012*\"drywall\" + 0.010*\"need\" + 0.009*\"head\" + 0.008*\"wood\"\n",
      "2019-07-08 12:59:15,120 : INFO : topic #3 (0.183): 0.040*\"price\" + 0.037*\"good\" + 0.035*\"product\" + 0.035*\"great\" + 0.031*\"easy\" + 0.025*\"quality\" + 0.022*\"well\" + 0.022*\"buy\" + 0.021*\"install\" + 0.018*\"work\"\n",
      "2019-07-08 12:59:15,124 : INFO : topic #1 (0.244): 0.035*\"easy\" + 0.027*\"great\" + 0.026*\"work\" + 0.022*\"install\" + 0.020*\"inch\" + 0.016*\"use\" + 0.015*\"hold\" + 0.014*\"flat\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 12:59:15,129 : INFO : topic #2 (0.320): 0.017*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.009*\"go\" + 0.009*\"make\" + 0.007*\"bracket\" + 0.007*\"two\" + 0.007*\"back\" + 0.007*\"like\" + 0.007*\"tilt\"\n",
      "2019-07-08 12:59:15,143 : INFO : topic diff=0.286779, rho=0.271568\n",
      "2019-07-08 12:59:15,185 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:59:20,272 : INFO : -6.794 per-word bound, 111.0 perplexity estimate based on a held-out corpus of 2000 documents with 76029 words\n",
      "2019-07-08 12:59:20,274 : INFO : PROGRESS: pass 7, at document #2000/13119\n",
      "2019-07-08 12:59:20,277 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:59:23,033 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:59:23,061 : INFO : optimized alpha [0.08684451, 0.24671955, 0.32129765, 0.18747006, 0.08851191, 0.06255453, 0.09630437, 0.117873415, 0.08024993, 0.109552376]\n",
      "2019-07-08 12:59:23,063 : DEBUG : updating topics\n",
      "2019-07-08 12:59:23,066 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:59:23,077 : INFO : topic #5 (0.063): 0.047*\"antenna\" + 0.025*\"get\" + 0.025*\"channel\" + 0.013*\"mohu\" + 0.013*\"signal\" + 0.013*\"one\" + 0.011*\"work\" + 0.011*\"new\" + 0.010*\"customer\" + 0.009*\"station\"\n",
      "2019-07-08 12:59:23,080 : INFO : topic #8 (0.080): 0.085*\"screw\" + 0.028*\"use\" + 0.021*\"stud\" + 0.013*\"anchor\" + 0.013*\"long\" + 0.013*\"bolt\" + 0.011*\"head\" + 0.011*\"drywall\" + 0.010*\"need\" + 0.009*\"strip\"\n",
      "2019-07-08 12:59:23,083 : INFO : topic #3 (0.187): 0.040*\"price\" + 0.037*\"good\" + 0.035*\"great\" + 0.033*\"product\" + 0.030*\"easy\" + 0.026*\"quality\" + 0.023*\"buy\" + 0.022*\"install\" + 0.022*\"well\" + 0.018*\"work\"\n",
      "2019-07-08 12:59:23,085 : INFO : topic #1 (0.247): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.022*\"install\" + 0.020*\"inch\" + 0.016*\"use\" + 0.015*\"hold\" + 0.014*\"flat\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 12:59:23,089 : INFO : topic #2 (0.321): 0.018*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.008*\"make\" + 0.008*\"bracket\" + 0.007*\"tilt\" + 0.007*\"two\" + 0.007*\"back\" + 0.007*\"like\"\n",
      "2019-07-08 12:59:23,091 : INFO : topic diff=0.219255, rho=0.262076\n",
      "2019-07-08 12:59:23,118 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:59:27,682 : INFO : -6.798 per-word bound, 111.3 perplexity estimate based on a held-out corpus of 2000 documents with 79013 words\n",
      "2019-07-08 12:59:27,684 : INFO : PROGRESS: pass 7, at document #4000/13119\n",
      "2019-07-08 12:59:27,686 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:59:30,402 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:59:30,429 : INFO : optimized alpha [0.08743359, 0.2553596, 0.32970154, 0.19076721, 0.088410676, 0.06207419, 0.09611009, 0.1189395, 0.08001061, 0.11169142]\n",
      "2019-07-08 12:59:30,431 : DEBUG : updating topics\n",
      "2019-07-08 12:59:30,434 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:59:30,447 : INFO : topic #5 (0.062): 0.040*\"antenna\" + 0.024*\"get\" + 0.022*\"channel\" + 0.013*\"customer\" + 0.013*\"one\" + 0.011*\"mohu\" + 0.011*\"new\" + 0.011*\"signal\" + 0.011*\"work\" + 0.010*\"service\"\n",
      "2019-07-08 12:59:30,450 : INFO : topic #8 (0.080): 0.085*\"screw\" + 0.027*\"use\" + 0.021*\"stud\" + 0.014*\"anchor\" + 0.014*\"bolt\" + 0.012*\"long\" + 0.011*\"drywall\" + 0.011*\"head\" + 0.010*\"need\" + 0.010*\"wood\"\n",
      "2019-07-08 12:59:30,453 : INFO : topic #3 (0.191): 0.040*\"price\" + 0.037*\"good\" + 0.035*\"great\" + 0.034*\"product\" + 0.031*\"easy\" + 0.026*\"quality\" + 0.023*\"buy\" + 0.022*\"install\" + 0.021*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 12:59:30,456 : INFO : topic #1 (0.255): 0.034*\"easy\" + 0.027*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.020*\"inch\" + 0.016*\"use\" + 0.014*\"flat\" + 0.014*\"hold\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 12:59:30,460 : INFO : topic #2 (0.330): 0.018*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.008*\"make\" + 0.008*\"bracket\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"like\"\n",
      "2019-07-08 12:59:30,463 : INFO : topic diff=0.205162, rho=0.262076\n",
      "2019-07-08 12:59:30,488 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:59:34,880 : INFO : -6.784 per-word bound, 110.2 perplexity estimate based on a held-out corpus of 2000 documents with 75399 words\n",
      "2019-07-08 12:59:34,882 : INFO : PROGRESS: pass 7, at document #6000/13119\n",
      "2019-07-08 12:59:34,885 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:59:37,646 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:59:37,679 : INFO : optimized alpha [0.090948805, 0.25807166, 0.3411723, 0.19537494, 0.088035375, 0.061951704, 0.09597029, 0.11553259, 0.0809501, 0.1139424]\n",
      "2019-07-08 12:59:37,681 : DEBUG : updating topics\n",
      "2019-07-08 12:59:37,684 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:59:37,695 : INFO : topic #5 (0.062): 0.032*\"antenna\" + 0.025*\"get\" + 0.018*\"channel\" + 0.016*\"customer\" + 0.013*\"one\" + 0.012*\"service\" + 0.012*\"new\" + 0.011*\"cheetah\" + 0.010*\"work\" + 0.009*\"return\"\n",
      "2019-07-08 12:59:37,698 : INFO : topic #8 (0.081): 0.090*\"screw\" + 0.027*\"use\" + 0.020*\"stud\" + 0.015*\"long\" + 0.014*\"bolt\" + 0.013*\"anchor\" + 0.010*\"need\" + 0.010*\"head\" + 0.009*\"drywall\" + 0.009*\"bottom\"\n",
      "2019-07-08 12:59:37,701 : INFO : topic #3 (0.195): 0.042*\"price\" + 0.037*\"good\" + 0.035*\"great\" + 0.034*\"product\" + 0.032*\"easy\" + 0.025*\"quality\" + 0.023*\"buy\" + 0.022*\"install\" + 0.020*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 12:59:37,704 : INFO : topic #1 (0.258): 0.035*\"easy\" + 0.027*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.020*\"inch\" + 0.016*\"use\" + 0.015*\"hold\" + 0.015*\"flat\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 12:59:37,707 : INFO : topic #2 (0.341): 0.018*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.008*\"make\" + 0.008*\"bracket\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"could\"\n",
      "2019-07-08 12:59:37,709 : INFO : topic diff=0.200257, rho=0.262076\n",
      "2019-07-08 12:59:37,733 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:59:42,104 : INFO : -6.771 per-word bound, 109.2 perplexity estimate based on a held-out corpus of 2000 documents with 73605 words\n",
      "2019-07-08 12:59:42,106 : INFO : PROGRESS: pass 7, at document #8000/13119\n",
      "2019-07-08 12:59:42,109 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:59:44,932 : DEBUG : 2000/2000 documents converged within 400 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 12:59:44,959 : INFO : optimized alpha [0.092969865, 0.26658702, 0.34728125, 0.20082594, 0.08715381, 0.061977215, 0.09590495, 0.11440707, 0.081637904, 0.1162838]\n",
      "2019-07-08 12:59:44,961 : DEBUG : updating topics\n",
      "2019-07-08 12:59:44,963 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:59:44,975 : INFO : topic #5 (0.062): 0.026*\"antenna\" + 0.025*\"get\" + 0.017*\"customer\" + 0.015*\"channel\" + 0.014*\"cheetah\" + 0.013*\"one\" + 0.013*\"service\" + 0.012*\"new\" + 0.010*\"work\" + 0.009*\"return\"\n",
      "2019-07-08 12:59:44,978 : INFO : topic #8 (0.082): 0.090*\"screw\" + 0.027*\"use\" + 0.022*\"stud\" + 0.015*\"bolt\" + 0.015*\"long\" + 0.014*\"anchor\" + 0.011*\"need\" + 0.010*\"head\" + 0.010*\"drywall\" + 0.009*\"tighten\"\n",
      "2019-07-08 12:59:44,981 : INFO : topic #3 (0.201): 0.042*\"price\" + 0.036*\"good\" + 0.035*\"great\" + 0.035*\"product\" + 0.031*\"easy\" + 0.025*\"buy\" + 0.024*\"quality\" + 0.022*\"install\" + 0.021*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 12:59:44,983 : INFO : topic #1 (0.267): 0.035*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.022*\"install\" + 0.020*\"inch\" + 0.016*\"hold\" + 0.016*\"use\" + 0.014*\"screen\" + 0.014*\"flat\" + 0.013*\"need\"\n",
      "2019-07-08 12:59:44,986 : INFO : topic #2 (0.347): 0.018*\"one\" + 0.016*\"would\" + 0.013*\"get\" + 0.009*\"go\" + 0.008*\"bracket\" + 0.008*\"make\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"like\"\n",
      "2019-07-08 12:59:44,989 : INFO : topic diff=0.190446, rho=0.262076\n",
      "2019-07-08 12:59:45,019 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:59:49,702 : INFO : -6.883 per-word bound, 118.1 perplexity estimate based on a held-out corpus of 2000 documents with 85614 words\n",
      "2019-07-08 12:59:49,704 : INFO : PROGRESS: pass 7, at document #10000/13119\n",
      "2019-07-08 12:59:49,707 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:59:52,675 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:59:52,702 : INFO : optimized alpha [0.09304369, 0.27176836, 0.361463, 0.20472649, 0.08845766, 0.06253002, 0.099075675, 0.11597394, 0.08297247, 0.117902726]\n",
      "2019-07-08 12:59:52,704 : DEBUG : updating topics\n",
      "2019-07-08 12:59:52,707 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:59:52,717 : INFO : topic #5 (0.063): 0.024*\"get\" + 0.021*\"antenna\" + 0.019*\"customer\" + 0.015*\"cheetah\" + 0.014*\"service\" + 0.014*\"new\" + 0.013*\"one\" + 0.012*\"channel\" + 0.011*\"return\" + 0.010*\"work\"\n",
      "2019-07-08 12:59:52,720 : INFO : topic #8 (0.083): 0.086*\"screw\" + 0.027*\"use\" + 0.023*\"stud\" + 0.015*\"long\" + 0.015*\"bolt\" + 0.015*\"anchor\" + 0.011*\"need\" + 0.010*\"drywall\" + 0.009*\"head\" + 0.009*\"tighten\"\n",
      "2019-07-08 12:59:52,723 : INFO : topic #3 (0.205): 0.041*\"price\" + 0.036*\"good\" + 0.036*\"product\" + 0.034*\"great\" + 0.030*\"easy\" + 0.025*\"quality\" + 0.024*\"buy\" + 0.021*\"well\" + 0.021*\"install\" + 0.017*\"work\"\n",
      "2019-07-08 12:59:52,728 : INFO : topic #1 (0.272): 0.034*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.022*\"install\" + 0.021*\"inch\" + 0.015*\"use\" + 0.015*\"hold\" + 0.014*\"flat\" + 0.013*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 12:59:52,732 : INFO : topic #2 (0.361): 0.017*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"bracket\" + 0.008*\"tilt\" + 0.008*\"back\" + 0.007*\"like\" + 0.007*\"could\"\n",
      "2019-07-08 12:59:52,735 : INFO : topic diff=0.220426, rho=0.262076\n",
      "2019-07-08 12:59:52,756 : DEBUG : bound: at document #0\n",
      "2019-07-08 12:59:56,840 : INFO : -6.909 per-word bound, 120.2 perplexity estimate based on a held-out corpus of 2000 documents with 69590 words\n",
      "2019-07-08 12:59:56,843 : INFO : PROGRESS: pass 7, at document #12000/13119\n",
      "2019-07-08 12:59:56,845 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 12:59:59,437 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 12:59:59,466 : INFO : optimized alpha [0.09296279, 0.27592555, 0.3676953, 0.20784116, 0.089697555, 0.06268614, 0.10051, 0.12047387, 0.08467612, 0.117542714]\n",
      "2019-07-08 12:59:59,468 : DEBUG : updating topics\n",
      "2019-07-08 12:59:59,471 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 12:59:59,482 : INFO : topic #5 (0.063): 0.023*\"get\" + 0.020*\"antenna\" + 0.016*\"customer\" + 0.015*\"new\" + 0.013*\"service\" + 0.013*\"one\" + 0.012*\"cheetah\" + 0.011*\"return\" + 0.011*\"work\" + 0.010*\"channel\"\n",
      "2019-07-08 12:59:59,486 : INFO : topic #8 (0.085): 0.084*\"screw\" + 0.029*\"use\" + 0.023*\"stud\" + 0.016*\"anchor\" + 0.015*\"long\" + 0.015*\"bolt\" + 0.012*\"drywall\" + 0.011*\"need\" + 0.010*\"head\" + 0.009*\"tighten\"\n",
      "2019-07-08 12:59:59,489 : INFO : topic #3 (0.208): 0.042*\"price\" + 0.037*\"good\" + 0.036*\"product\" + 0.035*\"great\" + 0.030*\"easy\" + 0.024*\"quality\" + 0.024*\"buy\" + 0.022*\"well\" + 0.021*\"install\" + 0.018*\"work\"\n",
      "2019-07-08 12:59:59,493 : INFO : topic #1 (0.276): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.023*\"install\" + 0.021*\"inch\" + 0.016*\"use\" + 0.015*\"flat\" + 0.015*\"hold\" + 0.014*\"screen\" + 0.014*\"need\"\n",
      "2019-07-08 12:59:59,496 : INFO : topic #2 (0.368): 0.018*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"bracket\" + 0.008*\"tilt\" + 0.008*\"back\" + 0.007*\"like\" + 0.007*\"two\"\n",
      "2019-07-08 12:59:59,499 : INFO : topic diff=0.184438, rho=0.262076\n",
      "2019-07-08 12:59:59,521 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:00:02,011 : INFO : -6.973 per-word bound, 125.6 perplexity estimate based on a held-out corpus of 1119 documents with 49461 words\n",
      "2019-07-08 13:00:02,014 : INFO : PROGRESS: pass 7, at document #13119/13119\n",
      "2019-07-08 13:00:02,016 : DEBUG : performing inference on a chunk of 1119 documents\n",
      "2019-07-08 13:00:03,487 : DEBUG : 1119/1119 documents converged within 400 iterations\n",
      "2019-07-08 13:00:03,504 : INFO : optimized alpha [0.09309025, 0.27914143, 0.37472817, 0.20823996, 0.09300205, 0.06433146, 0.10416963, 0.12239256, 0.085608065, 0.11725979]\n",
      "2019-07-08 13:00:03,506 : DEBUG : updating topics\n",
      "2019-07-08 13:00:03,509 : INFO : merging changes from 1119 documents into a model of 13119 documents\n",
      "2019-07-08 13:00:03,519 : INFO : topic #5 (0.064): 0.052*\"antenna\" + 0.028*\"channel\" + 0.025*\"get\" + 0.016*\"mohu\" + 0.013*\"signal\" + 0.011*\"one\" + 0.011*\"work\" + 0.010*\"new\" + 0.010*\"customer\" + 0.010*\"station\"\n",
      "2019-07-08 13:00:03,522 : INFO : topic #8 (0.086): 0.080*\"screw\" + 0.028*\"use\" + 0.022*\"stud\" + 0.016*\"anchor\" + 0.015*\"bolt\" + 0.014*\"long\" + 0.013*\"drywall\" + 0.010*\"need\" + 0.009*\"head\" + 0.009*\"wood\"\n",
      "2019-07-08 13:00:03,525 : INFO : topic #3 (0.208): 0.041*\"price\" + 0.038*\"good\" + 0.035*\"product\" + 0.035*\"great\" + 0.031*\"easy\" + 0.025*\"quality\" + 0.022*\"buy\" + 0.022*\"well\" + 0.021*\"install\" + 0.018*\"work\"\n",
      "2019-07-08 13:00:03,528 : INFO : topic #1 (0.279): 0.035*\"easy\" + 0.027*\"great\" + 0.026*\"work\" + 0.022*\"install\" + 0.021*\"inch\" + 0.017*\"use\" + 0.015*\"hold\" + 0.015*\"flat\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 13:00:03,533 : INFO : topic #2 (0.375): 0.018*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.007*\"like\" + 0.007*\"back\" + 0.007*\"bracket\" + 0.007*\"two\" + 0.007*\"tilt\"\n",
      "2019-07-08 13:00:03,535 : INFO : topic diff=0.265473, rho=0.262076\n",
      "2019-07-08 13:00:03,564 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:00:08,008 : INFO : -6.791 per-word bound, 110.8 perplexity estimate based on a held-out corpus of 2000 documents with 76029 words\n",
      "2019-07-08 13:00:08,010 : INFO : PROGRESS: pass 8, at document #2000/13119\n",
      "2019-07-08 13:00:08,012 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:00:10,834 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:00:10,862 : INFO : optimized alpha [0.091413476, 0.2832595, 0.37757933, 0.21353541, 0.093560055, 0.063209005, 0.102760226, 0.12401942, 0.085859336, 0.11814829]\n",
      "2019-07-08 13:00:10,864 : DEBUG : updating topics\n",
      "2019-07-08 13:00:10,866 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:00:10,876 : INFO : topic #5 (0.063): 0.049*\"antenna\" + 0.026*\"channel\" + 0.025*\"get\" + 0.014*\"mohu\" + 0.013*\"signal\" + 0.011*\"one\" + 0.011*\"new\" + 0.011*\"work\" + 0.010*\"customer\" + 0.009*\"station\"\n",
      "2019-07-08 13:00:10,879 : INFO : topic #8 (0.086): 0.087*\"screw\" + 0.029*\"use\" + 0.022*\"stud\" + 0.015*\"bolt\" + 0.014*\"anchor\" + 0.014*\"long\" + 0.011*\"drywall\" + 0.011*\"head\" + 0.010*\"need\" + 0.010*\"wood\"\n",
      "2019-07-08 13:00:10,883 : INFO : topic #3 (0.214): 0.042*\"price\" + 0.037*\"good\" + 0.035*\"great\" + 0.034*\"product\" + 0.030*\"easy\" + 0.026*\"quality\" + 0.024*\"buy\" + 0.022*\"well\" + 0.021*\"install\" + 0.018*\"work\"\n",
      "2019-07-08 13:00:10,886 : INFO : topic #1 (0.283): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.022*\"install\" + 0.021*\"inch\" + 0.017*\"use\" + 0.015*\"hold\" + 0.015*\"flat\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 13:00:10,889 : INFO : topic #2 (0.378): 0.018*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"bracket\" + 0.007*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"like\"\n",
      "2019-07-08 13:00:10,892 : INFO : topic diff=0.197703, rho=0.253514\n",
      "2019-07-08 13:00:10,914 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:00:15,340 : INFO : -6.793 per-word bound, 110.9 perplexity estimate based on a held-out corpus of 2000 documents with 79013 words\n",
      "2019-07-08 13:00:15,343 : INFO : PROGRESS: pass 8, at document #4000/13119\n",
      "2019-07-08 13:00:15,345 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:00:18,076 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:00:18,103 : INFO : optimized alpha [0.09193079, 0.29243985, 0.38863382, 0.21709768, 0.093391515, 0.06277507, 0.10251789, 0.12512088, 0.08557214, 0.12026331]\n",
      "2019-07-08 13:00:18,105 : DEBUG : updating topics\n",
      "2019-07-08 13:00:18,110 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:00:18,119 : INFO : topic #5 (0.063): 0.041*\"antenna\" + 0.025*\"get\" + 0.023*\"channel\" + 0.014*\"customer\" + 0.012*\"mohu\" + 0.011*\"signal\" + 0.011*\"one\" + 0.011*\"new\" + 0.011*\"service\" + 0.010*\"work\"\n",
      "2019-07-08 13:00:18,122 : INFO : topic #8 (0.086): 0.087*\"screw\" + 0.029*\"use\" + 0.022*\"stud\" + 0.016*\"bolt\" + 0.015*\"anchor\" + 0.013*\"long\" + 0.011*\"drywall\" + 0.011*\"head\" + 0.010*\"need\" + 0.010*\"wood\"\n",
      "2019-07-08 13:00:18,125 : INFO : topic #3 (0.217): 0.042*\"price\" + 0.037*\"good\" + 0.035*\"great\" + 0.034*\"product\" + 0.030*\"easy\" + 0.026*\"quality\" + 0.024*\"buy\" + 0.022*\"install\" + 0.022*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 13:00:18,128 : INFO : topic #1 (0.292): 0.035*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.023*\"install\" + 0.020*\"inch\" + 0.016*\"use\" + 0.015*\"flat\" + 0.015*\"hold\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 13:00:18,131 : INFO : topic #2 (0.389): 0.018*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.008*\"make\" + 0.008*\"bracket\" + 0.007*\"tilt\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"like\"\n",
      "2019-07-08 13:00:18,134 : INFO : topic diff=0.185070, rho=0.253514\n",
      "2019-07-08 13:00:18,158 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:00:22,550 : INFO : -6.779 per-word bound, 109.8 perplexity estimate based on a held-out corpus of 2000 documents with 75399 words\n",
      "2019-07-08 13:00:22,552 : INFO : PROGRESS: pass 8, at document #6000/13119\n",
      "2019-07-08 13:00:22,555 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:00:25,454 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:00:25,485 : INFO : optimized alpha [0.095484726, 0.2960602, 0.40340275, 0.22242832, 0.09306435, 0.062623225, 0.102297135, 0.121686555, 0.08658014, 0.12246341]\n",
      "2019-07-08 13:00:25,487 : DEBUG : updating topics\n",
      "2019-07-08 13:00:25,490 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:00:25,500 : INFO : topic #5 (0.063): 0.034*\"antenna\" + 0.025*\"get\" + 0.019*\"channel\" + 0.016*\"customer\" + 0.013*\"service\" + 0.012*\"one\" + 0.012*\"new\" + 0.011*\"cheetah\" + 0.010*\"work\" + 0.010*\"mohu\"\n",
      "2019-07-08 13:00:25,504 : INFO : topic #8 (0.087): 0.092*\"screw\" + 0.028*\"use\" + 0.021*\"stud\" + 0.016*\"bolt\" + 0.015*\"long\" + 0.014*\"anchor\" + 0.010*\"need\" + 0.010*\"head\" + 0.010*\"drywall\" + 0.010*\"bottom\"\n",
      "2019-07-08 13:00:25,506 : INFO : topic #3 (0.222): 0.043*\"price\" + 0.037*\"good\" + 0.035*\"great\" + 0.034*\"product\" + 0.031*\"easy\" + 0.025*\"quality\" + 0.024*\"buy\" + 0.022*\"install\" + 0.021*\"well\" + 0.018*\"work\"\n",
      "2019-07-08 13:00:25,509 : INFO : topic #1 (0.296): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.023*\"install\" + 0.020*\"inch\" + 0.016*\"use\" + 0.016*\"hold\" + 0.015*\"flat\" + 0.015*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 13:00:25,512 : INFO : topic #2 (0.403): 0.018*\"one\" + 0.017*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.008*\"make\" + 0.008*\"bracket\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"could\" + 0.007*\"two\"\n",
      "2019-07-08 13:00:25,515 : INFO : topic diff=0.180946, rho=0.253514\n",
      "2019-07-08 13:00:25,538 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:00:29,856 : INFO : -6.767 per-word bound, 108.9 perplexity estimate based on a held-out corpus of 2000 documents with 73605 words\n",
      "2019-07-08 13:00:29,858 : INFO : PROGRESS: pass 8, at document #8000/13119\n",
      "2019-07-08 13:00:29,861 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:00:32,610 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:00:32,637 : INFO : optimized alpha [0.097420886, 0.30630594, 0.41216946, 0.22908835, 0.092182696, 0.062636524, 0.10220965, 0.12062024, 0.08732156, 0.12480086]\n",
      "2019-07-08 13:00:32,639 : DEBUG : updating topics\n",
      "2019-07-08 13:00:32,642 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:00:32,652 : INFO : topic #5 (0.063): 0.028*\"antenna\" + 0.025*\"get\" + 0.018*\"customer\" + 0.016*\"channel\" + 0.014*\"cheetah\" + 0.013*\"service\" + 0.012*\"new\" + 0.012*\"one\" + 0.010*\"work\" + 0.009*\"return\"\n",
      "2019-07-08 13:00:32,656 : INFO : topic #8 (0.087): 0.092*\"screw\" + 0.029*\"use\" + 0.023*\"stud\" + 0.017*\"bolt\" + 0.015*\"long\" + 0.015*\"anchor\" + 0.011*\"need\" + 0.010*\"tighten\" + 0.010*\"drywall\" + 0.010*\"head\"\n",
      "2019-07-08 13:00:32,659 : INFO : topic #3 (0.229): 0.043*\"price\" + 0.036*\"good\" + 0.035*\"great\" + 0.035*\"product\" + 0.031*\"easy\" + 0.025*\"buy\" + 0.025*\"quality\" + 0.022*\"install\" + 0.021*\"well\" + 0.017*\"work\"\n",
      "2019-07-08 13:00:32,662 : INFO : topic #1 (0.306): 0.035*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.022*\"install\" + 0.021*\"inch\" + 0.016*\"hold\" + 0.016*\"use\" + 0.014*\"flat\" + 0.014*\"screen\" + 0.014*\"need\"\n",
      "2019-07-08 13:00:32,665 : INFO : topic #2 (0.412): 0.018*\"one\" + 0.017*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.008*\"make\" + 0.008*\"bracket\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"like\" + 0.007*\"could\"\n",
      "2019-07-08 13:00:32,667 : INFO : topic diff=0.170843, rho=0.253514\n",
      "2019-07-08 13:00:32,691 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:00:37,250 : INFO : -6.879 per-word bound, 117.7 perplexity estimate based on a held-out corpus of 2000 documents with 85614 words\n",
      "2019-07-08 13:00:37,252 : INFO : PROGRESS: pass 8, at document #10000/13119\n",
      "2019-07-08 13:00:37,254 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:00:40,014 : DEBUG : 1999/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:00:40,042 : INFO : optimized alpha [0.09741386, 0.3134656, 0.43072823, 0.23369642, 0.09353913, 0.06320789, 0.10545583, 0.12220866, 0.08875862, 0.1264265]\n",
      "2019-07-08 13:00:40,044 : DEBUG : updating topics\n",
      "2019-07-08 13:00:40,047 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:00:40,058 : INFO : topic #5 (0.063): 0.024*\"get\" + 0.023*\"antenna\" + 0.020*\"customer\" + 0.015*\"service\" + 0.014*\"cheetah\" + 0.014*\"new\" + 0.014*\"channel\" + 0.011*\"one\" + 0.011*\"return\" + 0.010*\"work\"\n",
      "2019-07-08 13:00:40,062 : INFO : topic #8 (0.089): 0.088*\"screw\" + 0.028*\"use\" + 0.024*\"stud\" + 0.017*\"bolt\" + 0.016*\"long\" + 0.015*\"anchor\" + 0.011*\"drywall\" + 0.011*\"need\" + 0.010*\"head\" + 0.009*\"tighten\"\n",
      "2019-07-08 13:00:40,065 : INFO : topic #3 (0.234): 0.042*\"price\" + 0.037*\"good\" + 0.036*\"product\" + 0.034*\"great\" + 0.030*\"easy\" + 0.025*\"quality\" + 0.025*\"buy\" + 0.022*\"well\" + 0.021*\"install\" + 0.018*\"work\"\n",
      "2019-07-08 13:00:40,067 : INFO : topic #1 (0.313): 0.034*\"easy\" + 0.028*\"great\" + 0.025*\"work\" + 0.022*\"install\" + 0.021*\"inch\" + 0.016*\"use\" + 0.016*\"hold\" + 0.015*\"flat\" + 0.014*\"screen\" + 0.013*\"need\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 13:00:40,070 : INFO : topic #2 (0.431): 0.018*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"bracket\" + 0.008*\"tilt\" + 0.008*\"back\" + 0.007*\"like\" + 0.007*\"could\"\n",
      "2019-07-08 13:00:40,073 : INFO : topic diff=0.199774, rho=0.253514\n",
      "2019-07-08 13:00:40,096 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:00:44,123 : INFO : -6.904 per-word bound, 119.8 perplexity estimate based on a held-out corpus of 2000 documents with 69590 words\n",
      "2019-07-08 13:00:44,126 : INFO : PROGRESS: pass 8, at document #12000/13119\n",
      "2019-07-08 13:00:44,129 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:00:46,631 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:00:46,659 : INFO : optimized alpha [0.09733385, 0.31971365, 0.4397466, 0.23736624, 0.09471203, 0.06343103, 0.10698423, 0.12688562, 0.09053322, 0.12607531]\n",
      "2019-07-08 13:00:46,662 : DEBUG : updating topics\n",
      "2019-07-08 13:00:46,665 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:00:46,675 : INFO : topic #5 (0.063): 0.023*\"get\" + 0.022*\"antenna\" + 0.017*\"customer\" + 0.015*\"new\" + 0.014*\"service\" + 0.012*\"cheetah\" + 0.011*\"channel\" + 0.011*\"one\" + 0.011*\"return\" + 0.011*\"work\"\n",
      "2019-07-08 13:00:46,679 : INFO : topic #8 (0.091): 0.087*\"screw\" + 0.030*\"use\" + 0.024*\"stud\" + 0.017*\"bolt\" + 0.016*\"anchor\" + 0.015*\"long\" + 0.013*\"drywall\" + 0.011*\"need\" + 0.010*\"head\" + 0.009*\"tighten\"\n",
      "2019-07-08 13:00:46,682 : INFO : topic #3 (0.237): 0.043*\"price\" + 0.037*\"good\" + 0.036*\"product\" + 0.035*\"great\" + 0.030*\"easy\" + 0.025*\"quality\" + 0.024*\"buy\" + 0.022*\"well\" + 0.021*\"install\" + 0.018*\"work\"\n",
      "2019-07-08 13:00:46,685 : INFO : topic #1 (0.320): 0.035*\"easy\" + 0.028*\"great\" + 0.027*\"work\" + 0.022*\"install\" + 0.021*\"inch\" + 0.016*\"use\" + 0.015*\"flat\" + 0.015*\"hold\" + 0.014*\"screen\" + 0.014*\"need\"\n",
      "2019-07-08 13:00:46,688 : INFO : topic #2 (0.440): 0.018*\"one\" + 0.017*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"back\" + 0.008*\"tilt\" + 0.008*\"like\" + 0.007*\"bracket\" + 0.007*\"two\"\n",
      "2019-07-08 13:00:46,691 : INFO : topic diff=0.165229, rho=0.253514\n",
      "2019-07-08 13:00:46,713 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:00:49,174 : INFO : -6.965 per-word bound, 124.9 perplexity estimate based on a held-out corpus of 1119 documents with 49461 words\n",
      "2019-07-08 13:00:49,177 : INFO : PROGRESS: pass 8, at document #13119/13119\n",
      "2019-07-08 13:00:49,179 : DEBUG : performing inference on a chunk of 1119 documents\n",
      "2019-07-08 13:00:50,645 : DEBUG : 1119/1119 documents converged within 400 iterations\n",
      "2019-07-08 13:00:50,663 : INFO : optimized alpha [0.09741706, 0.32423338, 0.44876748, 0.23815814, 0.098070376, 0.06512949, 0.1106773, 0.1288156, 0.091521844, 0.12586768]\n",
      "2019-07-08 13:00:50,665 : DEBUG : updating topics\n",
      "2019-07-08 13:00:50,669 : INFO : merging changes from 1119 documents into a model of 13119 documents\n",
      "2019-07-08 13:00:50,680 : INFO : topic #5 (0.065): 0.054*\"antenna\" + 0.030*\"channel\" + 0.025*\"get\" + 0.016*\"mohu\" + 0.014*\"signal\" + 0.010*\"customer\" + 0.010*\"work\" + 0.010*\"one\" + 0.010*\"station\" + 0.010*\"new\"\n",
      "2019-07-08 13:00:50,683 : INFO : topic #8 (0.092): 0.083*\"screw\" + 0.029*\"use\" + 0.023*\"stud\" + 0.017*\"anchor\" + 0.017*\"bolt\" + 0.015*\"long\" + 0.013*\"drywall\" + 0.010*\"need\" + 0.009*\"head\" + 0.009*\"wood\"\n",
      "2019-07-08 13:00:50,686 : INFO : topic #3 (0.238): 0.043*\"price\" + 0.038*\"good\" + 0.035*\"product\" + 0.035*\"great\" + 0.031*\"easy\" + 0.025*\"quality\" + 0.023*\"buy\" + 0.023*\"well\" + 0.021*\"install\" + 0.019*\"work\"\n",
      "2019-07-08 13:00:50,689 : INFO : topic #1 (0.324): 0.035*\"easy\" + 0.028*\"great\" + 0.027*\"work\" + 0.022*\"install\" + 0.022*\"inch\" + 0.017*\"use\" + 0.015*\"hold\" + 0.015*\"flat\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 13:00:50,692 : INFO : topic #2 (0.449): 0.018*\"one\" + 0.017*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"like\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"bracket\" + 0.007*\"tilt\"\n",
      "2019-07-08 13:00:50,695 : INFO : topic diff=0.245777, rho=0.253514\n",
      "2019-07-08 13:00:50,719 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:00:55,025 : INFO : -6.789 per-word bound, 110.5 perplexity estimate based on a held-out corpus of 2000 documents with 76029 words\n",
      "2019-07-08 13:00:55,027 : INFO : PROGRESS: pass 9, at document #2000/13119\n",
      "2019-07-08 13:00:55,030 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:00:57,674 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:00:57,699 : INFO : optimized alpha [0.09570368, 0.33066514, 0.45385012, 0.24436137, 0.09869616, 0.06408876, 0.10928414, 0.13044801, 0.0919223, 0.12673113]\n",
      "2019-07-08 13:00:57,701 : DEBUG : updating topics\n",
      "2019-07-08 13:00:57,704 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:00:57,716 : INFO : topic #5 (0.064): 0.050*\"antenna\" + 0.027*\"channel\" + 0.025*\"get\" + 0.014*\"mohu\" + 0.014*\"signal\" + 0.011*\"customer\" + 0.011*\"new\" + 0.010*\"work\" + 0.010*\"one\" + 0.010*\"station\"\n",
      "2019-07-08 13:00:57,720 : INFO : topic #8 (0.092): 0.090*\"screw\" + 0.030*\"use\" + 0.023*\"stud\" + 0.016*\"bolt\" + 0.015*\"anchor\" + 0.014*\"long\" + 0.012*\"drywall\" + 0.011*\"head\" + 0.010*\"need\" + 0.010*\"wood\"\n",
      "2019-07-08 13:00:57,723 : INFO : topic #3 (0.244): 0.043*\"price\" + 0.038*\"good\" + 0.035*\"great\" + 0.034*\"product\" + 0.030*\"easy\" + 0.026*\"quality\" + 0.025*\"buy\" + 0.022*\"well\" + 0.021*\"install\" + 0.018*\"work\"\n",
      "2019-07-08 13:00:57,726 : INFO : topic #1 (0.331): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.022*\"install\" + 0.021*\"inch\" + 0.017*\"use\" + 0.016*\"hold\" + 0.015*\"flat\" + 0.015*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 13:00:57,729 : INFO : topic #2 (0.454): 0.018*\"one\" + 0.017*\"would\" + 0.013*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"bracket\" + 0.007*\"tilt\" + 0.007*\"back\" + 0.007*\"like\" + 0.007*\"two\"\n",
      "2019-07-08 13:00:57,732 : INFO : topic diff=0.178201, rho=0.245740\n",
      "2019-07-08 13:00:57,754 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:01:02,117 : INFO : -6.789 per-word bound, 110.6 perplexity estimate based on a held-out corpus of 2000 documents with 79013 words\n",
      "2019-07-08 13:01:02,119 : INFO : PROGRESS: pass 9, at document #4000/13119\n",
      "2019-07-08 13:01:02,121 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:01:04,849 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:01:04,876 : INFO : optimized alpha [0.09624195, 0.34253138, 0.46865702, 0.24841519, 0.09851506, 0.06370814, 0.10904828, 0.13163058, 0.09164244, 0.12889764]\n",
      "2019-07-08 13:01:04,878 : DEBUG : updating topics\n",
      "2019-07-08 13:01:04,883 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:01:04,894 : INFO : topic #5 (0.064): 0.043*\"antenna\" + 0.024*\"get\" + 0.024*\"channel\" + 0.015*\"customer\" + 0.012*\"mohu\" + 0.012*\"signal\" + 0.011*\"service\" + 0.011*\"new\" + 0.010*\"one\" + 0.010*\"work\"\n",
      "2019-07-08 13:01:04,896 : INFO : topic #8 (0.092): 0.090*\"screw\" + 0.030*\"use\" + 0.023*\"stud\" + 0.018*\"bolt\" + 0.016*\"anchor\" + 0.014*\"long\" + 0.012*\"drywall\" + 0.011*\"head\" + 0.010*\"wood\" + 0.010*\"need\"\n",
      "2019-07-08 13:01:04,899 : INFO : topic #3 (0.248): 0.043*\"price\" + 0.038*\"good\" + 0.035*\"great\" + 0.034*\"product\" + 0.030*\"easy\" + 0.026*\"quality\" + 0.025*\"buy\" + 0.022*\"well\" + 0.021*\"install\" + 0.018*\"work\"\n",
      "2019-07-08 13:01:04,902 : INFO : topic #1 (0.343): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.023*\"install\" + 0.021*\"inch\" + 0.017*\"use\" + 0.015*\"hold\" + 0.015*\"flat\" + 0.015*\"screen\" + 0.014*\"need\"\n",
      "2019-07-08 13:01:04,905 : INFO : topic #2 (0.469): 0.019*\"one\" + 0.017*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.007*\"back\" + 0.007*\"tilt\" + 0.007*\"bracket\" + 0.007*\"like\" + 0.007*\"two\"\n",
      "2019-07-08 13:01:04,908 : INFO : topic diff=0.166891, rho=0.245740\n",
      "2019-07-08 13:01:04,933 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:01:09,212 : INFO : -6.775 per-word bound, 109.5 perplexity estimate based on a held-out corpus of 2000 documents with 75399 words\n",
      "2019-07-08 13:01:09,214 : INFO : PROGRESS: pass 9, at document #6000/13119\n",
      "2019-07-08 13:01:09,216 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:01:11,925 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:01:11,954 : INFO : optimized alpha [0.099802695, 0.34898847, 0.48768488, 0.25485045, 0.09829727, 0.06357023, 0.108841196, 0.12810633, 0.092785895, 0.13127278]\n",
      "2019-07-08 13:01:11,956 : DEBUG : updating topics\n",
      "2019-07-08 13:01:11,959 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:01:11,969 : INFO : topic #5 (0.064): 0.036*\"antenna\" + 0.025*\"get\" + 0.021*\"channel\" + 0.017*\"customer\" + 0.013*\"service\" + 0.012*\"new\" + 0.010*\"one\" + 0.010*\"cheetah\" + 0.010*\"mohu\" + 0.010*\"signal\"\n",
      "2019-07-08 13:01:11,972 : INFO : topic #8 (0.093): 0.095*\"screw\" + 0.029*\"use\" + 0.022*\"stud\" + 0.018*\"bolt\" + 0.016*\"long\" + 0.015*\"anchor\" + 0.010*\"bottom\" + 0.010*\"drywall\" + 0.010*\"head\" + 0.010*\"need\"\n",
      "2019-07-08 13:01:11,975 : INFO : topic #3 (0.255): 0.044*\"price\" + 0.038*\"good\" + 0.035*\"great\" + 0.035*\"product\" + 0.031*\"easy\" + 0.025*\"quality\" + 0.025*\"buy\" + 0.022*\"install\" + 0.021*\"well\" + 0.018*\"work\"\n",
      "2019-07-08 13:01:11,978 : INFO : topic #1 (0.349): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.023*\"install\" + 0.021*\"inch\" + 0.017*\"use\" + 0.016*\"hold\" + 0.015*\"flat\" + 0.015*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 13:01:11,981 : INFO : topic #2 (0.488): 0.019*\"one\" + 0.017*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"tilt\" + 0.008*\"bracket\" + 0.007*\"back\" + 0.007*\"could\" + 0.007*\"like\"\n",
      "2019-07-08 13:01:11,984 : INFO : topic diff=0.163384, rho=0.245740\n",
      "2019-07-08 13:01:12,008 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:01:16,323 : INFO : -6.763 per-word bound, 108.6 perplexity estimate based on a held-out corpus of 2000 documents with 73605 words\n",
      "2019-07-08 13:01:16,325 : INFO : PROGRESS: pass 9, at document #8000/13119\n",
      "2019-07-08 13:01:16,328 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:01:19,107 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:01:19,134 : INFO : optimized alpha [0.10173535, 0.36267936, 0.4991628, 0.26268724, 0.0974908, 0.06355059, 0.10874825, 0.12701234, 0.09357687, 0.13374688]\n",
      "2019-07-08 13:01:19,137 : DEBUG : updating topics\n",
      "2019-07-08 13:01:19,140 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:01:19,151 : INFO : topic #5 (0.064): 0.030*\"antenna\" + 0.024*\"get\" + 0.019*\"customer\" + 0.017*\"channel\" + 0.014*\"service\" + 0.013*\"cheetah\" + 0.012*\"new\" + 0.010*\"one\" + 0.010*\"work\" + 0.009*\"return\"\n",
      "2019-07-08 13:01:19,154 : INFO : topic #8 (0.094): 0.095*\"screw\" + 0.030*\"use\" + 0.024*\"stud\" + 0.019*\"bolt\" + 0.016*\"long\" + 0.015*\"anchor\" + 0.011*\"tighten\" + 0.011*\"drywall\" + 0.011*\"need\" + 0.010*\"bottom\"\n",
      "2019-07-08 13:01:19,157 : INFO : topic #3 (0.263): 0.045*\"price\" + 0.037*\"good\" + 0.035*\"great\" + 0.035*\"product\" + 0.030*\"easy\" + 0.026*\"buy\" + 0.025*\"quality\" + 0.022*\"install\" + 0.021*\"well\" + 0.018*\"work\"\n",
      "2019-07-08 13:01:19,160 : INFO : topic #1 (0.363): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.022*\"install\" + 0.021*\"inch\" + 0.017*\"hold\" + 0.017*\"use\" + 0.015*\"flat\" + 0.014*\"screen\" + 0.014*\"need\"\n",
      "2019-07-08 13:01:19,163 : INFO : topic #2 (0.499): 0.019*\"one\" + 0.017*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"bracket\" + 0.008*\"tilt\" + 0.007*\"back\" + 0.007*\"like\" + 0.007*\"could\"\n",
      "2019-07-08 13:01:19,166 : INFO : topic diff=0.153356, rho=0.245740\n",
      "2019-07-08 13:01:19,191 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:01:23,675 : INFO : -6.874 per-word bound, 117.3 perplexity estimate based on a held-out corpus of 2000 documents with 85614 words\n",
      "2019-07-08 13:01:23,677 : INFO : PROGRESS: pass 9, at document #10000/13119\n",
      "2019-07-08 13:01:23,680 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:01:26,450 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:01:26,476 : INFO : optimized alpha [0.10176413, 0.37345213, 0.52169275, 0.26788238, 0.098953485, 0.06414473, 0.1120977, 0.12859625, 0.09507934, 0.13550863]\n",
      "2019-07-08 13:01:26,479 : DEBUG : updating topics\n",
      "2019-07-08 13:01:26,482 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:01:26,494 : INFO : topic #5 (0.064): 0.025*\"antenna\" + 0.023*\"get\" + 0.021*\"customer\" + 0.016*\"service\" + 0.015*\"channel\" + 0.014*\"new\" + 0.014*\"cheetah\" + 0.011*\"return\" + 0.010*\"one\" + 0.010*\"amazon\"\n",
      "2019-07-08 13:01:26,497 : INFO : topic #8 (0.095): 0.091*\"screw\" + 0.029*\"use\" + 0.025*\"stud\" + 0.019*\"bolt\" + 0.016*\"long\" + 0.016*\"anchor\" + 0.011*\"drywall\" + 0.010*\"need\" + 0.010*\"tighten\" + 0.010*\"head\"\n",
      "2019-07-08 13:01:26,500 : INFO : topic #3 (0.268): 0.044*\"price\" + 0.037*\"good\" + 0.037*\"product\" + 0.034*\"great\" + 0.029*\"easy\" + 0.026*\"quality\" + 0.025*\"buy\" + 0.022*\"well\" + 0.021*\"install\" + 0.018*\"work\"\n",
      "2019-07-08 13:01:26,503 : INFO : topic #1 (0.373): 0.035*\"easy\" + 0.028*\"great\" + 0.026*\"work\" + 0.022*\"install\" + 0.022*\"inch\" + 0.016*\"use\" + 0.016*\"hold\" + 0.015*\"flat\" + 0.014*\"screen\" + 0.014*\"need\"\n",
      "2019-07-08 13:01:26,506 : INFO : topic #2 (0.522): 0.018*\"one\" + 0.017*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"bracket\" + 0.008*\"tilt\" + 0.008*\"back\" + 0.008*\"like\" + 0.007*\"could\"\n",
      "2019-07-08 13:01:26,508 : INFO : topic diff=0.181485, rho=0.245740\n",
      "2019-07-08 13:01:26,533 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:01:30,512 : INFO : -6.900 per-word bound, 119.4 perplexity estimate based on a held-out corpus of 2000 documents with 69590 words\n",
      "2019-07-08 13:01:30,514 : INFO : PROGRESS: pass 9, at document #12000/13119\n",
      "2019-07-08 13:01:30,517 : DEBUG : performing inference on a chunk of 2000 documents\n",
      "2019-07-08 13:01:32,966 : DEBUG : 2000/2000 documents converged within 400 iterations\n",
      "2019-07-08 13:01:32,994 : INFO : optimized alpha [0.10176083, 0.38340563, 0.5334886, 0.27278957, 0.100153744, 0.06443261, 0.11371045, 0.13335581, 0.09698144, 0.13521257]\n",
      "2019-07-08 13:01:32,996 : DEBUG : updating topics\n",
      "2019-07-08 13:01:32,999 : INFO : merging changes from 2000 documents into a model of 13119 documents\n",
      "2019-07-08 13:01:33,010 : INFO : topic #5 (0.064): 0.024*\"antenna\" + 0.022*\"get\" + 0.018*\"customer\" + 0.015*\"service\" + 0.015*\"new\" + 0.013*\"channel\" + 0.011*\"return\" + 0.011*\"cheetah\" + 0.010*\"work\" + 0.010*\"amazon\"\n",
      "2019-07-08 13:01:33,013 : INFO : topic #8 (0.097): 0.089*\"screw\" + 0.031*\"use\" + 0.025*\"stud\" + 0.019*\"bolt\" + 0.017*\"anchor\" + 0.016*\"long\" + 0.013*\"drywall\" + 0.010*\"need\" + 0.010*\"head\" + 0.010*\"tighten\"\n",
      "2019-07-08 13:01:33,016 : INFO : topic #3 (0.273): 0.045*\"price\" + 0.038*\"good\" + 0.036*\"product\" + 0.035*\"great\" + 0.029*\"easy\" + 0.025*\"buy\" + 0.025*\"quality\" + 0.022*\"well\" + 0.021*\"install\" + 0.019*\"work\"\n",
      "2019-07-08 13:01:33,019 : INFO : topic #1 (0.383): 0.035*\"easy\" + 0.028*\"great\" + 0.027*\"work\" + 0.023*\"install\" + 0.022*\"inch\" + 0.017*\"use\" + 0.016*\"hold\" + 0.016*\"flat\" + 0.015*\"screen\" + 0.014*\"need\"\n",
      "2019-07-08 13:01:33,022 : INFO : topic #2 (0.533): 0.018*\"one\" + 0.017*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"like\" + 0.008*\"back\" + 0.007*\"tilt\" + 0.007*\"bracket\" + 0.007*\"could\"\n",
      "2019-07-08 13:01:33,026 : INFO : topic diff=0.148520, rho=0.245740\n",
      "2019-07-08 13:01:33,045 : DEBUG : bound: at document #0\n",
      "2019-07-08 13:01:35,437 : INFO : -6.958 per-word bound, 124.4 perplexity estimate based on a held-out corpus of 1119 documents with 49461 words\n",
      "2019-07-08 13:01:35,439 : INFO : PROGRESS: pass 9, at document #13119/13119\n",
      "2019-07-08 13:01:35,442 : DEBUG : performing inference on a chunk of 1119 documents\n",
      "2019-07-08 13:01:36,840 : DEBUG : 1119/1119 documents converged within 400 iterations\n",
      "2019-07-08 13:01:36,859 : INFO : optimized alpha [0.10202659, 0.3907597, 0.54403424, 0.27413744, 0.10364541, 0.066140845, 0.1176379, 0.13541253, 0.09803969, 0.13482748]\n",
      "2019-07-08 13:01:36,861 : DEBUG : updating topics\n",
      "2019-07-08 13:01:36,864 : INFO : merging changes from 1119 documents into a model of 13119 documents\n",
      "2019-07-08 13:01:36,874 : INFO : topic #5 (0.066): 0.055*\"antenna\" + 0.031*\"channel\" + 0.025*\"get\" + 0.017*\"mohu\" + 0.014*\"signal\" + 0.011*\"customer\" + 0.010*\"station\" + 0.010*\"new\" + 0.010*\"work\" + 0.010*\"mile\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 13:01:36,877 : INFO : topic #8 (0.098): 0.086*\"screw\" + 0.031*\"use\" + 0.024*\"stud\" + 0.019*\"bolt\" + 0.017*\"anchor\" + 0.016*\"long\" + 0.014*\"drywall\" + 0.010*\"need\" + 0.010*\"head\" + 0.009*\"tighten\"\n",
      "2019-07-08 13:01:36,880 : INFO : topic #3 (0.274): 0.044*\"price\" + 0.039*\"good\" + 0.036*\"product\" + 0.035*\"great\" + 0.030*\"easy\" + 0.026*\"quality\" + 0.024*\"buy\" + 0.023*\"well\" + 0.020*\"install\" + 0.019*\"work\"\n",
      "2019-07-08 13:01:36,883 : INFO : topic #1 (0.391): 0.036*\"easy\" + 0.028*\"great\" + 0.027*\"work\" + 0.022*\"install\" + 0.022*\"inch\" + 0.018*\"use\" + 0.016*\"hold\" + 0.015*\"flat\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 13:01:36,886 : INFO : topic #2 (0.544): 0.018*\"one\" + 0.018*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"like\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"could\" + 0.007*\"bracket\"\n",
      "2019-07-08 13:01:36,889 : INFO : topic diff=0.228914, rho=0.245740\n",
      "2019-07-08 13:01:36,904 : INFO : topic #0 (0.102): 0.063*\"cable\" + 0.040*\"hdmi\" + 0.033*\"come\" + 0.021*\"level\" + 0.016*\"get\" + 0.015*\"include\" + 0.015*\"work\" + 0.015*\"price\" + 0.014*\"low\" + 0.014*\"good\"\n",
      "2019-07-08 13:01:36,907 : INFO : topic #1 (0.391): 0.036*\"easy\" + 0.028*\"great\" + 0.027*\"work\" + 0.022*\"install\" + 0.022*\"inch\" + 0.018*\"use\" + 0.016*\"hold\" + 0.015*\"flat\" + 0.014*\"screen\" + 0.013*\"need\"\n",
      "2019-07-08 13:01:36,911 : INFO : topic #2 (0.544): 0.018*\"one\" + 0.018*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"like\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"could\" + 0.007*\"bracket\"\n",
      "2019-07-08 13:01:36,914 : INFO : topic #3 (0.274): 0.044*\"price\" + 0.039*\"good\" + 0.036*\"product\" + 0.035*\"great\" + 0.030*\"easy\" + 0.026*\"quality\" + 0.024*\"buy\" + 0.023*\"well\" + 0.021*\"install\" + 0.019*\"work\"\n",
      "2019-07-08 13:01:36,918 : INFO : topic #4 (0.104): 0.039*\"cable\" + 0.031*\"shelf\" + 0.021*\"look\" + 0.018*\"wire\" + 0.014*\"power\" + 0.013*\"box\" + 0.011*\"cord\" + 0.010*\"hide\" + 0.010*\"glass\" + 0.010*\"player\"\n",
      "2019-07-08 13:01:36,921 : INFO : topic #5 (0.066): 0.055*\"antenna\" + 0.031*\"channel\" + 0.025*\"get\" + 0.017*\"mohu\" + 0.014*\"signal\" + 0.011*\"customer\" + 0.010*\"station\" + 0.010*\"new\" + 0.010*\"work\" + 0.010*\"mile\"\n",
      "2019-07-08 13:01:36,924 : INFO : topic #6 (0.118): 0.041*\"bracket\" + 0.026*\"screw\" + 0.022*\"plate\" + 0.020*\"hole\" + 0.019*\"bolt\" + 0.019*\"use\" + 0.018*\"bar\" + 0.017*\"fit\" + 0.016*\"x\" + 0.015*\"vesa\"\n",
      "2019-07-08 13:01:36,927 : INFO : topic #7 (0.135): 0.050*\"monitor\" + 0.031*\"arm\" + 0.022*\"use\" + 0.017*\"stand\" + 0.017*\"move\" + 0.016*\"hold\" + 0.013*\"work\" + 0.013*\"well\" + 0.013*\"position\" + 0.011*\"desk\"\n",
      "2019-07-08 13:01:36,930 : INFO : topic #8 (0.098): 0.086*\"screw\" + 0.031*\"use\" + 0.024*\"stud\" + 0.019*\"bolt\" + 0.017*\"anchor\" + 0.016*\"long\" + 0.014*\"drywall\" + 0.010*\"need\" + 0.010*\"head\" + 0.009*\"tighten\"\n",
      "2019-07-08 13:01:36,934 : INFO : topic #9 (0.135): 0.046*\"level\" + 0.041*\"stud\" + 0.025*\"use\" + 0.023*\"include\" + 0.021*\"bolt\" + 0.018*\"drill\" + 0.018*\"hole\" + 0.018*\"make\" + 0.017*\"need\" + 0.016*\"screw\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.063*\"cable\" + 0.040*\"hdmi\" + 0.033*\"come\" + 0.021*\"level\" + 0.016*\"get\" + '\n",
      "  '0.015*\"include\" + 0.015*\"work\" + 0.015*\"price\" + 0.014*\"low\" + '\n",
      "  '0.014*\"good\"'),\n",
      " (1,\n",
      "  '0.036*\"easy\" + 0.028*\"great\" + 0.027*\"work\" + 0.022*\"install\" + '\n",
      "  '0.022*\"inch\" + 0.018*\"use\" + 0.016*\"hold\" + 0.015*\"flat\" + 0.014*\"screen\" + '\n",
      "  '0.013*\"need\"'),\n",
      " (2,\n",
      "  '0.018*\"one\" + 0.018*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + '\n",
      "  '0.008*\"like\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"could\" + '\n",
      "  '0.007*\"bracket\"'),\n",
      " (3,\n",
      "  '0.044*\"price\" + 0.039*\"good\" + 0.036*\"product\" + 0.035*\"great\" + '\n",
      "  '0.030*\"easy\" + 0.026*\"quality\" + 0.024*\"buy\" + 0.023*\"well\" + '\n",
      "  '0.021*\"install\" + 0.019*\"work\"'),\n",
      " (4,\n",
      "  '0.039*\"cable\" + 0.031*\"shelf\" + 0.021*\"look\" + 0.018*\"wire\" + 0.014*\"power\" '\n",
      "  '+ 0.013*\"box\" + 0.011*\"cord\" + 0.010*\"hide\" + 0.010*\"glass\" + '\n",
      "  '0.010*\"player\"'),\n",
      " (5,\n",
      "  '0.055*\"antenna\" + 0.031*\"channel\" + 0.025*\"get\" + 0.017*\"mohu\" + '\n",
      "  '0.014*\"signal\" + 0.011*\"customer\" + 0.010*\"station\" + 0.010*\"new\" + '\n",
      "  '0.010*\"work\" + 0.010*\"mile\"'),\n",
      " (6,\n",
      "  '0.041*\"bracket\" + 0.026*\"screw\" + 0.022*\"plate\" + 0.020*\"hole\" + '\n",
      "  '0.019*\"bolt\" + 0.019*\"use\" + 0.018*\"bar\" + 0.017*\"fit\" + 0.016*\"x\" + '\n",
      "  '0.015*\"vesa\"'),\n",
      " (7,\n",
      "  '0.050*\"monitor\" + 0.031*\"arm\" + 0.022*\"use\" + 0.017*\"stand\" + 0.017*\"move\" '\n",
      "  '+ 0.016*\"hold\" + 0.013*\"work\" + 0.013*\"well\" + 0.013*\"position\" + '\n",
      "  '0.011*\"desk\"'),\n",
      " (8,\n",
      "  '0.086*\"screw\" + 0.031*\"use\" + 0.024*\"stud\" + 0.019*\"bolt\" + 0.017*\"anchor\" '\n",
      "  '+ 0.016*\"long\" + 0.014*\"drywall\" + 0.010*\"need\" + 0.010*\"head\" + '\n",
      "  '0.009*\"tighten\"'),\n",
      " (9,\n",
      "  '0.046*\"level\" + 0.041*\"stud\" + 0.025*\"use\" + 0.023*\"include\" + 0.021*\"bolt\" '\n",
      "  '+ 0.018*\"drill\" + 0.018*\"hole\" + 0.018*\"make\" + 0.017*\"need\" + '\n",
      "  '0.016*\"screw\"')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 13:01:37,034 : DEBUG : Setting topics to those of the model: LdaModel(num_terms=5711, num_topics=10, decay=0.5, chunksize=2000)\n",
      "2019-07-08 13:01:37,039 : INFO : using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n",
      "2019-07-08 13:01:58,524 : INFO : 199 batches submitted to accumulate stats from 12736 documents (-879996 virtual)\n",
      "2019-07-08 13:01:59,239 : INFO : 3 accumulators retrieved from output queue\n",
      "2019-07-08 13:01:59,337 : INFO : accumulated word occurrence stats for 65072 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model coherence score is: 0.44547078456106093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 13:02:00,045 : DEBUG : performing inference on a chunk of 13119 documents\n",
      "2019-07-08 13:02:15,810 : DEBUG : 13119/13119 documents converged within 400 iterations\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build an LDA model with alpha, eta learned from data automatically\n",
    "lda_0, vis_0 = train_lda_gensim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### topics from lda_0\n",
    "[(0,\n",
    "  '0.063*\"cable\" + 0.040*\"hdmi\" + 0.033*\"come\" + 0.021*\"level\" + 0.016*\"get\" + '\n",
    "  '0.015*\"include\" + 0.015*\"work\" + 0.015*\"price\" + 0.014*\"low\" + '\n",
    "  '0.014*\"good\"'),\n",
    " (1,\n",
    "  '0.036*\"easy\" + 0.028*\"great\" + 0.027*\"work\" + 0.022*\"install\" + '\n",
    "  '0.022*\"inch\" + 0.018*\"use\" + 0.016*\"hold\" + 0.015*\"flat\" + 0.014*\"screen\" + '\n",
    "  '0.013*\"need\"'),\n",
    " (2,\n",
    "  '0.018*\"one\" + 0.018*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + '\n",
    "  '0.008*\"like\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"could\" + '\n",
    "  '0.007*\"bracket\"'),\n",
    " (3,\n",
    "  '0.044*\"price\" + 0.039*\"good\" + 0.036*\"product\" + 0.035*\"great\" + '\n",
    "  '0.030*\"easy\" + 0.026*\"quality\" + 0.024*\"buy\" + 0.023*\"well\" + '\n",
    "  '0.021*\"install\" + 0.019*\"work\"'),\n",
    " (4,\n",
    "  '0.039*\"cable\" + 0.031*\"shelf\" + 0.021*\"look\" + 0.018*\"wire\" + 0.014*\"power\" '\n",
    "  '+ 0.013*\"box\" + 0.011*\"cord\" + 0.010*\"hide\" + 0.010*\"glass\" + '\n",
    "  '0.010*\"player\"'),\n",
    " (5,\n",
    "  '0.055*\"antenna\" + 0.031*\"channel\" + 0.025*\"get\" + 0.017*\"mohu\" + '\n",
    "  '0.014*\"signal\" + 0.011*\"customer\" + 0.010*\"station\" + 0.010*\"new\" + '\n",
    "  '0.010*\"work\" + 0.010*\"mile\"'),\n",
    " (6,\n",
    "  '0.041*\"bracket\" + 0.026*\"screw\" + 0.022*\"plate\" + 0.020*\"hole\" + '\n",
    "  '0.019*\"bolt\" + 0.019*\"use\" + 0.018*\"bar\" + 0.017*\"fit\" + 0.016*\"x\" + '\n",
    "  '0.015*\"vesa\"'),\n",
    " (7,\n",
    "  '0.050*\"monitor\" + 0.031*\"arm\" + 0.022*\"use\" + 0.017*\"stand\" + 0.017*\"move\" '\n",
    "  '+ 0.016*\"hold\" + 0.013*\"work\" + 0.013*\"well\" + 0.013*\"position\" + '\n",
    "  '0.011*\"desk\"'),\n",
    " (8,\n",
    "  '0.086*\"screw\" + 0.031*\"use\" + 0.024*\"stud\" + 0.019*\"bolt\" + 0.017*\"anchor\" '\n",
    "  '+ 0.016*\"long\" + 0.014*\"drywall\" + 0.010*\"need\" + 0.010*\"head\" + '\n",
    "  '0.009*\"tighten\"'),\n",
    " (9,\n",
    "  '0.046*\"level\" + 0.041*\"stud\" + 0.025*\"use\" + 0.023*\"include\" + 0.021*\"bolt\" '\n",
    "  '+ 0.018*\"drill\" + 0.018*\"hole\" + 0.018*\"make\" + 0.017*\"need\" + '\n",
    "  '0.016*\"screw\"')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This wall mount does everything it's supposed to do.  The piece that attaches to the wall isn't overly long, which made it easier to mount the arm in the tight space I needed to mount it in.  The only issues I saw was that the joints were VERY tight initially and as we moved the arm around to install it, the joints loosened up to the point where I had to take the included allen wrench and tighten them up again. \n",
      "\n",
      "['everything', 'suppose', 'piece', 'attache', 'overly', 'long', 'make', 'easy', 'arm', 'tight', 'space', 'need', 'issue', 'see', 'joint', 'tight', 'initially', 'move', 'arm', 'around', 'install', 'joint', 'loosen', 'point', 'take', 'include', 'allen', 'wrench', 'tighten'] \n",
      "\n",
      "[(1, 0.019347183), (2, 0.24029793), (7, 0.47445524), (9, 0.24062134)] \n",
      "\n",
      "0.050*\"monitor\" + 0.031*\"arm\" + 0.022*\"use\" + 0.017*\"stand\" + 0.017*\"move\" + 0.016*\"hold\" + 0.013*\"work\" + 0.013*\"well\" + 0.013*\"position\" + 0.011*\"desk\" \n",
      "\n",
      "0.046*\"level\" + 0.041*\"stud\" + 0.025*\"use\" + 0.023*\"include\" + 0.021*\"bolt\" + 0.018*\"drill\" + 0.018*\"hole\" + 0.018*\"make\" + 0.017*\"need\" + 0.016*\"screw\" \n",
      "\n",
      "0.018*\"one\" + 0.018*\"would\" + 0.014*\"get\" + 0.010*\"go\" + 0.009*\"make\" + 0.008*\"like\" + 0.007*\"back\" + 0.007*\"two\" + 0.007*\"could\" + 0.007*\"bracket\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at top documents from topics\n",
    "i = 4\n",
    "print(df['reviewText'][i],'\\n')\n",
    "print(reviews[i],'\\n')\n",
    "print(lda_0[DTM][i],'\\n')\n",
    "print(lda_0.print_topic(7, topn=10),'\\n')\n",
    "print(lda_0.print_topic(9, topn=10),'\\n')\n",
    "print(lda_0.print_topic(2, topn=10),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monitor', 0.049846414),\n",
       " ('arm', 0.031200508),\n",
       " ('use', 0.022123555),\n",
       " ('stand', 0.017210353),\n",
       " ('move', 0.017024033),\n",
       " ('hold', 0.015627088),\n",
       " ('work', 0.012842008),\n",
       " ('well', 0.012568197)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_0.show_topic(topicid=7,topn=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_doc_topics(ldamodel, corpus, rev_proc, rev_orig):\n",
    "    # Init output\n",
    "    doc_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Probability generated from this topic, and topic keywords \n",
    "        for j, (topic_num, prob_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num,5)\n",
    "                topic_keywords = \", \".join([word for word, prob in wp])\n",
    "                doc_topics_df = doc_topics_df.append(pd.Series([int(topic_num), round(prob_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    doc_topics_df.columns = ['Dominant_Topic', 'Prob_From_Topic', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    #contents = pd.Series(rev_proc)\n",
    "    doc_topics_df = pd.concat([doc_topics_df, rev_proc, rev_orig], axis=1)\n",
    "    return(doc_topics_df)\n",
    "\n",
    "def out_topics_docs(ldamodel, corpus, prob0=0):\n",
    "    # get a dictionary with topics as keys, and list of tuples (document_id, prob) as values\n",
    "    # only keep tuples with prob > prob0\n",
    "    topics_docs_dict = {}\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        # ldamodel[corpus][i] is a list of tuples (topic, prob) for document i\n",
    "        for j, (topic_num, prob_topic) in enumerate(row):\n",
    "            if prob_topic > prob0:\n",
    "                if topic_num in topics_docs_dict:\n",
    "                    topics_docs_dict[topic_num].append((i, prob_topic))  # add tuple (document_id, prob) \n",
    "                else: \n",
    "                    topics_docs_dict[topic_num] = [(i, prob_topic)]  # add the first document_id, prob pair\n",
    "                \n",
    "    return(topics_docs_dict)\n",
    "\n",
    "def check_topic_doc_prob(topics_docs_dict,topic_num):\n",
    "    # check the distribution of probabilities for a specified topic\n",
    "    prob_lst = pd.Series([x[1] for x in topics_docs_dict[topic_num] ])\n",
    "    return prob_lst\n",
    "\n",
    "def topn_docs_by_topic(topics_docs_dict,topic_num, topn = 10):\n",
    "    # return top 10 reviews and associated generating probability for specified topic\n",
    "    top_docprobs = sorted(topics_docs_dict[topic_num], key = lambda x: x[1], reverse=True)[:topn]\n",
    "    return top_docprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 has 2169 documents\n",
      "topic 1 has 7363 documents\n",
      "topic 2 has 9027 documents\n",
      "topic 3 has 5954 documents\n",
      "topic 4 has 1808 documents\n",
      "topic 5 has 1004 documents\n",
      "topic 6 has 2487 documents\n",
      "topic 7 has 2914 documents\n",
      "topic 8 has 2134 documents\n",
      "topic 9 has 3385 documents\n"
     ]
    }
   ],
   "source": [
    "topics_docs_dict = out_topics_docs(lda_0, DTM)\n",
    "# for k in sorted(topics_docs_dict.keys()):\n",
    "#     print(\"topic\", k, \"has\", len(topics_docs_dict[k]),\"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2169.000000\n",
      "mean     0.245978   \n",
      "std      0.133368   \n",
      "min      0.100009   \n",
      "25%      0.146248   \n",
      "50%      0.207459   \n",
      "75%      0.306080   \n",
      "max      0.852974   \n",
      "dtype: float64 \n",
      "\n",
      "count    7363.000000\n",
      "mean     0.349926   \n",
      "std      0.197166   \n",
      "min      0.100159   \n",
      "25%      0.189316   \n",
      "50%      0.301134   \n",
      "75%      0.465259   \n",
      "max      0.925084   \n",
      "dtype: float64 \n",
      "\n",
      "count    9027.000000\n",
      "mean     0.349097   \n",
      "std      0.171069   \n",
      "min      0.100005   \n",
      "25%      0.209925   \n",
      "50%      0.324278   \n",
      "75%      0.460708   \n",
      "max      0.953336   \n",
      "dtype: float64 \n",
      "\n",
      "count    5954.000000\n",
      "mean     0.337878   \n",
      "std      0.190470   \n",
      "min      0.100033   \n",
      "25%      0.185039   \n",
      "50%      0.288047   \n",
      "75%      0.453645   \n",
      "max      0.918724   \n",
      "dtype: float64 \n",
      "\n",
      "count    1808.000000\n",
      "mean     0.244878   \n",
      "std      0.138379   \n",
      "min      0.100022   \n",
      "25%      0.136301   \n",
      "50%      0.200499   \n",
      "75%      0.313554   \n",
      "max      0.918114   \n",
      "dtype: float64 \n",
      "\n",
      "count    1004.000000\n",
      "mean     0.220892   \n",
      "std      0.124385   \n",
      "min      0.100050   \n",
      "25%      0.130800   \n",
      "50%      0.177087   \n",
      "75%      0.269917   \n",
      "max      0.893383   \n",
      "dtype: float64 \n",
      "\n",
      "count    2487.000000\n",
      "mean     0.245532   \n",
      "std      0.131454   \n",
      "min      0.100177   \n",
      "25%      0.145381   \n",
      "50%      0.205299   \n",
      "75%      0.307542   \n",
      "max      0.919448   \n",
      "dtype: float64 \n",
      "\n",
      "count    2914.000000\n",
      "mean     0.261533   \n",
      "std      0.138938   \n",
      "min      0.100067   \n",
      "25%      0.152628   \n",
      "50%      0.224141   \n",
      "75%      0.332767   \n",
      "max      0.883272   \n",
      "dtype: float64 \n",
      "\n",
      "count    2134.000000\n",
      "mean     0.220064   \n",
      "std      0.112564   \n",
      "min      0.100017   \n",
      "25%      0.134354   \n",
      "50%      0.186397   \n",
      "75%      0.267898   \n",
      "max      0.906324   \n",
      "dtype: float64 \n",
      "\n",
      "count    3385.000000\n",
      "mean     0.263654   \n",
      "std      0.135916   \n",
      "min      0.100039   \n",
      "25%      0.158697   \n",
      "50%      0.228789   \n",
      "75%      0.338931   \n",
      "max      0.900604   \n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in sorted(topics_docs_dict.keys()):\n",
    "    test_prob = check_topic_doc_prob(topics_docs_dict, t)\n",
    "    print(test_prob.describe(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4952, 0.8529744), (5414, 0.84606296), (5364, 0.8449979), (3510, 0.83928895), (2012, 0.83633184), (307, 0.8297959), (5375, 0.82223487), (12337, 0.8201404), (6254, 0.8130527), (5109, 0.8099714)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "testp = topn_docs_by_topic(topics_docs_dict,topic_num)\n",
    "print(testp,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('level', 0.04647892), ('stud', 0.041454233), ('use', 0.024952756), ('include', 0.022682786), ('bolt', 0.020564314), ('drill', 0.018463153), ('hole', 0.018424856), ('make', 0.018338157), ('need', 0.016770896), ('screw', 0.01564362)]\n",
      "topic 9 has 3385 documents\n",
      "Distribution of probabilities of documents being generated from this topic:\n",
      "count    3385.000000\n",
      "mean     0.263654   \n",
      "std      0.135916   \n",
      "min      0.100039   \n",
      "25%      0.158697   \n",
      "50%      0.228789   \n",
      "75%      0.338931   \n",
      "max      0.900604   \n",
      "dtype: float64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>product</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>prob_from_topic</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00080CM30</td>\n",
       "      <td>Sanus VMPL250B Fixed Low-Profile Wall Mount for 30&amp;quot; to 56&amp;quot; Displays (Black) (Discontinued by Manufacturer)</td>\n",
       "      <td>407</td>\n",
       "      <td>0.900604</td>\n",
       "      <td>I picked this mount up for our new 50\" Samsung Plasma and have been very happy with it.  As the title of the review says, this is a no frills flush mount, if you are looking for tilt or mobility look elsewhere.  Mounting the TV is simple, locate your studs and drive in 4 large screws for stud mount.  There is a huge package of hardware to fit your specific installation and they are all well organized into their own separate pouches.  From opening the box to fully installed the mount took less than 30 minutes to complete.  Something I didn't notice or see anywhere before buying was the included metal plate used to lock the TV into place.  There is a predrilled hole which allows for a padlock to be installed effectively making the TV impossible to steal, or be potentially pulled off the wall.  Very nice added security.Many people have mentioned how close this mounts, leaving little room for cables behind.  This is true and exactly what I was looking for.  My advice is to install a recessed receptacle behind the TV so that cables don't have to but up against the wall.  I love this item and am so happy I didn't spend $100 on a mount from an electronics store.  Anyone with basic do-it-yourself skills should be able to install it and enjoy it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000WYVBR0</td>\n",
       "      <td>VideoSecu LED LCD TV Wall Mount for most 22&amp;quot;-47&amp;quot; LCD, LED &amp;amp; Plasma Televisions and some models up to 55&amp;quot; inches - up to 88 lb VESA 400x400 mm with Full Motion Swivel Articulating Arm, 20 in Extension and Post-installation Leveling System, for Monitor Flat Panel Screen, Bonus 10 ft HDMI cable and Magnetic Bubble Leveler WP5</td>\n",
       "      <td>3928</td>\n",
       "      <td>0.875433</td>\n",
       "      <td>I mounted a 32\" Toshiba TV on a bedroom wall. Seems well made, looks solid, beefy, pivots well. You can adjust the tension on the hinges, not all do. Even if you do not need it at first, you may after it wears a bot.The mount can fold out flat extended to either side moving the TV a a few extra inches to one side off the mounts center. Works for me as my stud is not exactly centered where I want to park the TV.When fully extended, the center of the bracket extends 17\" from the wall. This is enough to put my 32\" screen at a full right angle to the wall.The mount allows the TV to rotate. I do not see a need for this on a TV if you mount the bracket plumb. If you are off a bit, you can adjust for it here. It could be useful if you mount a PC Monitor that supports portrait and landscape though.Came well packed, no damage or missing parts. The level is plastic with a magnetic strip on one side. Doesn't look like it would be critically accurate, but good enough I suppose. I didn't test, I used my own. It even comes with an extra HDMI cable.The TV mount hangs on the wall bracket with a hook on the top, then is secured by two small bolts at the bottom. A bit awkward to get them both, but not terrible.Two lag bolts hold it into a wood stud. Comes with four bolts and plastic anchors for mounting into a mortar wall. The bracket has 3 holes at the top. The two outer holes are too wide for extra support into wood though. A third lag bolt centered for wood may help the paranoid feel better, but two is plenty strong if you get the center of your stud.Most importantly: If the need arose, I would buy another.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002YUVPK8</td>\n",
       "      <td>Mount-It Ultra-Low Profile Tilting LCD/Plasma HD TV Universal Wall Mount for 32-60 Inch TVs</td>\n",
       "      <td>9497</td>\n",
       "      <td>0.864511</td>\n",
       "      <td>only bad thing about this product is the screws used to mount brackets to tv were kinda crappy out of the 4, 3 went in great the other had trouble, just bought a set of better screws.  no problesm leveling this product or mounting.  make sure you adjust your TILT before you try to hang it on wall!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00823170Y</td>\n",
       "      <td>Sewell Direct Universal Soundbar Bracket</td>\n",
       "      <td>12195</td>\n",
       "      <td>0.861943</td>\n",
       "      <td>Love the versatility of this bracket system.  You can hang your soundbar on the bottom or top of your tv with ease.  I first installed mine on the bottom, then realized I would like it better on the top.  It  was so simple to make the adjustments.  I made the switch in under 10 minutes. Works as intended and it's sturdy.  LOVE IT.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0012S4APK</td>\n",
       "      <td>Cheetah Mounts APTMM2B Flush Tilt (1.3&amp;quot; Profile) TV Wall Mount Bracket for 32-65 inch LED, LCD and Plasma Flat Screen TVs Up To VESA 684x400 and 165lbs, Including a Twisted Veins 10' Braided High Speed with Ethernet HDMI Cable and a 6&amp;quot; 3-Axis Magnetic Bubble Level</td>\n",
       "      <td>4354</td>\n",
       "      <td>0.856535</td>\n",
       "      <td>Purchased this for a friend, because I had purchased a couple a while back.  I told her this one is awesome product for the price. The cable work for a year or so, but for the price you can't beat it....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B003O1UYHG</td>\n",
       "      <td>VideoSecu Articulating Arm TV LCD Monitor Wall Mount, Full Motion Tilt Swivel and Rotate for Most 15&amp;quot; 17&amp;quot; 19&amp;quot; 20&amp;quot; 22&amp;quot; 23&amp;quot; 24&amp;quot; 26&amp;quot; 27&amp;quot; LED TV Flat Panel Screen with VESA 100, 75 ML12B CB5</td>\n",
       "      <td>10365</td>\n",
       "      <td>0.854054</td>\n",
       "      <td>Used it on a 20\" dell monitor on a work bench.  I wish there was vertical adjustment.  Seems pretty sturdy, although for a larger TV you might need larger lag bolts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B0025PKFUI</td>\n",
       "      <td>VideoSecu TV Wall Mount Articulating Arm Tilt Swivel Bracket for most 15-27&amp;quot; TV Monitor Display VESA 100X100 75X75 up to 33LBS ML15B A28</td>\n",
       "      <td>8095</td>\n",
       "      <td>0.853835</td>\n",
       "      <td>Very well constructed.  I never need to worry that my LCD might crash to the floor.  This thing is secure and much MUCH stronger than I expected.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B00BT0RT8Q</td>\n",
       "      <td>Impact Mounts Lcd Led Plasma Flat Tilt Tv Wall Mount Bracket 30 32 37 42 46 47 50 52 55 60 65 70 80. Don't Be Fooled By Our Low Price! These Are High Quality Mounts Used By Pro Installers Throughout the Usa. Priced Low for a Limited Time.</td>\n",
       "      <td>12870</td>\n",
       "      <td>0.838861</td>\n",
       "      <td>Great buy, this is the second one I purchased so I knew it would be a great product, however, the only issues I had with this mount was that the screws to mount my TV with did not work. They send several different sizes for different TV sets. however, none of the screws fit the particular TV I had which was a top name brand TV, so other then that, the product is great!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B001TICH08</td>\n",
       "      <td>VideoSecu Tilt Swivel TV Wall Mount 32&amp;quot;- 55&amp;quot; LCD LED Plasma TV Flat Screen with VESA up to 600x400 mm, Full Motion Articulating Dual Arm Mount Fits up to 24&amp;quot; Studs MW365B2 C20</td>\n",
       "      <td>7476</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>I mounted this on my plaster wall without a problem. My TV is 32 inches but this mount is sturdy enough for a larger TV.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B0081F2Z40</td>\n",
       "      <td>VonHaus by Designer Habitat Ultra Slim Cantilever Swivel &amp;amp; Tilt Wall Mount TV Bracket for 26-55&amp;quot; for LCD, LED, 3D, Plasma TVs. Load Capacity 88lbs</td>\n",
       "      <td>12070</td>\n",
       "      <td>0.822377</td>\n",
       "      <td>running a 50\" LED tv on this wall mount. Works well, install was smooth, directions were great (which is a rare thing these days) and I've had no issues with it. All said and done these are incredible value and price!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  \\\n",
       "0  B00080CM30   \n",
       "1  B000WYVBR0   \n",
       "2  B002YUVPK8   \n",
       "3  B00823170Y   \n",
       "4  B0012S4APK   \n",
       "5  B003O1UYHG   \n",
       "6  B0025PKFUI   \n",
       "7  B00BT0RT8Q   \n",
       "8  B001TICH08   \n",
       "9  B0081F2Z40   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                   product  \\\n",
       "0  Sanus VMPL250B Fixed Low-Profile Wall Mount for 30&quot; to 56&quot; Displays (Black) (Discontinued by Manufacturer)                                                                                                                                                                                                                                      \n",
       "1  VideoSecu LED LCD TV Wall Mount for most 22&quot;-47&quot; LCD, LED &amp; Plasma Televisions and some models up to 55&quot; inches - up to 88 lb VESA 400x400 mm with Full Motion Swivel Articulating Arm, 20 in Extension and Post-installation Leveling System, for Monitor Flat Panel Screen, Bonus 10 ft HDMI cable and Magnetic Bubble Leveler WP5   \n",
       "2  Mount-It Ultra-Low Profile Tilting LCD/Plasma HD TV Universal Wall Mount for 32-60 Inch TVs                                                                                                                                                                                                                                                               \n",
       "3  Sewell Direct Universal Soundbar Bracket                                                                                                                                                                                                                                                                                                                  \n",
       "4  Cheetah Mounts APTMM2B Flush Tilt (1.3&quot; Profile) TV Wall Mount Bracket for 32-65 inch LED, LCD and Plasma Flat Screen TVs Up To VESA 684x400 and 165lbs, Including a Twisted Veins 10' Braided High Speed with Ethernet HDMI Cable and a 6&quot; 3-Axis Magnetic Bubble Level                                                                        \n",
       "5  VideoSecu Articulating Arm TV LCD Monitor Wall Mount, Full Motion Tilt Swivel and Rotate for Most 15&quot; 17&quot; 19&quot; 20&quot; 22&quot; 23&quot; 24&quot; 26&quot; 27&quot; LED TV Flat Panel Screen with VESA 100, 75 ML12B CB5                                                                                                                   \n",
       "6  VideoSecu TV Wall Mount Articulating Arm Tilt Swivel Bracket for most 15-27&quot; TV Monitor Display VESA 100X100 75X75 up to 33LBS ML15B A28                                                                                                                                                                                                             \n",
       "7  Impact Mounts Lcd Led Plasma Flat Tilt Tv Wall Mount Bracket 30 32 37 42 46 47 50 52 55 60 65 70 80. Don't Be Fooled By Our Low Price! These Are High Quality Mounts Used By Pro Installers Throughout the Usa. Priced Low for a Limited Time.                                                                                                            \n",
       "8  VideoSecu Tilt Swivel TV Wall Mount 32&quot;- 55&quot; LCD LED Plasma TV Flat Screen with VESA up to 600x400 mm, Full Motion Articulating Dual Arm Mount Fits up to 24&quot; Studs MW365B2 C20                                                                                                                                                            \n",
       "9  VonHaus by Designer Habitat Ultra Slim Cantilever Swivel &amp; Tilt Wall Mount TV Bracket for 26-55&quot; for LCD, LED, 3D, Plasma TVs. Load Capacity 88lbs                                                                                                                                                                                               \n",
       "\n",
       "   doc_id  prob_from_topic  \\\n",
       "0  407     0.900604          \n",
       "1  3928    0.875433          \n",
       "2  9497    0.864511          \n",
       "3  12195   0.861943          \n",
       "4  4354    0.856535          \n",
       "5  10365   0.854054          \n",
       "6  8095    0.853835          \n",
       "7  12870   0.838861          \n",
       "8  7476    0.822430          \n",
       "9  12070   0.822377          \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            reviewText  \n",
       "0  I picked this mount up for our new 50\" Samsung Plasma and have been very happy with it.  As the title of the review says, this is a no frills flush mount, if you are looking for tilt or mobility look elsewhere.  Mounting the TV is simple, locate your studs and drive in 4 large screws for stud mount.  There is a huge package of hardware to fit your specific installation and they are all well organized into their own separate pouches.  From opening the box to fully installed the mount took less than 30 minutes to complete.  Something I didn't notice or see anywhere before buying was the included metal plate used to lock the TV into place.  There is a predrilled hole which allows for a padlock to be installed effectively making the TV impossible to steal, or be potentially pulled off the wall.  Very nice added security.Many people have mentioned how close this mounts, leaving little room for cables behind.  This is true and exactly what I was looking for.  My advice is to install a recessed receptacle behind the TV so that cables don't have to but up against the wall.  I love this item and am so happy I didn't spend $100 on a mount from an electronics store.  Anyone with basic do-it-yourself skills should be able to install it and enjoy it.                                                                                                                                                                                                                                                                                                                                                                            \n",
       "1  I mounted a 32\" Toshiba TV on a bedroom wall. Seems well made, looks solid, beefy, pivots well. You can adjust the tension on the hinges, not all do. Even if you do not need it at first, you may after it wears a bot.The mount can fold out flat extended to either side moving the TV a a few extra inches to one side off the mounts center. Works for me as my stud is not exactly centered where I want to park the TV.When fully extended, the center of the bracket extends 17\" from the wall. This is enough to put my 32\" screen at a full right angle to the wall.The mount allows the TV to rotate. I do not see a need for this on a TV if you mount the bracket plumb. If you are off a bit, you can adjust for it here. It could be useful if you mount a PC Monitor that supports portrait and landscape though.Came well packed, no damage or missing parts. The level is plastic with a magnetic strip on one side. Doesn't look like it would be critically accurate, but good enough I suppose. I didn't test, I used my own. It even comes with an extra HDMI cable.The TV mount hangs on the wall bracket with a hook on the top, then is secured by two small bolts at the bottom. A bit awkward to get them both, but not terrible.Two lag bolts hold it into a wood stud. Comes with four bolts and plastic anchors for mounting into a mortar wall. The bracket has 3 holes at the top. The two outer holes are too wide for extra support into wood though. A third lag bolt centered for wood may help the paranoid feel better, but two is plenty strong if you get the center of your stud.Most importantly: If the need arose, I would buy another.  \n",
       "2  only bad thing about this product is the screws used to mount brackets to tv were kinda crappy out of the 4, 3 went in great the other had trouble, just bought a set of better screws.  no problesm leveling this product or mounting.  make sure you adjust your TILT before you try to hang it on wall!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "3  Love the versatility of this bracket system.  You can hang your soundbar on the bottom or top of your tv with ease.  I first installed mine on the bottom, then realized I would like it better on the top.  It  was so simple to make the adjustments.  I made the switch in under 10 minutes. Works as intended and it's sturdy.  LOVE IT.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "4  Purchased this for a friend, because I had purchased a couple a while back.  I told her this one is awesome product for the price. The cable work for a year or so, but for the price you can't beat it....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "5  Used it on a 20\" dell monitor on a work bench.  I wish there was vertical adjustment.  Seems pretty sturdy, although for a larger TV you might need larger lag bolts.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "6  Very well constructed.  I never need to worry that my LCD might crash to the floor.  This thing is secure and much MUCH stronger than I expected.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "7  Great buy, this is the second one I purchased so I knew it would be a great product, however, the only issues I had with this mount was that the screws to mount my TV with did not work. They send several different sizes for different TV sets. however, none of the screws fit the particular TV I had which was a top name brand TV, so other then that, the product is great!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "8  I mounted this on my plaster wall without a problem. My TV is 32 inches but this mount is sturdy enough for a larger TV.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "9  running a 50\" LED tv on this wall mount. Works well, install was smooth, directions were great (which is a rare thing these days) and I've had no issues with it. All said and done these are incredible value and price!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine each topic by topic key words, number of generated documents, document probabilities, docs with top probabilities\n",
    "topic_num = 9\n",
    "print(lda_0.show_topic(topicid=topic_num))\n",
    "print(\"topic\", topic_num, \"has\", len(topics_docs_dict[topic_num]),\"documents\")\n",
    "print(\"Distribution of probabilities of documents being generated from this topic:\")\n",
    "doc_prob = check_topic_doc_prob(topics_docs_dict, topic_num)\n",
    "print(doc_prob.describe(),\"\\n\")\n",
    "top_docprobs = topn_docs_by_topic(topics_docs_dict,topic_num)\n",
    "idxs = pd.Series([x[0] for x in top_docprobs])\n",
    "probs = pd.Series([x[1] for x in top_docprobs])\n",
    "texts = pd.Series([df['review_no_html'][i] for i in idxs])\n",
    "products = pd.Series([df['title'][i] for i in idxs])\n",
    "asins = pd.Series([df['asin'][i] for i in idxs])\n",
    "top_docs_df = pd.concat([asins, products, idxs, probs, texts], axis = 1)\n",
    "top_docs_df.columns = ['asin','product','doc_id', 'prob_from_topic','reviewText']\n",
    "top_docs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Topic 0: mostly about mounting and installation\n",
    "- Topic 1: good value/quality for the price (a few obviously mis-classified reviews in top 10)\n",
    "- Topic 2: not meaningful\n",
    "- Topic 3: topic keywords indicate good price is the main theme, but top 10 reviews point to easy installation and arm\n",
    "- Topic 4: dimensions of components w.r.t fit and dimension\n",
    "- Topic 5: antenna/channel: these do not seem to be reviews about TV mounts (mis-categorized reviews)\n",
    "- Topic 6: a subcategory of product: sound-bar brackets\n",
    "- Topic 7: mixed in some monitor stands (not TV mounts)\n",
    "- Topic 8: installation that concerns screws and studs\n",
    "- Topic 9: similar to 8, about screws, studs and brackets in installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin     B005HPSFWI                                                                                       \n",
       "title    Halter&reg; Freestanding Dual/Two LCD Monitor Desk Stand Holds Monitors up to 24&quot; Widescreen\n",
       "Name: 11613, dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['asin','title']].iloc[11609,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_topics = out_doc_topics(ldamodel=lda_0, corpus=DTM, rev_proc = reviews, rev_orig = df['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Prob_From_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>review_lemmatized</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4013</td>\n",
       "      <td>price, good, product, great, easy</td>\n",
       "      <td>[well, construct, set, inch, plate, numerous, hole, varius, set, plenty, extra, hardware, provide, price, th, would, cost, open, market, recommend, highly]</td>\n",
       "      <td>Well constructed wall mount for TV sets up to 37 inches. The mounting  plate has numerous holes for varius sets. Plenty of extra hardware provided. Price was about 1/8th of what it would cost on the open market. I recommend it highly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5853</td>\n",
       "      <td>one, would, get, go, make</td>\n",
       "      <td>[use, lcd, lb, instal, less, hour, happy, resultsproscome, hardware, needcom, extra, hardware, idea, suspect, universal, hardware, pack, several, model, hardware, use, model, nice, little, extra, always, good, enoughthe, include, level, nice, well, cheap, worksthe, instruction, decent, enough, job, explain, install, unitconsmetal, tad, flimsy, side, problem, trust, lb, television, something, close, maximum, rat, weight, lb, think, would, quite, bit, nervous, hold, upthe, hole, base, little, bit, wide, stud, think, particular, stud, installing, onto, typical, x, center, leave, right, side, hole, little, far, grab, side, stud, reposition, center, hole, align, leave, side, stud, right, side, hole, align, right, side, stud, result, able, ...]</td>\n",
       "      <td>I used it to mount a 32\" LCD TV to the wall... about 28LBS.  I installed it in less than 1/2 hour and am very happy with the results.PROS:-Comes with all of the hardware you'll need-Comes with some extra hardware of which I have NO IDEA what it is there for.  I suspect it's a 'universal' hardware pack for several models and not all hardware is used for all models, but it's nice to have a little 'extra' (which is always better than not enough!)-The included Level is nice... well it's cheap but it works!-The instructions did a decent enough job of explaining how to install the unit.CONS:-Metal is just a tad on the flimsy side.  I have no problems trusting it with my &amp;lt;30lb television but if I were to mount something closer to its maximum rated weight of 55lbs, I think I would be quite a bit nervous about it holding up.-The holes in the base were just a little bit too wide for my wall stud.  I think the particular stud I was installing it onto was a typical 2X4 and if centered, the left and right side holes were just a little too far to grab both sides of the stud.  I had to reposition it so that the center holes were aligned to the left side of the stud, and that the right side holes were aligned to the right side of the stud.  As a result, I was only able to install four of the six bolts to hold it in place, but I don't feel it will be an issue with my 28LB television.  If your house uses wider studs this probably wouldn't even be an issue.-The metal does sag just a little bit with the weight of the television on it.  I mounted the base just a little bit \"off level\" to help compensate for this, and had no problems getting the television level using the adjustments available to me.CONCLUSION:  All in all It's not a bad unit.. ESPECIALLY for the price.  Yes I would have liked to see a sturdier unit, but when you take into account the &amp;lt;$30 price tag, it's an excellent bargain.  I don't think I'll have any issue with a static mounting of my TV in the corner of the bedroom *BUT* if you are considering installing this unit for a television that will see a lot of traffic, constant repositioning, etc... then you might want to spend more money on something sturdier.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>price, good, product, great, easy</td>\n",
       "      <td>[excellent, well, build, sturdy, use, fit, need, perfectly, price, also, good, much, much, cheap, inferior, would, cost, retail, store, would, definitely, recommend]</td>\n",
       "      <td>This mount is excellent. It is very well built and sturdy. I used it to mount a 32\" TV and it fit the need perfectly. The price was also very good and much, much cheaper than what an inferior mount would cost in a retail store. I would definitely recommend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>price, good, product, great, easy</td>\n",
       "      <td>[work, great, much, cheaper, expensive, version, big, box, store, super, easy, install, need, drill, ratchet, set, get, stud, oh, yea, stud, finder]</td>\n",
       "      <td>Works great and is so much cheaper than the more expensive versions at the Big box stores. It is super easy to install yourself too. You just need a drill and a ratchet set to get it into the stud (oh yea a stud finder too).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>easy, great, work, install, inch</td>\n",
       "      <td>[buy, gym, get, move, around, bit, definitely, sturdy, work, well]</td>\n",
       "      <td>We bought this for the tv in our gym as it gets moved around a bit.  It's definitely sturdy and works well.  Our tv in there is 24&amp;#34;,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5097</td>\n",
       "      <td>one, would, get, go, make</td>\n",
       "      <td>[price, beat, -PRON-, come, screw, luckily, leftover, another, want, bother, return, also, sure, mean, tilt, mine, arm, extend, say, swivel, leave, right, tilt, expectation, otherwise, beat, price, targetb, buy, etc, go]</td>\n",
       "      <td>For the price, you can't beat it. Mine didn't come with any of the screws for the TV, but luckily I had some leftover from another mount so I didn't want to bother returning it. Also, not sure what they mean by tilt, but mine doesn't. The arm extends in and out as said, tv swivels left to right, but does not tilt up and down as was my expectation. Otherwise, can't beat it for the price as in Target/Best Buy etc., these are going for $60+.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2817</td>\n",
       "      <td>easy, great, work, install, inch</td>\n",
       "      <td>[beat, deal, anywhere, else, web, retailer, overprice, get, couple, piece, fabricate, metal, hold, articulate, reasonably, pricedpro, easy, install, help, cordless, driver, drill, pilot, hole, drive, lag, screw, also, need, stud, finder, well, fabricate, everything, advertise, ie, articulate, make, need, loosen, nutscon, really, stretch, since, good, deal, instruction, could, use, help, novice, diyersinstall, tip, really, help, second, person, assist, final, step, flat, panel, mountinstall, lb, inch, flat, panel, lcd, vesa, mm, x, mm, work, beautifully, originally, sit, little, high, stand, picture, good, upward, view, angle, screen, inherent, problem, cheap, lcds, directly, front, lcd, screen, correct, issue, allow, tilt, screen, would, strongly, ...]</td>\n",
       "      <td>Cannot beat this deal anywhere else on the web!  All other retailers are over-priced for what you are getting - a couple pieces of fabricated metal to hold a TV that articulates! This mount is reasonably priced.Pros:  Easy to install (helps to have a cordless driver to drill 6 pilot holes, and to drive in 6 lag screws. You also need to have a stud finder).- Well fabricated- Mount does everything advertised (i.e. articulates - you made need to loosen up some nuts)Con's: Really stretching here since this is a good deal: Instructions could use some help for the \"novice\" DIY'ersInstall tip:  It really helps if you have a second person assisting you for the final step of mounting the flat panel to the TV mountInstalled a 15.5 lbs, 26 Inch Flat Panel LCD (VESA 200mm X 100mm) to this mount. Mount works beautifully! I originally had the TV sitting a little high on a stand, but then the picture was not as good because of the upward viewing angle of the screen (inherent problem with cheaper LCD's - not being directly in front of a LCD screen) - this mount corrected this issue by allowing me to \"tilt down\" the screen.  I would strongly recommend this mount if you are in the market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>price, good, product, great, easy</td>\n",
       "      <td>[easy, install, sturdy, functional, affordable, price]</td>\n",
       "      <td>This mount is easy to install and very sturdy and is very functional and very affordable for the price. A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3656</td>\n",
       "      <td>easy, great, work, install, inch</td>\n",
       "      <td>[work, like, charm, lie, flat, want, pull, swivel, like, charm, need, toothe, instruction, call, stud, however, mine, directly, drywall, use, heavy, duty, anchor, work, perfect, well, great, product, amazing, price]</td>\n",
       "      <td>Works like a charm! Lies flat on the wall when I want it too and pulls out and swivels like a charm when I need it too!The instructions call for it to be mounted into a stud in the wall, however mine is mounted directly into the drywall using heavy duty anchors and it works perfect as well! This is a great product for an amazing price!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3346</td>\n",
       "      <td>one, would, get, go, make</td>\n",
       "      <td>[easey, put, together, install, use, lead, flat, screen, instuction, say, complete, unit, back, plate, grind, first, one, person, job, well, build, product, make, chinawish, could, buy, american, make, good, luck, next, time]</td>\n",
       "      <td>Easey to put together and install. Used to mount a 37\" LED flat screen. Instuction say to mount the complete unit but if you mount the TV to the back plate on the ground first its a one person job. Well built product for being made in China.wish you could buy American made, better luck next time.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant_Topic  Prob_From_Topic                     Topic_Keywords  \\\n",
       "20  3.0             0.4013           price, good, product, great, easy   \n",
       "21  2.0             0.5853           one, would, get, go, make           \n",
       "22  3.0             0.9188           price, good, product, great, easy   \n",
       "23  3.0             0.5135           price, good, product, great, easy   \n",
       "24  1.0             0.6045           easy, great, work, install, inch    \n",
       "25  2.0             0.5097           one, would, get, go, make           \n",
       "26  1.0             0.2817           easy, great, work, install, inch    \n",
       "27  3.0             0.4960           price, good, product, great, easy   \n",
       "28  1.0             0.3656           easy, great, work, install, inch    \n",
       "29  2.0             0.3346           one, would, get, go, make           \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             review_lemmatized  \\\n",
       "20  [well, construct, set, inch, plate, numerous, hole, varius, set, plenty, extra, hardware, provide, price, th, would, cost, open, market, recommend, highly]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "21  [use, lcd, lb, instal, less, hour, happy, resultsproscome, hardware, needcom, extra, hardware, idea, suspect, universal, hardware, pack, several, model, hardware, use, model, nice, little, extra, always, good, enoughthe, include, level, nice, well, cheap, worksthe, instruction, decent, enough, job, explain, install, unitconsmetal, tad, flimsy, side, problem, trust, lb, television, something, close, maximum, rat, weight, lb, think, would, quite, bit, nervous, hold, upthe, hole, base, little, bit, wide, stud, think, particular, stud, installing, onto, typical, x, center, leave, right, side, hole, little, far, grab, side, stud, reposition, center, hole, align, leave, side, stud, right, side, hole, align, right, side, stud, result, able, ...]                 \n",
       "22  [excellent, well, build, sturdy, use, fit, need, perfectly, price, also, good, much, much, cheap, inferior, would, cost, retail, store, would, definitely, recommend]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "23  [work, great, much, cheaper, expensive, version, big, box, store, super, easy, install, need, drill, ratchet, set, get, stud, oh, yea, stud, finder]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "24  [buy, gym, get, move, around, bit, definitely, sturdy, work, well]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "25  [price, beat, -PRON-, come, screw, luckily, leftover, another, want, bother, return, also, sure, mean, tilt, mine, arm, extend, say, swivel, leave, right, tilt, expectation, otherwise, beat, price, targetb, buy, etc, go]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "26  [beat, deal, anywhere, else, web, retailer, overprice, get, couple, piece, fabricate, metal, hold, articulate, reasonably, pricedpro, easy, install, help, cordless, driver, drill, pilot, hole, drive, lag, screw, also, need, stud, finder, well, fabricate, everything, advertise, ie, articulate, make, need, loosen, nutscon, really, stretch, since, good, deal, instruction, could, use, help, novice, diyersinstall, tip, really, help, second, person, assist, final, step, flat, panel, mountinstall, lb, inch, flat, panel, lcd, vesa, mm, x, mm, work, beautifully, originally, sit, little, high, stand, picture, good, upward, view, angle, screen, inherent, problem, cheap, lcds, directly, front, lcd, screen, correct, issue, allow, tilt, screen, would, strongly, ...]   \n",
       "27  [easy, install, sturdy, functional, affordable, price]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "28  [work, like, charm, lie, flat, want, pull, swivel, like, charm, need, toothe, instruction, call, stud, however, mine, directly, drywall, use, heavy, duty, anchor, work, perfect, well, great, product, amazing, price]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "29  [easey, put, together, install, use, lead, flat, screen, instuction, say, complete, unit, back, plate, grind, first, one, person, job, well, build, product, make, chinawish, could, buy, american, make, good, luck, next, time]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 reviewText  \n",
       "20  Well constructed wall mount for TV sets up to 37 inches. The mounting  plate has numerous holes for varius sets. Plenty of extra hardware provided. Price was about 1/8th of what it would cost on the open market. I recommend it highly.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "21  I used it to mount a 32\" LCD TV to the wall... about 28LBS.  I installed it in less than 1/2 hour and am very happy with the results.PROS:-Comes with all of the hardware you'll need-Comes with some extra hardware of which I have NO IDEA what it is there for.  I suspect it's a 'universal' hardware pack for several models and not all hardware is used for all models, but it's nice to have a little 'extra' (which is always better than not enough!)-The included Level is nice... well it's cheap but it works!-The instructions did a decent enough job of explaining how to install the unit.CONS:-Metal is just a tad on the flimsy side.  I have no problems trusting it with my &lt;30lb television but if I were to mount something closer to its maximum rated weight of 55lbs, I think I would be quite a bit nervous about it holding up.-The holes in the base were just a little bit too wide for my wall stud.  I think the particular stud I was installing it onto was a typical 2X4 and if centered, the left and right side holes were just a little too far to grab both sides of the stud.  I had to reposition it so that the center holes were aligned to the left side of the stud, and that the right side holes were aligned to the right side of the stud.  As a result, I was only able to install four of the six bolts to hold it in place, but I don't feel it will be an issue with my 28LB television.  If your house uses wider studs this probably wouldn't even be an issue.-The metal does sag just a little bit with the weight of the television on it.  I mounted the base just a little bit \"off level\" to help compensate for this, and had no problems getting the television level using the adjustments available to me.CONCLUSION:  All in all It's not a bad unit.. ESPECIALLY for the price.  Yes I would have liked to see a sturdier unit, but when you take into account the &lt;$30 price tag, it's an excellent bargain.  I don't think I'll have any issue with a static mounting of my TV in the corner of the bedroom *BUT* if you are considering installing this unit for a television that will see a lot of traffic, constant repositioning, etc... then you might want to spend more money on something sturdier.  \n",
       "22  This mount is excellent. It is very well built and sturdy. I used it to mount a 32\" TV and it fit the need perfectly. The price was also very good and much, much cheaper than what an inferior mount would cost in a retail store. I would definitely recommend.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "23  Works great and is so much cheaper than the more expensive versions at the Big box stores. It is super easy to install yourself too. You just need a drill and a ratchet set to get it into the stud (oh yea a stud finder too).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "24  We bought this for the tv in our gym as it gets moved around a bit.  It's definitely sturdy and works well.  Our tv in there is 24&#34;,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "25  For the price, you can't beat it. Mine didn't come with any of the screws for the TV, but luckily I had some leftover from another mount so I didn't want to bother returning it. Also, not sure what they mean by tilt, but mine doesn't. The arm extends in and out as said, tv swivels left to right, but does not tilt up and down as was my expectation. Otherwise, can't beat it for the price as in Target/Best Buy etc., these are going for $60+.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "26  Cannot beat this deal anywhere else on the web!  All other retailers are over-priced for what you are getting - a couple pieces of fabricated metal to hold a TV that articulates! This mount is reasonably priced.Pros:  Easy to install (helps to have a cordless driver to drill 6 pilot holes, and to drive in 6 lag screws. You also need to have a stud finder).- Well fabricated- Mount does everything advertised (i.e. articulates - you made need to loosen up some nuts)Con's: Really stretching here since this is a good deal: Instructions could use some help for the \"novice\" DIY'ersInstall tip:  It really helps if you have a second person assisting you for the final step of mounting the flat panel to the TV mountInstalled a 15.5 lbs, 26 Inch Flat Panel LCD (VESA 200mm X 100mm) to this mount. Mount works beautifully! I originally had the TV sitting a little high on a stand, but then the picture was not as good because of the upward viewing angle of the screen (inherent problem with cheaper LCD's - not being directly in front of a LCD screen) - this mount corrected this issue by allowing me to \"tilt down\" the screen.  I would strongly recommend this mount if you are in the market.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "27  This mount is easy to install and very sturdy and is very functional and very affordable for the price. A+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "28  Works like a charm! Lies flat on the wall when I want it too and pulls out and swivels like a charm when I need it too!The instructions call for it to be mounted into a stud in the wall, however mine is mounted directly into the drywall using heavy duty anchors and it works perfect as well! This is a great product for an amazing price!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "29  Easey to put together and install. Used to mount a 37\" LED flat screen. Instuction say to mount the complete unit but if you mount the TV to the back plate on the ground first its a one person job. Well built product for being made in China.wish you could buy American made, better luck next time.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc_topics.iloc[20:30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim LDA number of topics optimization\n",
    "# model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=DTM, texts=reviews, limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "14.51501\n",
      "0.034318022\n",
      "0.23312211\n",
      "[(0,\n",
      "  '0.034*\"easy\" + 0.031*\"level\" + 0.026*\"come\" + 0.024*\"install\" + '\n",
      "  '0.020*\"great\" + 0.017*\"need\" + 0.017*\"price\" + 0.016*\"include\" + '\n",
      "  '0.016*\"cable\" + 0.015*\"use\"'),\n",
      " (1,\n",
      "  '0.015*\"get\" + 0.014*\"one\" + 0.012*\"would\" + 0.012*\"go\" + 0.010*\"review\" + '\n",
      "  '0.009*\"instruction\" + 0.008*\"product\" + 0.008*\"say\" + 0.007*\"take\" + '\n",
      "  '0.007*\"make\"'),\n",
      " (2,\n",
      "  '0.033*\"shelf\" + 0.026*\"look\" + 0.019*\"stand\" + 0.014*\"box\" + 0.012*\"cable\" '\n",
      "  '+ 0.011*\"great\" + 0.011*\"glass\" + 0.011*\"player\" + 0.010*\"put\" + '\n",
      "  '0.009*\"hold\"'),\n",
      " (3,\n",
      "  '0.035*\"cable\" + 0.023*\"bar\" + 0.022*\"sound\" + 0.017*\"soundbar\" + '\n",
      "  '0.015*\"use\" + 0.014*\"back\" + 0.012*\"work\" + 0.011*\"power\" + 0.010*\"make\" + '\n",
      "  '0.009*\"get\"'),\n",
      " (4,\n",
      "  '0.044*\"monitor\" + 0.020*\"arm\" + 0.016*\"use\" + 0.013*\"move\" + 0.011*\"stand\" '\n",
      "  '+ 0.010*\"one\" + 0.010*\"desk\" + 0.009*\"work\" + 0.009*\"would\" + '\n",
      "  '0.009*\"position\"'),\n",
      " (5,\n",
      "  '0.058*\"antenna\" + 0.031*\"channel\" + 0.022*\"get\" + 0.018*\"mohu\" + '\n",
      "  '0.016*\"signal\" + 0.011*\"station\" + 0.010*\"mile\" + 0.010*\"hdtv\" + '\n",
      "  '0.009*\"good\" + 0.009*\"work\"'),\n",
      " (6,\n",
      "  '0.033*\"work\" + 0.032*\"easy\" + 0.030*\"great\" + 0.020*\"install\" + '\n",
      "  '0.020*\"flat\" + 0.019*\"screen\" + 0.016*\"inch\" + 0.016*\"use\" + 0.014*\"well\" + '\n",
      "  '0.013*\"recommend\"'),\n",
      " (7,\n",
      "  '0.031*\"screw\" + 0.019*\"bolt\" + 0.019*\"use\" + 0.017*\"bracket\" + 0.016*\"stud\" '\n",
      "  '+ 0.014*\"hole\" + 0.011*\"one\" + 0.010*\"plate\" + 0.010*\"would\" + '\n",
      "  '0.010*\"make\"'),\n",
      " (8,\n",
      "  '0.030*\"buy\" + 0.029*\"one\" + 0.023*\"good\" + 0.022*\"price\" + 0.014*\"great\" + '\n",
      "  '0.014*\"get\" + 0.014*\"product\" + 0.014*\"quality\" + 0.013*\"would\" + '\n",
      "  '0.013*\"work\"'),\n",
      " (9,\n",
      "  '0.023*\"hold\" + 0.020*\"heavy\" + 0.019*\"would\" + 0.017*\"well\" + 0.014*\"make\" '\n",
      "  '+ 0.014*\"good\" + 0.013*\"work\" + 0.013*\"tilt\" + 0.012*\"little\" + '\n",
      "  '0.011*\"use\"')]\n",
      "0.3976081334245362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build an LDA model with specified alpha = 0.01 (smaller than default values 1/k, fewer topics per document)\n",
    "n_topics = 10\n",
    "lda_1, vis_1 = train_lda_gensim(alpha0 = np.ones(n_topics)*(1/n_topics)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build an LDA model with specified alpha = 0.001 (smaller than default values 1/k, fewer topics per document)\n",
    "lda_2, vis_2 = train_lda_gensim(alpha0 = np.ones(n_topics)*0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 19:35:12,293 : INFO : serializing temporary corpus to C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.txt\n",
      "2019-07-08 19:35:12,297 : DEBUG : {'uri': 'C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.txt', 'mode': 'wb', 'kw': {}}\n",
      "2019-07-08 19:35:12,965 : INFO : converting temporary corpus to MALLET format with C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.txt --output C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.mallet\n",
      "2019-07-08 19:35:12,967 : DEBUG : COMMAND: () {'args': 'C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\\\S+\" --input C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.txt --output C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.mallet', 'shell': True}\n",
      "2019-07-08 19:35:17,006 : INFO : training MALLET LDA with C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet train-topics --input C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.mallet --num-topics 10  --alpha 50 --optimize-interval 0 --num-threads 4 --output-state C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_state.mallet.gz --output-doc-topics C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_doctopics.txt --output-topic-keys C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_topickeys.txt --num-iterations 1000 --inferencer-filename C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2019-07-08 19:35:17,008 : DEBUG : COMMAND: () {'args': 'C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet train-topics --input C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.mallet --num-topics 10  --alpha 50 --optimize-interval 0 --num-threads 4 --output-state C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_state.mallet.gz --output-doc-topics C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_doctopics.txt --output-topic-keys C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_topickeys.txt --num-iterations 1000 --inferencer-filename C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_inferencer.mallet --doc-topics-threshold 0.0', 'shell': True}\n",
      "2019-07-08 19:36:05,719 : INFO : loading assigned topics from C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_state.mallet.gz\n",
      "2019-07-08 19:36:05,721 : DEBUG : {'uri': 'C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_state.mallet.gz', 'mode': 'rb', 'kw': {}}\n"
     ]
    }
   ],
   "source": [
    "# mallet implementation of LDA\n",
    "import os\n",
    "os.environ['MALLET_HOME'] = \"C:/Users/yanqi/Library/mallet-2.0.8\"\n",
    "mallet_path = \"C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet\"\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=DTM, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('product', 0.040998082551216064),\n",
      "   ('review', 0.028938338883842972),\n",
      "   ('amazon', 0.024144716924008477),\n",
      "   ('star', 0.022252497729336965),\n",
      "   ('order', 0.021949742658189525),\n",
      "   ('item', 0.021848824301140376),\n",
      "   ('give', 0.019325865374911697),\n",
      "   ('part', 0.01907356948228883),\n",
      "   ('find', 0.016727217680896155),\n",
      "   ('purchase', 0.016323544252699565)]),\n",
      " (1,\n",
      "  [('level', 0.08489181383457223),\n",
      "   ('stud', 0.08470242886226978),\n",
      "   ('hole', 0.05198617489702192),\n",
      "   ('plate', 0.03856351498508594),\n",
      "   ('bolt', 0.037214147057430993),\n",
      "   ('drill', 0.02753184034846835),\n",
      "   ('center', 0.02658491548695611),\n",
      "   ('make', 0.02630083802850244),\n",
      "   ('lag', 0.020122153307135078),\n",
      "   ('find', 0.017565456181052035)]),\n",
      " (2,\n",
      "  [('tilt', 0.06603422157101349),\n",
      "   ('arm', 0.05545483895000869),\n",
      "   ('move', 0.03871656691583679),\n",
      "   ('adjust', 0.03071994437132143),\n",
      "   ('angle', 0.029751409342637893),\n",
      "   ('side', 0.024908734199220205),\n",
      "   ('position', 0.021556112946084883),\n",
      "   ('adjustment', 0.021531278714580177),\n",
      "   ('swivel', 0.019817716740755456),\n",
      "   ('pull', 0.01594357662602131)]),\n",
      " (3,\n",
      "  [('price', 0.06007137192704203),\n",
      "   ('good', 0.05808881839809675),\n",
      "   ('monitor', 0.055823042936445),\n",
      "   ('buy', 0.052679279483403195),\n",
      "   ('product', 0.04423926588875043),\n",
      "   ('recommend', 0.04101053585589668),\n",
      "   ('quality', 0.04050073637702504),\n",
      "   ('flat', 0.03882972697405687),\n",
      "   ('screen', 0.037781805823042934),\n",
      "   ('purchase', 0.03514784184887278)]),\n",
      " (4,\n",
      "  [('easy', 0.1307374563101187),\n",
      "   ('great', 0.11409919408417343),\n",
      "   ('install', 0.10254484531615587),\n",
      "   ('work', 0.09876079609463012),\n",
      "   ('inch', 0.056702966579046186),\n",
      "   ('buy', 0.045379704786388975),\n",
      "   ('sturdy', 0.03784049221525752),\n",
      "   ('price', 0.036049568156214795),\n",
      "   ('samsung', 0.029839105693405355),\n",
      "   ('lcd', 0.028365926225483118)]),\n",
      " (5,\n",
      "  [('unit', 0.038853554035713334),\n",
      "   ('good', 0.023338744444740135),\n",
      "   ('work', 0.02307262421161881),\n",
      "   ('television', 0.017351039199510337),\n",
      "   ('high', 0.01527530138116401),\n",
      "   ('year', 0.015222077334539745),\n",
      "   ('antenna', 0.013678579982436065),\n",
      "   ('-PRON-', 0.012321366793517311),\n",
      "   ('home', 0.011735902280650398),\n",
      "   ('set', 0.011310109907656279)]),\n",
      " (6,\n",
      "  [('cable', 0.0681190956374058),\n",
      "   ('room', 0.03486890988217811),\n",
      "   ('hdmi', 0.03380745143827619),\n",
      "   ('nice', 0.031206878250716486),\n",
      "   ('back', 0.029190107207302834),\n",
      "   ('shelf', 0.022555991932915825),\n",
      "   ('box', 0.02157414287230655),\n",
      "   ('space', 0.017726356013162085),\n",
      "   ('put', 0.015470756819870502),\n",
      "   ('wire', 0.014913491136821994)]),\n",
      " (7,\n",
      "  [('screw', 0.12377887336802702),\n",
      "   ('bracket', 0.08301378617730303),\n",
      "   ('bolt', 0.035720807084816945),\n",
      "   ('attach', 0.03056240299461335),\n",
      "   ('long', 0.02677348671596823),\n",
      "   ('back', 0.021569433032046014),\n",
      "   ('bottom', 0.019880398064457225),\n",
      "   ('provide', 0.019195654158677987),\n",
      "   ('set', 0.017757691956541588),\n",
      "   ('small', 0.016091481785812108)]),\n",
      " (8,\n",
      "  [('hardware', 0.04772865571341641),\n",
      "   ('include', 0.044342143556366904),\n",
      "   ('good', 0.03875968992248062),\n",
      "   ('instruction', 0.03844220440775723),\n",
      "   ('installation', 0.036510834193189935),\n",
      "   ('hang', 0.03291266502632484),\n",
      "   ('make', 0.026298383469587534),\n",
      "   ('store', 0.02566341244014075),\n",
      "   ('plasma', 0.022620842924041592),\n",
      "   ('instal', 0.02119215810778633)]),\n",
      " (9,\n",
      "  [('hold', 0.07276763030513733),\n",
      "   ('make', 0.045997914048083864),\n",
      "   ('heavy', 0.04222715481507234),\n",
      "   ('put', 0.04123766480357286),\n",
      "   ('thing', 0.04008771695237077),\n",
      "   ('solid', 0.03401706201695504),\n",
      "   ('weight', 0.02995213007782205),\n",
      "   ('fine', 0.023747760275987483),\n",
      "   ('feel', 0.02315941486374455),\n",
      "   ('lb', 0.020939748081191666)])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 19:37:37,370 : DEBUG : Setting topics to those of the model: <gensim.models.wrappers.ldamallet.LdaMallet object at 0x0000025AD3559FD0>\n",
      "2019-07-08 19:37:37,375 : INFO : using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n",
      "2019-07-08 19:38:02,758 : INFO : 3 accumulators retrieved from output queue\n",
      "2019-07-08 19:38:02,883 : INFO : accumulated word occurrence stats for 65085 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.4348644493605834\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=reviews, dictionary=dictionary, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 19:44:28,890 : INFO : serializing temporary corpus to C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.txt\n",
      "2019-07-08 19:44:28,894 : DEBUG : {'uri': 'C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.txt', 'mode': 'wb', 'kw': {}}\n",
      "2019-07-08 19:44:29,532 : INFO : converting temporary corpus to MALLET format with C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.txt --output C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.mallet.infer --use-pipe-from C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.mallet\n",
      "2019-07-08 19:44:29,534 : DEBUG : COMMAND: () {'args': 'C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\\\S+\" --input C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.txt --output C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.mallet.infer --use-pipe-from C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.mallet', 'shell': True}\n",
      "2019-07-08 19:44:33,633 : INFO : inferring topics with MALLET LDA 'C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet infer-topics --input C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.mallet.infer --inferencer C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_inferencer.mallet --output-doc-topics C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_doctopics.txt.infer --num-iterations 100 --doc-topics-threshold 0.0'\n",
      "2019-07-08 19:44:33,636 : DEBUG : COMMAND: () {'args': 'C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet infer-topics --input C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.mallet.infer --inferencer C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_inferencer.mallet --output-doc-topics C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_doctopics.txt.infer --num-iterations 100 --doc-topics-threshold 0.0', 'shell': True}\n",
      "2019-07-08 19:44:38,921 : DEBUG : {'uri': 'C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_doctopics.txt.infer', 'mode': 'rb', 'kw': {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ldamallet[DTM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-08 19:40:49,348 : INFO : serializing temporary corpus to C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.txt\n",
      "2019-07-08 19:40:49,351 : DEBUG : {'uri': 'C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.txt', 'mode': 'wb', 'kw': {}}\n",
      "2019-07-08 19:40:49,945 : INFO : converting temporary corpus to MALLET format with C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.txt --output C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.mallet.infer --use-pipe-from C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.mallet\n",
      "2019-07-08 19:40:49,947 : DEBUG : COMMAND: () {'args': 'C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\\\S+\" --input C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.txt --output C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.mallet.infer --use-pipe-from C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.mallet', 'shell': True}\n",
      "2019-07-08 19:40:54,243 : INFO : inferring topics with MALLET LDA 'C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet infer-topics --input C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_corpus.mallet.infer --inferencer C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_inferencer.mallet --output-doc-topics C:\\Users\\yanqi\\AppData\\Local\\Temp\\425456_doctopics.txt.infer --num-iterations 100 --doc-topics-threshold 0.0'\n",
      "2019-07-08 19:40:54,246 : DEBUG : COMMAND: () {'args': 'C:/Users/yanqi/Library/mallet-2.0.8/bin/mallet infer-topics --input C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_corpus.mallet.infer --inferencer C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_inferencer.mallet --output-doc-topics C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_doctopics.txt.infer --num-iterations 100 --doc-topics-threshold 0.0', 'shell': True}\n",
      "2019-07-08 19:40:59,770 : DEBUG : {'uri': 'C:\\\\Users\\\\yanqi\\\\AppData\\\\Local\\\\Temp\\\\425456_doctopics.txt.infer', 'mode': 'rb', 'kw': {}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 has 13119 documents\n",
      "topic 1 has 13119 documents\n",
      "topic 2 has 13119 documents\n",
      "topic 3 has 13119 documents\n",
      "topic 4 has 13119 documents\n",
      "topic 5 has 13119 documents\n",
      "topic 6 has 13119 documents\n",
      "topic 7 has 13119 documents\n",
      "topic 8 has 13119 documents\n",
      "topic 9 has 13119 documents\n"
     ]
    }
   ],
   "source": [
    "# examine the topics \n",
    "topics_docs_dict = out_topics_docs(ldamallet, DTM)\n",
    "for k in sorted(topics_docs_dict.keys()):\n",
    "    print(\"topic\", k, \"has\", len(topics_docs_dict[k]),\"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of topics\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=DTM, texts=reviews, limit=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other ideas to try\n",
    "https://towardsdatascience.com/the-complete-guide-for-topics-extraction-in-python-a6aaa6cedbbc\n",
    "\n",
    "try low alpha and low eta\n",
    "try mallet LDA\n",
    "add bi-grams\n",
    "\n",
    "References\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "https://www.vladsandulescu.com/topic-prediction-lda-user-reviews/\n",
    "\n",
    "Include sentence level prediction and Mallet LDA\n",
    "https://github.com/raffg/harry_potter_nlp/blob/master/LDA.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
